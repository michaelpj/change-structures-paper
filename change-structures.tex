% Toggle comments for preamble and topmatter to typeset in ACM style

%\input{preamble-standard}
\input{preamble-acm}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{thmtools}
\usepackage{todonotes}
\usepackage{etoolbox}
\usepackage{appendix}

% Packages where the order matters
\usepackage[
  safeinputenc,
  natbib=true
]{biblatex}
\usepackage{cleveref}
\usepackage{hyperref}

\newcommand{\todoall}[1]{\todo[inline,color=black!30,author=All]{#1}}
\newcommand{\todompj}[1]{\todo[inline,color=yellow!40,author=Michael]{#1}}
\newcommand{\todomario}[1]{\todo[inline,color=blue!40,author=Mario]{#1}}

\input{notation}

\newif\ifproofs
% Comment out to disable proofs
%\proofstrue

\addbibresource{paper.bib}

\begin{document}

%\input{topmatter-standard}
\input{topmatter-acm}

\begin{abstract}
  Incremental computation has been studied using the concepts of \emph{change
  structures} and \emph{derivatives} of programs, where the deirvative of a function allows updating the output
  of the function based on a change to its input.

  We generalise change structures to a Cartesian closed category of \emph{change actions},
  and study their algebraic properties. We develop change actions for several common structures
  in computer science, including directed-complete partial orders and Boolean algebras.

  We then show how to compute derivatives of fixpoints. This allows us to
  perform incremental evaluation and maintenance of recursively defined
  functions such as generalized Datalog programs.

  Moreover, unlike previous results our techniques are \emph{modular} in that
  they are easy to apply both to variants of Datalog and to other programming languages.
\end{abstract}

\title{Fixing incremental computation}
\subtitle{Derivatives of fixpoints, and the recursive semantics of Datalog}

\maketitle

\section{Introduction}
\label{sec:intro}

Consider the following classic Datalog program\footnote{See \autocite[][part D]{abiteboul1995foundations} for an introduction to Datalog.},
which computes the transitive closure of an edge relation $e$:
\begin{align*}
  tc(x, y) &\leftarrow e(x, y)\\
  tc(x, y) &\leftarrow e(x, z) \wedge tc(z, y)
\end{align*}


The semantics of Datalog, tells us that the denotation of this program is the
least fixpoint of the rule $tc$. Kleene's Theorem tells us that we can in fact
compute this by repeatedly applying the rule to fixpoint, starting from the empty relation. For example, supposing
that $e = \{ (1, 2), (2, 3), (3, 4) \}$, we get the following evaluation trace:
\begin{center}
  \begin{tabular} {p{3.5em} p{10em} p{10em}}
    Iteration & Newly deduced facts & Accumulated data in $tc$ \\
    \toprule
    1 & $\{ (1, 2), (2, 3), (3, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4) \}$\\
    2 & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4) \}$\\
    3 & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4), (1, 4),(1, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4), (1, 4) \}$\\
    4 & (as above) & (as above) \\
    \bottomrule
  \end{tabular}
\end{center}
\medskip

At this point we have reached a fixpoint, and so we are done.

However, this process is quite wasteful. We deduced the fact $(1,2)$ at every iteration,
even though we had already deduced it in the first iteration. Indeed, for a
chain of $n$ such edges we will deduce $O(n^2)$ facts along the way.

The standard improvement to this evaluation strategy is known as ``semi-naive'' 
evaluation, where we transform 
the program into a \emph{delta} program that only deduces the \emph{new} facts at each
iteration. We can then gradually accumulate these to compute the final relation \autocite[See][section
13.1]{abiteboul1995foundations}.
\begin{align*}
  \Delta tc_{0}(x, y) &\leftarrow e(x, y)\\
  \Delta tc_{i+1}(x, y) &\leftarrow e(x, z) \wedge \Delta tc_i(z, y)\\
  tc_{0}(x, y) &\leftarrow e(x, z)\\
  tc_{i+1}(x, y) &\leftarrow tc_{i}(x,y) \vee \Delta tc_{i+1}(x,y)
\end{align*}

\begin{center}
  \begin{tabular} {p{3.5em} p{8em} p{10em}}
    Iteration & $\Delta tc_i$ & $tc_i$ \\
    \toprule
    1 & $\{ (1, 2), (2, 3), (3, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4) \}$\\
    2 & $\{ (1, 3), (2, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4) \}$\\
    3 & $\{ (1, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4), (1, 4) \}$\\
    4 & $\{ \}$ & (as above) \\
    \bottomrule
  \end{tabular}
\end{center}
\medskip

This is much better \textemdash{} we have turned a quadratic computation into a linear one.

But the delta rule translation works only for traditional Datalog. It is common to
liberalise the formula syntax with additional features, such as disjunction,
existential quantification, negation, and aggregation.\footnote{ See, for
  example, \autocites(LogiQL)(){logicbloxWebsite}{halpin2014logiql},
  \autocites(Datomic)(){datomicWebsite},
  \autocites(Souffle)(){souffleWebsite}{scholz2016fast}, and
  \autocites(DES)(){saenz2011deductive}, which between them have all of these
  features and more. } 
This allows us to write programs like the following, where we compute whether all the
nodes in a subtree given by $child$ have some property $p$:
\begin{align*}
  treeP(x) &\leftarrow p(x) \wedge \neg \exists y . (child(x,y) \wedge \neg treeP(y))
\end{align*}

Here the combination of negation and explicit existential quantification amounts
to recursion through a \emph{universal} quantifier. We would
like to be able to use semi-naive evaluation for this rule too, but the simple delta
transformation does not produce a correct incremental program, and it is unclear how to extend it (and the
correctness proof) to handle such cases.

This is of more than theoretical interest \textemdash{} the research
in this paper was carried out at Semmle, which
makes heavy use of a commercial Datalog implementation
\autocites{semmleWebsite}{avgustinov2016ql}{sereni2008adding}{schafer2010type}.
Semmle's implementation includes parity-stratified negation\footnote{Parity-stratified negation means that recursive calls must
  appear under an even number of negations. This ensures that the rule remains
  monotone, so the least fixpoint still exists.},
recursive aggregates \autocite{demoor2013aggregates}, and other non-standard
features, so we are faced with a dilemma: either abandon the new language
features, or abandon incremental computation.

We can tell a similar story about \emph{maintenance} of Datalog programs. Again,
this problem has known solutions for traditional Datalog
\autocite{gupta1993maintaining}, but these break down when the language is extended.

There is a piece of folkloric knowledge in the Datalog community that hints at a
solution: the semi-naive translation of a rule corresponds to the
\emph{derivative} of that rule \autocites{bancilhon1986naive}[section
3.2.2]{bancilhon1986amateur}. The idea of performing incremental computation using derivatives has been
studied recently by \textcite{cai2014changes}, who give an account using
\emph{change structures}. They use this to provide a framework for incrementally evaluating lambda calculus programs.

However, \citeauthor{cai2014changes}'s work isn't directly applicable to Datalog: the tricky part
of Datalog's semantics are recursive definitions and the need for the \emph{fixpoints}, and we need some additional theory to tell us how to
handle incremental evaluation and maintenance of fixpoint computations.

This paper aims to bridge that gap by providing a solid semantic foundation for the incremental
computation of Datalog, and other recursive programs, in terms of changes and
differentiable functions.

\subsection{Contributions}

We start by generalizing change structures to
\emph{change actions} (\cref{sec:changeActions}). Change actions are simpler and weaker than change
structures, while still providing enough information to handle incremental computation,
having nice categorical behaviour (\cref{sec:category}) and fruitful
interactions with a variety of structures (\cref{sec:moreStructures}, \cref{sec:dcpos}).

We then show how change actions can be used to perform incremental evaluation and maintenance
of non-recursive program semantics, using the formula semantics of generalized Datalog as our primary
example (\cref{sec:nonRecursiveDatalog}). Moreover, the structure of the
approach is modular, and can accommodate arbitrary additional
formula constructs (\cref{sec:extensions}).

We then show how to incrementally compute and maintain fixpoints
(\cref{sec:fixpoints}). We use this to perform incremental evaluation and
maintenance of \emph{recursive} program semantics, including generalized
recursive Datalog (\cref{sec:recursiveDatalog}). This provides, to the best
of our knowledge, the world's first incremental
evaluation and maintenance mechanism for Datalog that can handle negation,
disjunction, and existential quantification. 

Finally, we provide a few remarks about the categorical structure of change
actions (\cref{sec:category}).

We have omitted the proofs from this paper. Most of the results have routine
proofs, but the proofs of the more substantial results
(especially those in \cref{sec:fixpoints}) are included in an appendix.

\section{Change actions and derivatives}
\label{sec:changeActions}

Incremental computation is about understanding how values \emph{change}. For
example, we can change an integer by adding a natural to it.
Abstractly, we have a set of values (the integers), and a set of changes
(the naturals) which we can ``apply'' to a value (by addition) to get a new value.

This kind of structure is well-known \textemdash{} it describes an set action. It is
also very natural to want to combine changes sequentially, and if we do this
then we find ourselves with a monoid action.\footnote{
Using monoid actions for change sets gives us a reason to think that
change actions are an adequate representation of changes: any subset of $A
\rightarrow A$ which is closed under composition can be
represented as a monoid action, so we are able to capture all of these as change
actions.}

\subsection{Change actions}

\begin{defn}[Change actions]
  A \emph{change action} is defined as:

  \begin{displaymath}
    \cstr{A} \defeq \cstruct{A}{\changes{A}}{\cplus_A}
  \end{displaymath}

  where $A$ is a set, $\changes{A}$ is a monoid, and $\cplus : A \rightarrow
  \changes{A} \rightarrow A$ is a monoid action on $A$.\footnote{Why not
    just work with monoid actions? The reason is that while the category of
    monoid actions and the category of change actions have the same objects, they
  have different morphisms. See \cref{sec:sacts} for further discussion.}

  We will call $A$ the base set, and $\changes{A}$ the change set of the change
  action. We will use $\splus$ for the monoid operation of $\changes{A}$, and
  $\mzero$ for its identity element. We may abbreviate $\cstruct{A}{\changes{A}}{\cplus}$ to $\cstr{A}_\cplus$ or $\cstr{A}$. When there is no risk of confusion, we will simply write $\cplus$ for $\cplus_A$.
\end{defn}

A typical change action is $\cstruct{[A]}{[A]}{\doubleplus}$. Here we represent changes
to a list (or stream) made by concatenating another list onto it. The changes
themselves can be combined using $\doubleplus$ as the monoid operation, and this
is a monoid action: $(a \doubleplus b) \doubleplus c = a \doubleplus \left( b \doubleplus c \right)$.

This is a very common case: any monoid $(A, \splus)$ can be seen as a change action
$\cstruct{A}{A}{\splus}$. Many practical change actions
can be constructed in this way. In particular, for any change action $\cstruct{A}{\changes{A}}{\cplus}$,
$\cstruct{\changes{A}}{\changes{A}}{\splus}$ is also a change action. This means
that we don't have to do any extra work to talk about changes to changes \textemdash{} we can always take $\changes{\changes{A}} = \changes{A}$.

Here are some other recurring examples of change actions:
\begin{itemize}
  \item $\cstruct{A}{M}{\lambda(a, da). a}$, where $M$ is any monoid,
    which we call the \emph{discrete} change action on any base set, since it
    induces no changes at all.
  \item $\cstr{A}_\Rightarrow \defeq \cstruct{A}{\exponential{A}{A}}{\ev}$, where $A$ is some
    category, $\exponential{A}{A}$ is the exponential object with the
    composition monoid, and $\ev$ is the evaluation map
    (for example, functions and function application).
  \item $2^A$, the type of sets, has change actions
    $\cstruct{2^A}{2^A}{\cup}$, $\cstruct{2^A}{2^A}{\cap}$, as well as
    the combination of these which we will see in \cref{sec:booleanAlgebras}.
  \item $\cstr{\NN} \defeq \cstruct{\NN}{\NN}{+}$, the natural numbers with
    itself as the change set under the additive monoid.
\end{itemize}

Many other notions in computer science can be understood in terms of change actions, \emph{e.g.} databases
and database updates, files and diffs, Git repositories and commits, even video compression
algorithms that encode a frame as a series of changes to the previous frame.

\subsection{Derivatives}

When we do incremental computation we are usually trying to save ourselves some
work. We have an expensive function $f: A \rightarrow B$, which we've evaluated at some point
$a$. Now we are interested in evaluating $f$ after some change to $a$,
$\change{a}$, but ideally we want to avoid actually computing $f(a \cplus
\change{a})$ directly.

A solution to this problem is a function $\derive{f}: A \times \changes{A}
\rightarrow \changes B$, which given $a$ and $\change{a}$ tells us how to change
$f(a)$ to $f(a \cplus \change{a})$. We call this a \emph{derivative} of a function.

\begin{defn}[Derivatives]
  \label{def:derivative}
  A \emph{derivative} of a function $f: \cstr{A} \rightarrow \cstr{B}$ is a function $\derive{f}: A \times \changes{A} \rightarrow
  \changes{B}$ such that
  \begin{displaymath}
    f(a \cplus_A \change{a}) = f(a) \cplus_B \derive{f}(a, \change{a})
  \end{displaymath}

  A function which has a derivative is 
  \emph{differentiable}.\footnote{Note that we do not require that $\derive{f}(a,
    \change{a} \splus \change{b}) = \derive{f}(a, \change{a}) \splus \derive{f}(a
    \cplus \change{a}, \change{b})$. This is a natural condition, and almost all
    derivatives satisfy it, but we have not found it to be necessary so far.}
\end{defn}

Derivatives need not be unique in general, so we will speak of ``a''
derivative.\footnote{In several places we will need to pick an arbitrary
  derivative for some construction. In general this needs the Axiom of Choice,
  but in most practical cases we will want to have a computable derivative
  operator for our domain, which alleviates the problem.} A ``thin'' change
action \textemdash{} where $a \cplus \change{a} = a \cplus \change{b}$ implies $\change{a} =
\change{b}$ \textemdash{} has unique derivatives, but many change actions are not thin.
For example, because $\{0\} \cap \{1\} = \{0\}
\cap \{2\}$, $\cstruct{\mathcal{P}(\NN)}{\mathcal{P}(\NN)}{\cap}$ is not thin.

Derivatives capture the structure of incremental computation, but there are
important operational considerations that affect whether they actually save us
any work. As we will see in a moment (\cref{prop:minusDerivatives}), for many change actions we will always have the option
of picking the ``worst'' derivative which says ``compute $f(a \cplus \change{a})$
directly and then work out how to get there from $f(a)$''. While this is a correct
derivative, it certainly does not save us any work! We will be concerned at
various points with both the possibility of constructing correct derivatives
(\cref{sec:booleanAlgebras} and \cref{sec:fixpoints} in particular), and also in
giving ourselves a range of derivatives to choose from so that we can soundly
optimize for operational value.

For our Datalog case study, we are going to want a good derivative of the semantics of
Datalog. As we will see later (\cref{sec:nonRecursiveDatalog},
\cref{sec:recursiveDatalog}), we can get good deriviatives for both the
non-recursive and the full, recursive, semantics of Datalog.

\subsection{Useful facts about change actions and derivatives}

\subsubsection{The Chain Rule}

The derivative of a function can be computed compositionally, because derivatives satisfy the standard chain rule.

\begin{thm}[The Chain Rule]
  Let $f: \cstr{A} \rightarrow \cstr{B}$, $g: \cstr{B} \rightarrow \cstr{C}$ be differentiable functions. Then $g \circ f$ is also
  differentiable, with derivative given by
  \begin{displaymath}
    \derive{(g \circ f)}(x, \change{x}) = \derive{g}\left(f(x), \derive{f}(x, \change{x})\right)
  \end{displaymath}
  or, in curried form
  \begin{displaymath}
    \derive{(g \circ f)}(x) = \derive{g}(f(x)) \circ \derive{f}(x)
  \end{displaymath}
\end{thm}

\subsubsection{Complete change actions and minus operators}

Complete change actions are an important class of change actions, because they
have changes between \emph{any} two values in the base set.

\begin{defn}[Complete change actions]
  A change action is \emph{complete} if for any $a, b \in A$, there is
  a change $\change{a} \in \changes{A}$ such that $a \cplus \change{a} = b$.
\end{defn}

Complete change actions have convenient ``minus operators'' that allow us to
compute the difference between two values.

\begin{defn}[Minus operator]
  A \emph{minus operator} is a function $\cminus: A \times A \rightarrow
  \changes{A}$ such that $a \cplus (b \cminus a) = b$ for all $a, v \in A$.
\end{defn}

\begin{prop}[Completeness equivalences]
  Let $\cstr{A}$ be a change action. Then the following are equivalent:
  \begin{itemize}
    \item $\cstr{A}$ is complete.
    \item There is a minus operator on $\cstr{A}$.
    \item Any function $f: \cstr{B} \rightarrow \cstr{A}$ is differentiable.
  \end{itemize}
\end{prop}

This last property is of the utmost importance, since we are often concerned with the differentiability
of functions.

\begin{prop}[Minus derivative]
  \label{prop:minusDerivatives}
  Given a minus operator $\cminus$, and a function $f$, let
  \begin{displaymath}
    \derive{f}_\cminus(a, \change{a}) \defeq f(a \cplus \change{a}) \cminus f(a)
  \end{displaymath}

  Then $\derive{f}_\cminus$ is a derivative for $f$.
\end{prop}

\subsubsection{Products and sums}

Given change actions on sets $A, B$, the question immediately arises of whether there are
change actions on their Cartesian product $A \times B$ or disjoint union $A + B$. While there are
many candidates, there is a clear ``natural'' choice for both.

\begin{prop}[name=Products, restate=products]
  \label{prop:products}
  Let $\cstr{A} = \cstruct{A}{\changes{A}}{\cplus_A}$ and $\cstr{B} =
  \cstruct{B}{\changes{B}}{\cplus_B}$ be change actions,
  and let $\cplus_{\times} : (A \times B) \times (\changes A \times \changes B)$ be defined by
  \begin{align*}
    (a, b) \cplus_{A \times B} (da, db) \defeq (a \cplus_A da, b \cplus_B db)
  \end{align*}

  Then $\cstr{A} \times \cstr{B} \defeq \cstruct{A \times B}{\changes{A} \times
  \changes{B}}{\cplus_{\times}}$ is a change action, and the projection
maps $\pi_1$,$\pi_2$
  are differentiable with respect to it.

  Furthermore, a function 
  $f : A \times B \into C$ is differentiable as a map from $\cstr{A} \times \cstr{B}$ into $\cstr{C}$ if
  and only if, for every  (fixed) $a \in A$ and $b \in B$, the partially applied functions 
  \begin{align*}
    f(a, \cdot) : B \into C\\
    f(\cdot, b) : A \into C
  \end{align*}
  are differentiable.

\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:products}.
\end{proof}
\fi

\todomario{Move this, rewrite}
\begin{prop}[name=Coproducts, restate=coproducts]
  \label{prop:coproducts}
  Let $\cstr{A} = \cstruct{A}{\changes{A}}{\cplus_A}$ and $\cstr{B} =
  \cstruct{B}{\changes{B}}{\cplus_B}$ be change actions.

  Then $\cstr{A} + \cstr{B} \defeq \cstruct{A + B}{\changes{A} \times
  \changes{B}}{\cplus_{+}}$ is their categorical coproduct, and the injection
maps $i_1$, $i_2$ are differentiable with $\cplus_{+}$ defined as:
  \begin{align*}
    i_1 a \cplus_{+} (\change{a}, \change{b}) &\defeq \iota_1 (a \cplus_A \change{a})\\
    i_2 b \cplus_{+} (\change{a}, \change{b}) &\defeq \iota_2 (b \cplus_B \change{b})
  \end{align*}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:coproducts}.
\end{proof}
\fi

\section{Posets and Boolean algebras}
\label{sec:moreStructures}

The semantic domain of Datalog is a complete Boolean algebra, and so our first step needs
to be to construct a good change action for Boolean algebras. Along the way, we
will consider change actions over posets, which give us the ability to
\emph{approximate} derivatives, which will turn out to be very important in practice.

\subsection{Posets}

Ordered sets give us an interestingly constrained class of functions: monotone
functions. We can define \emph{ordered} change actions, which are those that
are well-behaved with respect to the order on the underlying set.
\footnote{If we were giving a presentation that was
generic in the base category, then this would simply be the definition of being
a change action in the category of posets and monotone maps.}

\begin{defn}[Ordered change actions]
  A change action $\cstr{A}$ is \emph{ordered} if
  \begin{itemize}
    \item $A$ and $\changes{A}$ are posets.
    \item $\cplus$ and $\splus$ are monotone in both arguments.
  \end{itemize}
\end{defn}

In fact, any change action whose base set is a poset induces a particularly convenient partial order
on the corresponding change set:

\begin{defn}[Change order]
  $\change{a} \changeOrder \change{b}$ iff for all $a \in A$ it is the case that $a \cplus \change{a} \leq a \cplus \change{b}$.
\end{defn}

\begin{prop}
  Let $\cstr{A}$ be a change action on a set $A$ equipped with a partial order $\leq$ such that
  $\cplus$ is monotone in its first argument. Then $\cstr{A}$ is an ordered change action when
  $\changes{A}$ is equipped with the partial order $\changeOrder$.
\end{prop}

In what follows, we will abuse the notation and extend the partial order $\changeOrder$ on some change
set $\changes{B}$ pointwise to functions from some $A$ into $\changes{B}$. This pointwise
order interacts nicely with derivatives, in that it gives us the following lemma:

\begin{thm}[Sandwich lemma]
  \label{thm:sandwich}
  Let $\cstr{A}$ be an change action, $\cstr{B}$ be an ordered change action,
  $f: \cstr{A} \rightarrow \cstr{B}$, and $g: A \time \changes{A} \rightarrow
  \changes{B}$. If $\supderive{f}$ and $\subderive{f}$ are
  derivatives for $f$ such that

  \begin{displaymath}
    \supderive{f} \changeOrder g \changeOrder \subderive{f}
  \end{displaymath}

  then $g$ is a derivative for $f$.
\end{thm}

If unique minimal and maximal derivatives exist, then this gives us a full
characterisation of all the derivatives for a function.

\begin{thm}[Characterization of derivatives]
\label{thm:derivativeCharacterization}
  Let $\cstr{A}$ and $\cstr{B}$ be change actions, with $\cstr{B}$ ordered, and let
  $f: \cstr{A} \rightarrow \cstr{B}$ be a function. If there exist $\subderiveM{f}$ and
  $\supderiveM{f}$ which are unique minimal and maximal derivatives of $f$,
  respectively, then the derivatives of $f$ are precisely
  the functions $\derive{f}$ such that
  \begin{displaymath}
    \subderiveM{f} \changeOrder \derive{f} \changeOrder \supderiveM{f}
  \end{displaymath}
\end{thm}
\ifproofs
\begin{proof}
  Follows easily from \cref{thm:sandwich} and minimality/maximality.
\end{proof}
\fi

This theorem gives us the leeway that we need when trying to pick a derivative: we can pick out the
bounds, and that tells us how much ``wiggle room'' we have above and below.

\subsubsection{Precision}

The change preorder corresponds to a natural notion of precision: if $\change{a}
\changeOrder \change{b}$, then $\change{b}$ produces ``bigger'' updates than
$\change{a}$, and there is some additional information in it that is being
ignored even when $c \cplus \change{a} = c \cplus \change{b}$.

For example, in $\cstruct{2^A}{2^A}{\cup}$, $\{1\} \changeOrder \{1,2\}$. Even
though $\{2\} \cplus \{1\} = \{2\} \cplus \{1,2\} = \{1,2\}$, the second change is
imprecise because it adds in 2 even though it was already present.

\begin{defn}[Precision of derivatives]
  \label{def:precision}
  A derivative is precise if it is minimal with respect to $\changeOrder$.
\end{defn}

This gives us a sense in which \cref{thm:derivativeCharacterization} is an
\emph{approximation} theorem \textemdash{} it lets us pick out a sound range of
derivatives bounded below by a precise derivative. This means we can trade off
precision for other desirable operational properties, such as how easy the
derivative is to compute.

\subsection{Boolean algebras}
\label{sec:booleanAlgebras}

Complete Boolean algebras are of special interest to us due to their role in modelling the semantics of
Datalog programs. Conveniently, these structures have a complete change action.

\begin{prop}[name=Boolean algebra change actions, restate=lsuperpose]
 Let $L$ be a complete Boolean algebra. Define
  \begin{displaymath}
    \cstr{L}_\superpose \defeq \cstruct{L}{L \disjointTimes L}{\twist}
  \end{displaymath}
  where
  \begin{align*}
    A \disjointTimes B &\defeq \{ (a, b) \in A \times B \mid a \wedge b = \bot \}\\
    a \twist (p, q) &\defeq (a \vee p) \wedge \neg q
  \end{align*}
  and the monoid operator is
  \begin{displaymath}
    (p, q) \splus (r, s) \defeq ((p \wedge \neg s) \vee r, (q \wedge \neg r) \vee s)
  \end{displaymath}
  with identity element $(\top, \bot)$.

  Then $\cstr{L}_\superpose$ is a complete change action on $L$.
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:lsuperpose}.
\end{proof}
\fi

We can think of $\cstr{L}_\superpose$ as tracking changes as pairs of ``upwards'' and
``downwards'' changes, where the monoid action simply applies one after the
other, with an adjustment to make sure that the components remain disjoint.\footnote{
  The intuition that $\cstr{L}_\superpose$ is made up of an ``upwards''
  and a ``downwards'' change action glued together can in fact be made precise, but the specifics
  are outside the scope of this paper.}

Boolean algebras also have unique maximal and minimal
derivatives, under the usual preorder based on implication.\footnote{The change
set is, as usual, given the change preorder, which in this case corresponds to
the natural order on $L \times L^{\textrm{op}}$.}

\begin{prop}
  \label{prop:minimalMaximalDerivatives}
  Let $L$ be a (complete) Boolean algebra with the $\cstr{L}_\superpose$ change action, and
  $f: A \rightarrow L$ a function.
  Define minus operators
  \begin{align*}
    a \cminus_\bot b &= (a \wedge \neg b, \neg a)\\
    a \cminus_\top b &= (a, b \wedge \neg a)
  \end{align*}

  Then $\derive{f}_{\cminus_{\bot}}$ and $\derive{f}_{\cminus_{\top}}$ 
  define least and greatest derivatives for $f$.
\end{prop}

\Cref{thm:derivativeCharacterization} then gives us bounds for
all the derivatives on Boolean algebras:

\begin{corollary}
\label{cor:booleanCharacterization}
  Let $L$ be a (complete) Boolean algebra with the corresponding change action
  $\cstr{L}_\superpose$, $A$ be an arbitrary change action, and $f: A \rightarrow
  L$ be a function. Then the derivatives of $f$ are precisely those functions
  $\derive{f}: A \time \changes{A} \rightarrow \changes{A}$ such that
  \begin{displaymath}
    \derive{f}_{\cminus_{\bot}}
    \changeOrder
    \derive{f}
    \changeOrder
    \derive{f}_{\cminus_{\top}}
  \end{displaymath}
\end{corollary}

This makes \cref{thm:derivativeCharacterization} actually usable in practice, since
we have concrete definitions for our bounds (which we will make use of in \cref{sec:datalogDifferentiability}).

\section{Derivatives for non-recursive Datalog}
\label{sec:nonRecursiveDatalog}

We now want to apply the theory we have developed to the specific case of the semantics
of Datalog. Giving a semantics for Datalog that admits derivatives will then
naturally lead us to a strategy for performing incremental evaluation and maintenance of Datalog programs. 
To begin with, we will restrict ourselves to the non-recursive fragment of the language, and we will tackle
fixpoints in a later section (\cref{sec:recursiveDatalog}).

Although the techniques we are using should work for any language, Datalog
provides a non-trivial case study where the need for incremental computation is
real and pressing, as we saw in \cref{sec:intro}.

\subsection{Semantics of Datalog formulae}

Datalog is usually given a logical semantics where formulae are interpreted as first-order
logic predicates and the semantics of a program is the set of models of its constituent
predicates. We will instead give a simpler denotational semantics that treats a Datalog
formula (and later, a Datalog program) as directly denoting a family of relations.

We will adopt the usual closed-world assumption to give a denotation to negation.

\begin{defn}[Closed-world assumption and negation]
  There exists a universal relation $\universalRel$.

  Negation on relations is defined as
  \begin{displaymath}
    \neg R \defeq \universalRel \setminus R
  \end{displaymath}
\end{defn}

This makes $\Rel$, the set of all relations over $\universalRel$, into a
complete Boolean
algebra.\footnote{Technically we need to use the set of relations of a given
  arity. In practice it is easy to make the arities match up, and we will gloss
  over them for clarity.}

The semantics of Datalog formulae are usually given in terms of satisfaction by
structures. We would like to use a more denotational semantics (as is typical
when working with fixpoints \autocite[see e.g.][]{compton1994stratified}). We are
going to parameterize by the parts of the structure that are usually variable,
namely the assignments to variables and relation variables. We will assume we
are otherwise working in the context of an ambient structure $\Phi$ that
provides our universe and interpretation of constants.

\begin{defn}[Formula semantics]
  A Datalog formula $T$ denotes a function from its free relation variables to
  $\Rel$.
  \begin{align*}
    &\denote{\_} : \Formula \rightarrow \Rel^n \rightarrow \Rel\\
    &\denote{T}(R_1, \dots, R_n) = \left\{ \left(a_1, \dots a_m \right) \mid \Phi \models T\left[R_1, \dots R_n, a_1, \dots a_m \right] \right\}
  \end{align*}
\end{defn}

Since $\Rel$ is a complete Boolean algebra, and so is $\Rel^n$, $\denote{T}$ is
a function between complete Boolean algebras.

\subsection{Differentiability of Datalog formula semantics}
\label{sec:datalogDifferentiability}

In order to perform incremental evaluation, we first need to provide derivatives for the semantics
of Datalog formulae. Since $\denote{T}$ is a function between the complete Boolean algebras $\Rel^n$ and
$\Rel$, and we know that the corresponding change actions 
$\widehat{\Rel^n}_\superpose, \widehat{\Rel}_\superpose$
are complete, this immediately guarantees the existence of a derivative for $\denote{T}$.

Unfortunately, this does not necessarily provide us with a way to compute an \emph{efficient} 
derivative for $\denote{T}$. The precise derivative that we know how to compute relies on
a minus operator:
\begin{displaymath}
  \derive{f}_{\cminus_\bot}(a, \change{a}) = f(a \cplus \change{a}) \cminus_\bot f(a)
\end{displaymath}

Naively computed, this expression requires computing $f(a \cplus \change{a})$
itself, which is the very thing we were trying to avoid computing!

Of course, given a concrete definition of $\cminus_\bot$ we can simplify this
expression and hopefully make it easier to compute. But we also know from
\cref{cor:booleanCharacterization} that \emph{any} function bounded by
$\derive{f}_{\cminus_\bot}$ and $\derive{f}_{\cminus_\top}$ is a valid derivative,
and we can therefore weaken our derivative within that range to make a 
trade-off between ease of computation and precision.

In the case of Datalog, the change preorder on the change action also
corresponds to the size of the derivative as a pair of relations. The minimal (precise)
derivative contains only the elements that are newly added or removed,
whereas the maximal derivative contains all the elements that have \emph{ever}
been added or removed but not re-added. This means that \cref{cor:booleanCharacterization} allows
us to \emph{approximate} the precise derivative while still being
guaranteed that the result is sound.\footnote{The idea of using an approximation
to the precise derivative, and a soundness condition, appears in \textcite{bancilhon1986amateur}.}

There is also the question of how to compute the derivative. Since the change
set for $\widehat{\Rel}_\superpose$ is a subset of $\Rel \times \Rel$, it
is possible and indeed very natural to compute the two components via a pair of
Datalog formulae, which allows us to reuse an existing Datalog formula
evaluator.\footnote{
  Indeed, if this process is occurring in an optimizing compiler,
  the derivative formulae can themselves be optimized. This is very 
  beneficial in practice, since the initial formulae may be quite complex.}

This does give us additional constraints that the derivative formulae must satisfy:
for example, we need to be able to evaluate them; and we may wish to pick formulae that will be easy or cheap
for our evaluation engine to compute, even if they compute a less precise derivative.

The upshot of these considerations is that the optimal choice of derivatives is likely
to be quite dependent on the precise variant of Datalog being evaluated, and the
specifics of the evaluation engine. Here is one possibility.\footnote{This is
  the derivative actually in use at Semmle. We arrived at it by starting with the
  minimal derivative and then simplifying and weakening it while preserving the
  soundness bound given by the maximal derivative.}

\subsubsection{A concrete Datalog formula derivative}

We define here a ``symbolic'' derivative operator as a pair of mutually recursive functions,
$\updiff$ and $\downdiff$, which turn a formula $T$ into new formulae that compute
the upwards and downwards parts of the derivative, respectively. As we expect
from a derviative, the new formulae will have additional free relation variables
for the upwards and downwards derivatives of the free relation variables of $T$.

\newcommand{\bothdiff}{\diamond}

We will make use of an auxilliary function, $\bothdiff$, which computes the
``next'' value of a term by applying the upwards and downwards derivatives.

\newcommand{\bothchanges}{\rho}
\begin{thm}[Concrete Datalog formula derivatives]
\label{thm:concreteDatalog}
  Let $\updiff, \downdiff, \bothdiff : \Formula \rightarrow \Formula$ be mutually recursive functions
  defined by structural induction as in \cref{fig:datalogDerivatives}

  Then for any Datalog formula $T$, 
  $\derive{\denote{T}} \defeq (\denote{\updiff(T)}, \denote{\downdiff(T)})$
  is a derivative for $\denote{T}$.
\end{thm}
\ifproofs
\begin{proof}
  Straightforward structural induction.
\end{proof}
\fi

\begin{figure}
  \fbox{
    \begin{minipage}[t]{0.9\textwidth}
    \begin{minipage}[t]{.45\textwidth}
      \begin{align*}
        \updiff(\bot) \defeq& \bot\\
        \updiff(\top) \defeq& \bot\\
        \updiff(R_j) \defeq& \updiff R_j \\
        \updiff(T\vee U) \defeq& \updiff(T) \vee \updiff (U) &(\dagger)\\
        \updiff(T\wedge U) \defeq& (\updiff(T)\wedge \bothdiff(U))\\
                            & \vee (\updiff(U) \wedge \bothdiff(T))\\
        \updiff(\neg T) \defeq& \downdiff(T)\\
        \updiff(\exists x.T) \defeq& \exists x.\updiff(T) &(\dagger)
      \end{align*}
    \end{minipage}\hfill\noindent
    \begin{minipage}[t]{.45\textwidth}
      \begin{align*}
        \downdiff(\bot) \defeq& \bot\\
        \downdiff(\top) \defeq& \bot\\
        \downdiff(R_j) \defeq& \downdiff R_j \\
        \downdiff(T\vee U) \defeq& (\downdiff(T) \wedge \neg \bothdiff(U))\\
                              & \vee (\downdiff(U) \wedge \neg \bothdiff(T))\\
        \downdiff(T\wedge U) \defeq& (\downdiff(T)\wedge U) \vee (T \wedge \downdiff(U))\\
        \downdiff(\neg T) \defeq& \updiff(T)\\
        \downdiff(\exists x.T) \defeq& \exists x.\downdiff(T) \wedge \neg \exists x.\bothdiff(T)
      \end{align*}
    \end{minipage}
    \vspace{12pt}
    \begin{align*}
      \bothdiff(X) \defeq X \twist (\updiff(X), \downdiff(X))
    \end{align*}
    \end{minipage}
  }
  \caption{Upwards and downwards formula derivatives for Datalog}
  \label{fig:datalogDerivatives}
\end{figure}

There is a symmetry between the cases for $\wedge$ and $\vee$ between $\updiff$
and $\downdiff$, but the cases for $\exists$ look quite different.
This is because our dialect of Datalog does not have a primitive universal quantifier.
If we did have one, its cases would be dual to those for $\exists$, namely:
\begin{align*}
\updiff(\forall x.T) &= \exists x. \updiff(T) \wedge \forall x. \bothdiff(T)\\
\downdiff(\forall x.T) &= \exists x. \downdiff(T)
\end{align*}

We can now give a derivative for our $treeP$ predicate (assuming only changes to
$treeP$ itself):
\begin{align*}
  \updiff(treeP(x)) \leftarrow & p(x)\\
    &\wedge
    \exists y. (
      child(x, y)
      \wedge
      \updiff(treeP(y))
    )\\
    &\wedge 
    \neg \exists y. (
      child(x, y)
      \wedge
      \neg \bothdiff(treeP(y))
    )\\
  \downdiff(treeP(x)) \leftarrow & p(x)\\
  &\wedge \exists y. \left( child(x, y) \wedge \downdiff(treeP(y)) \right)
\end{align*}

The upwards difference in particular is not especially easy to compute. If we naively compute it, the
third conjunct requires us to recompute the whole of the recursive part. However,
the second conjunct gives us a
guard: we only need to evaluate the third conjunct if the second conjunct is
non-empty, i.e there is \emph{some} change in the body of the existential.

This shows that our derivatives aren't a panacea: it is simply \emph{hard} to compute
downwards differences for $\exists$ (and, equivalently, upwards differences for
$\forall$) because we must check that there is no other way of deriving the same
facts.\footnote{The ``support'' data structures introduced by
  \autocite{gupta1993maintaining} are an attempt to avoid this issue by
  tracking the number of derivations of each tuple.} However, we can still avoid
the re-evaluation in many cases, and the inefficiency is local to this subformula.

\subsubsection{Precision}

In practice, while the derivative given in \cref{thm:concreteDatalog} is not
precise, most of the cases are \emph{preciseness-preserving}, in that if the
subsidiary recursive cases are precise, then so is that case. The only cases
which lose precision are labelled with $\dagger$.

\subsection{Extensions to Datalog}
\label{sec:extensions}

Our formulation of Datalog formula semantics and incremental evaluation is 
generic and modular, so it is easy to extend the language with new
formula constructs: all we need to do is add cases for $\updiff$ and $\downdiff$.

In fact, because we are using a complete change action, we can \emph{always} do this by using the maximal or
minimal derivative. This justifies our claim that we can support
\emph{arbitrary} additional formula constructs: although the maximal and minimal
derivatives are likely to be impractical, having them
available as options means that we will never be completely stymied.

This is important in practice for Semmle's variant of Datalog. For example, the
upwards derivative for recursive aggregates \autocite{demoor2013aggregates} is:
\begin{align*}
  \updiff(\textrm{agg}(vs \mid T \mid U)) \defeq \exists vs. (T \wedge \updiff{U}) \wedge \textrm{agg}(vs \mid T \mid U)
\end{align*}

While this isn't a precise derivative, it is still substantially cheaper than
re-evaluating the whole subfomula, as the guard allows us to skip the second conjunct when $U$
has not changed.

\section{Changes on functions}

We would like to be able to impose a change action structure on function spaces. This will enable us
to discuss derivatives in the context of higher-order languages, but in particular derivatives for
fixpoint operators, which are best thought of as higher-order functions 
$\fixpoint : (A \rightarrow A) \rightarrow A$. 

\todomario{Back-references}
Function spaces, however, differ from products and coproducts in that there is no obvious choice
of a ``best'' change action structure on $A \rightarrow B$, given change actions $\cstr{A}, \cstr{B}$.
Instead of settling on a concrete choice of a change action, we restrict ourselves to working
with change actions that respect the structure of the function space in the following sense:

\begin{defn}[Functional change actions]
  \label{def:functionalChanges}
  Given change actions $\cstr{A}, \cstr{B}$ and a set $U \subseteq A \rightarrow B$, a change action
  $(U, \changes U, \cplus)$ is functional whenever the evaluation map $\ev : U \times A \rightarrow B$
  is differentiable, that is to say, whenever there exists a function 
  $\ev' : (U \times A) \times (\changes U \times \changes A)$ such that:
  \begin{displaymath}
    (f \cplus \change{f})(a \cplus \change{a}) = f(a) \cplus \derive{\ev}((f, a), (\change{f}, \change{a}))
  \end{displaymath}
  
  We will write $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$ whenever 
  $U \subseteq A \rightarrow B$ and $\cstr{U}$ is functional.
\end{defn}

We have defined functional change actions on arbitrary subsets $U \subseteq A \rightarrow B$ for two
reasons. First, it will later allow us to restrict ourselves to spaces of monotone or continuous
functions. But more importantly, functional change actions are necessarily made up of differentiable
functions, and thus a functional change action may not exist for the entire function space
$A \rightarrow B$.

\begin{prop}[Differentiability and functional change actions]
  \label{prop:differentiableFunctionalChanges}
  Let $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$ be a functional change action. Then every 
  $f : U$ is differentiable, with a derivative $f'$ given by:
  \begin{displaymath}
    f'(x, dx) = \ev'((f, x), (0, dx))
  \end{displaymath}
\end{prop}

Conversely, the derivative of the evaluation map can also be used to compute the effect of a given
function change $\delta f$:
\begin{prop}[Evaluating function changes]
  Let $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$. Then for every $f : U, \delta f : \changes U$
  we have:
  \begin{displaymath}
    (f \cplus \delta f)(x) = f(x) \cplus \ev'((f, x), (\delta f, 0))
  \end{displaymath}
\end{prop}

\todomario{
  There's a classification theorem here, but it's a bit tricky, I'll get around to it eventually.
}
\iffalse
The nature of functional change actions can be quite varied (we will introduce concrete examples later),
but the previous result shows they can all be classified up to (differentiable) isomorphism:
\begin{prop}[Functional change sets]
  Let $\cstr{A}, \cstr{B}$ be change actions and $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$
  a functional change action. First, we note that the set $U \times A \rightarrow \Delta B$ can be
  considered as a monoid with addition $+_\Rightarrow$ and neutral element $0_\Rightarrow$ defined by:
  \begin{align*}
    (\upsilon f +_\Rightarrow \upsilon g)(h, x) 
    &\defeq \upsilon f (f, x) + \upsilon g((\lambda x . \upsilon f (h, x)) , x)
  \end{align*}

  Every functional change action $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$ is equivalent to
  a (functional) change action of the form $(U, W, \cplus_\Rightarrow)$ where:
  \begin{itemize}
  \item $U \times A \rightarrow \Delta B$ is considered as a monoid with
  \item $W$ is the sub-monoid of 
  \end{itemize}
  \begin{align*}
    V &\subseteq (A \rightarrow B) \times A \rightarrow \Delta B\\
    V &\defeq \{~
      \lambda f. \lambda x. \ev'((f, x), (\delta f, 0)) ~|~ \delta f \in \changes U
    ~\}\\
    (f \cplus_\Rightarrow \upsilon f)(x) &\defeq f(x) \cplus \upsilon f(f, x)
  \end{align*}
\end{prop}
\fi

\subsection{Pointwise functional change actions}

As we shall see later in \cref{sec:category}, one can always find functional change actions on the set
of differentiable functions $\cstr{A} \rightarrow_\cplus \cstr{B}$, but these can be unwieldy for 
the purpose of actual computation. In general it's hard to find convenient presentations of such
actions. A relatively large family of change actions, however, give rise to a particularly simple
way of representing spaces of differentiable functions into them.

\begin{defn}[Pointwise functional change actions]
  Let $\cstr{A}, \cstr{B}$ be change actions. The pointwise functional change action 
  $\cstr{A} \Rightarrow \cstr{B}$, when it is defined,
  is given by $(\cstr{A} \rightarrow_\cplus \cstr{B}, A \rightarrow \changes{B}, \cplus_\rightarrow)$, with
  the monoid structure $(A \rightarrow \changes{B}, \splus_\rightarrow, 0_\rightarrow)$ and the action 
  $\cplus_\rightarrow$ defined by:
  \begin{align*}
    (f \cplus \delta f)(x) &\defeq f(x) \cplus \delta_B f\\
    (\delta f \splus_\rightarrow \delta g)(x) &\defeq \delta f(x) \splus_B \delta g(x)\\
    0_\rightarrow (x) &\defeq 0_B
  \end{align*}
\end{defn}

The above definition isn't always well-typed, since given $f : \cstr{A} \rightarrow_\cplus \cstr{B}$ and
$\delta f : A \rightarrow \changes{B}$ there is, in general, no guarantee that 
$f \cplus_\rightarrow \delta f$ is differentiable. We present two simple criteria that enforce this:

\begin{thm}[Pointwise functional change actions]
  Let $\cstr{A}, \cstr{B}$ be change actions, and suppose that $\cstr{B}$ satisfies one of the
  following conditions:
  \begin{itemize}
    \item $\cstr{B}$ is a complete change action.
    \item The monoidal change action $\widehat {\changes{B}} \defeq (\Delta B, \Delta B, \splus_B)$ is 
      complete and 
      $\cplus_B$ is differentiable as a map from $\cstr{B} \times \widehat{\changes{B}}$ into $\cstr{B}$
  \end{itemize}
  
  Then the pointwise functional change action 
  $(\cstr{A} \rightarrow_\cplus \cstr{B}, A \rightarrow \changes{B}, \cplus_\rightarrow)$ is well defined.
  \footnote{
    These conditions are sufficient, but not necessary, to guarantee the well-formedness of the
    pointwise change action exist; A more complete account of when pointwise function change actions
    are applicable has resulted vastly more complex and is entirely outside the scope of this paper.
  }
\end{thm}

These pointwise change actions are, furthermore, functional in the sense of 
\cref{def:functionalChanges}. What's more, the derivative of the evaluation map is quite easy to 
compute.
\begin{prop}[Derivatives of the evaluation map]
\label{prop:evDerivatives}
  Let $\cstr{A}, \cstr{B}$ be change actions such that the pointwise functional change action
  $\cstr{A} \Rightarrow \cstr{B}$ is well defined, and let
  $f: \cstr{A} \rightarrow_\cplus \cstr{B}$,
  $a \in A$, $\change{a} \in \changes{A}$,
  $\change{f} \in A \rightarrow \changes{B}$.

  Then, by taking a derivative of $f$ we obtain the following derivative for the evaluation map:
  \begin{displaymath}
    \derive{\ev}_1((f, a), (\change{f}, \change{a})) \defeq \derive{f}(a, \change{a}) \splus \change{f}(a \cplus \change{a})
  \end{displaymath}

  Alternatively, by taking a derivative of $f \cplus \change{f}$ we can obtain another derivative
  for the evaluation map:
  \begin{displaymath}
    \derive{\ev}_2((f, a), (\change{f}, \change{a})) \defeq \change{f}(a) \splus \derive{(f \cplus \change{f})}(a, \change{a})
  \end{displaymath}
\end{prop}

\section{Directed-complete partial orders and fixpoints}

An important class of posets, particularly relevant to programming language semantics, is that of 
directed-complete partial orders (dcpos) equipped with a least element, and the associated notion of \emph{(Scott) continuous} maps. 

\subsection{Dcpos}
\label{sec:dcpos}

As before, we can define change actions on dcpos, rather than sets, as change
actions whose sets $A$, $\Delta A$ are endowed with a dcpo structure, and where
the maps $\cplus$, $\splus$ are continuous.

\begin{defn}[Continuous change actions]
  A change action $\cstr{A}$ is \emph{continuous} if
  \begin{itemize}
    \item $A$ and $\changes{A}$ are dcpos.
    \item $\cplus$ and $\splus$ are Scott-continuous in both arguments.
  \end{itemize}
\end{defn}

Unlike before, the change order $\changeOrder$ does \emph{not}, in general,
induce a dcpo structure on $\changes{A}$. As a counterexample, consider 
the change action $(\overline{\NN}, \NN, +, +, 0)$, where $\overline{\NN}$ denotes the dcpo of natural numbers
extended with a positive infinity.

A key example of a continuous change action is the $\cstr{L}_\superpose$ change
action on Boolean algebras.

\begin{prop}[name=Boolean algebra continuity, restate=booleanAlgebraContinuous]
  \label{prop:booleanAlgebraContinuous}
  Let $L$ be a Boolean algebra. Then $\cstr{L}_\superpose$ is a continuous
  change action.
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:booleanAlgebraContinuous}.
\end{proof}
\fi

For a general overview of results in domain theory and dcpos, we refer the reader to an
introductory work such as \cite{abramsky1994domain}, but we state here some specific results that
we shall be using, such as the following, whose proof can be found in 
\cite[Lemma~3.2.6]{abramsky1994domain}:

\begin{prop}[Distributivity of limits across arguments]
  \label{prop:distributivityLimit}
  A function $f : A \times B \rightarrow C$ is continuous iff it is continuous in each variable
  separately.
\end{prop}

It is a well-known result in standard calculus that the limit of an absolutely convergent sequence of
differentiable functions $\{f_i\}$ is itself differentiable, and its derivative is equal to the limit
of the derivatives of the $f_i$. A remarkable consequence of the previous distributivity property
is the following analogous result:

\begin{corollary}[Continuity of differentiation]
  \label{cor:diffContinuous}
  Let $\cstr{A}$, $\cstr{B}$ be change actions, with $\cstr{B}$ continuous and let $\{f_i\}$ and $\{\derive{f_i}\}$ be
  $I$-indexed directed families of functions in $A \rightarrow B$ and $A \times \changes{A} \rightarrow \changes{B}$.

  Then, if for every $i \in I$ it is the case that $\derive{f_i}$ is a derivative of $f_i$, then $\bigsqcup_{i \in I} \derive{f_i}$ is
  a derivative of $\bigsqcup_{i \in I} f_i $.
\end{corollary}
\ifproofs
\begin{proof}
  It suffices to apply $\cplus$ and \cref{prop:distributivityLimit} to the directed families $\{ f_i(a) \}$ and
  $\{ \derive{f_i}(a, \change{a}) \}$.
\end{proof}
\fi

We also state the following additional fixpoint lemma. This is a specialization of
Becik's Theorem \autocite[][section 10.1]{winskel1993formal}, but it has a straightforward direct proof.

\begin{prop}[name=Factoring of fixpoints, restate=factoringFixpoints]
  \label{prop:factoringFixpoints}
  Let $A$ and $B$ be dcpos, $f : A \rightarrow A$ and $g: A \times B \rightarrow B$ be continuous, and let
  \begin{displaymath}
    h(a, b) \defeq (f(a), g(a, b))
  \end{displaymath}
  Then
  \begin{displaymath}
    \lfp(h) = (\lfp(f), \lfp(\lambda b . g(\lfp(f), b)))
  \end{displaymath}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:factoringFixpoints}.
\end{proof}
\fi

\subsection{Fixpoints}
\label{sec:fixpoints}

Fixpoints appear frequently in the semantics of languages with recursion. If we
can give a generic account of how to compute fixpoints using change actions,
then this gives us a compositional way of extending a derivative for the
non-recursive semantics of a language to a derivative that can handle recursion.
We will do this later to handle full recursive Datalog (\cref{sec:datalogIncr}).

\subsubsection{Iteration functions}

Over directed-complete partial orders we can define a least fixpoint operator $\lfp$ in terms of the
iteration function $\iter$:
\begin{align*}
  &\lfp : (A \rightarrow A) \rightarrow A\\
  &\lfp \defeq \bigsqcup_{n \in \NN} \iter_n \\
  &\iter : (A \rightarrow A) \times \NN \rightarrow A\\
  &\iter(f, n) \defeq f^n(\bot)
\end{align*}

The iteration function is the basis for everything in this section:
we can take the ``partial derivative'' with respect to $n$, and this will give us a way to get
to the next iteration incrementally; and we can take the partial derivative
with respect to $f$, and this will give us a way to get from iterating $f$ to iterating $f
\cplus \change{f}$.\footnote{The sharp-eyed reader may have noticed that we
  could also abstract out the point from which we begin iterating (which is of
  course typically $\bot$) and differentiate with respect to that.}

To avoid confusion, we shall write $\iter_f$ when we are holding $f$ constant,
and $\iter_n$ when we are holding $n$ constant. We will also subscript fixpoint
operators with the lattice over which they operate when it is not obvious from context.

\subsubsection{Incremental computation of fixpoints}

The following theorems provide a
generalization of semi-naive evaluation to any differentiable function over a
continuous change action. 

Since we are trying to incrementalize the iterative step, we start by taking the partial
derivative of $\iter$ with respect to $n$.

\begin{prop}[name=Derivative of the iteration map with respect to $n$, restate=iterDerivativesN]
  \label{prop:iterDerivativesN}
  Let $\cstr{A}$ be a complete change action and $f: A \rightarrow A$ differentiable. Then $\iter_f$ is differentiable, and a derivative is given by:
  \begin{align*}
    &\derive{\iter_f}: \NN \times \changes{\NN} \rightarrow \changes{A}\\
    &\derive{\iter_f}(0, m) \defeq \iter_f(m) \cminus \bot\\
    &\derive{\iter_f}(n+1, m) \defeq \derive{f}(\iter_f(n), \derive{\iter_f}(n, m))
  \end{align*}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:iterDerivativesN}.
\end{proof}
\fi

We can then compute $\derive{\iter_f}(n)$ along with $\iter_f(n)$ via mutual recursion.
We want to do this by computing a fixpoint, so we can rewrite it as a recurrence
relation:
\begin{align*}
  &\nextiter_f : A \times \changes{A} \rightarrow A \times \changes{A}\\
  &\nextiter_f (\bot, \bot) \defeq (\bot, f(\bot) \cminus \bot)\\
  &\nextiter_f (a, \change{a}) \defeq (a \cplus \change{a}, \derive{f}(a, \change{a}))
\end{align*}
Which has the property that
\begin{align*}
  &\nextiter_f^n (\bot, \bot) = (\iter_f(n), \derive{\iter_f}(n, 1))
\end{align*}

\begin{thm}[name=Incremental computation of least fixpoints, restate=fixpointIter]
\label{thm:fixpointIter}
  Let $\cstr{A}$ be a continuous change action, $f: \cstr{A} \rightarrow
  \cstr{A}$ be continuous and differentiable.

  Then $\lfp(f) = \bigsqcup_{n \in \NN}(\pi_1(\nextiter_f^n(\bot, \bot)))$.\footnote{
    Note that we have \emph{not} taken the fixpoint of $\nextiter_f$, since it is
    not continuous.}
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:fixpointIter}.
\end{proof}
\fi

This gives us a way to compute a fixpoint incrementally, by adding successive
changes to an accumulator until we reach fixpoint. This is exactly how
semi-naive evaluation works, with the delta relation and the accumulator relation.

\subsubsection{Derivatives of fixpoints}
\label{sec:fixpointDerivatives}

In the previous section we have shown how to use derivatives to compute fixpoints
more efficiently, but we also want to take the derivative of the fixpoint
operator itself. A typical use case for this is where we have some fixpoint
\begin{displaymath}
  \fixpoint (\lambda X . F(E, X))
\end{displaymath}
and we now wish to apply a change $\change{E}$ to $E$ and compute
\begin{displaymath}
  \fixpoint (\lambda X . F(E \cplus \change{E}, X))
\end{displaymath}

This amounts to applying a change to the \emph{function} whose fixpoint we are taking.

In Datalog this would allow us to update a recursively defined relation given an
update to one of its non-recursive dependencies, or the extensional database.
For example, we might want to take the transitive closure relation
and update it by changing the edge relation $e$.\footnote{See
  \cref{sec:workedExample} for a worked example of doing exactly that.}

However, this requires us to have a derivative for the fixpoint operator
$\fixpoint$ with respect to the function whose fixpoint is being taken.

\begin{defn}[Derivatives of fixpoints]
\label{def:fixpointDerivatives}
  Let $\cstr{A}$ be a change action, $\fixpoint_A$ a fixpoint operator for
  endofunctions on $A$, and $\derive{\ev}$ be a derivative of the evaluation map.
  
  Then we define
  \begin{align*}
    &\adjust : (A \rightarrow A) \times \changes{(A \rightarrow A)} \rightarrow (\changes{A} \rightarrow \changes{A})\\
    &\adjust(f, \change{f}) \defeq \lambda\ \change{a} . \derive{\ev}((f, \fixpoint_A(f)), (\change{f}, \change{a}))\\
    &\derive{\fixpoint_A} : (A \rightarrow A) \times \changes{(A \rightarrow A)} \rightarrow \changes{A}\\
    &\derive{\fixpoint_A}(f, \change{f}) \defeq \fixpoint_{\changes{A}}(\adjust(f, \change{f}))
  \end{align*}
\end{defn}

The suggestively named $\derive{\fixpoint_A}$ will in fact turn out to be a
derivative \textemdash{} for \emph{least} fixpoints. The appearance of
$\derive{\ev}$, a derivative of the evaluation map, in the definition of
$\adjust$ is also no coincidence: as evaluating a fixpoint consists of many
steps of applying the evaluation map, so computing the derivative of a fixpoint
consists of many stages of applying the derivative of the evaluatoin
map.\footnote{Perhaps surprisingly, the authors first discovered an expanded
  version of this formula, and it was only later that we realised the remarkable
  connection to $\derive{\ev}$.}

\begin{thm}[name=Pseudo-derivatives of fixpoints, restate=fixpointPseudoDerivatives]
\label{thm:fixpointPseudoDerivatives}
  Let
  \begin{itemize}
    \item $\cstr{A}$ be a change action
    \item $\fixpoint : (A \rightarrow A) \rightarrow A$ be a fixpoint operator
    \item $f: \cstr{A} \rightarrow \cstr{A}$ be a differentiable function
    \item $\change{f} \in \changes{(A \rightarrow A)}$ be a function change 
    \item $\derive{\ev}$ be a derivative of the evaluation map
  \end{itemize}
  Then $\fixpoint(f) \cplus \derive{\fixpoint}(f, \change{f})$ is a fixpoint
  of $f \cplus \change{f}$.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:fixpointPseudoDerivatives}.
\end{proof}
\fi

This is not enough to give us a true derivative, because we have only shown
that $\fixpoint(f) \cplus \derive{\fixpoint}(f, \change{f})$ computes \emph{a} fixpoint, not necessarily
the same one computed by $\fixpoint{(f \cplus \change{f})}$.

However, if we restrict ourselves to directed-complete partial orders, least
fixpoints, and continuous change actions, then $\derive{\lfp}$ (using the
derivative definition from \cref{def:fixpointDerivatives}) \emph{is} a
derivative of $\lfp$. This is not too onerous a restriction, since this is
the setting in which we normally compute fixpoints anyway.

Since $\lfp$ is characterized as the limit of a chain of functions,
\cref{cor:diffContinuous} suggests a way to compute its derivative. If we can find a derivative
$\derive{\iter_n}$ of each iteration map 
such that the resulting set $\{ \derive{\iter_n} \mid n \in \NN\}$ is directed, then $\bigsqcup_{n \in \NN}\derive{\iter_n}$ will be a derivative of $\lfp$.

These correspond to the other derivative of $\iter$ \textemdash{} this time with respect to
$f$. While we are differentiating with respect to $f$, we are still going to
need to define our derivatives inductively in terms of $n$.

\begin{prop}[name=Derivative of the iteration map with respect to $f$, restate=iterDerivativesF]
  \label{prop:iterDerivativesF}
  $\iter_n$ is differentiable and a derivative is given by:
  \begin{align*}
    &\derive{\iter_n} : (A \rightarrow A) \times \changes{(A \rightarrow A)} \rightarrow \changes{A}\\
    &\derive{\iter_0} (f, \change{f}) \defeq \bot_{\changes{A}}\\
    &\derive{\iter_{n+1}} (f, \change{f}) \defeq \derive{\ev}((f, \iter_n(f)), (\change{f}, \derive{\iter_n}(f, \change{f})))
  \end{align*}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:iterDerivativesF}.
\end{proof}
\fi

As before, we can now compute $\derive{\iter_n}$ together with $\iter_n$ by
mutual recursion.\footnote{
  In fact, the recursion here is not \emph{mutual}: the first component does not
  depend on the second. However, writing it in this way makes it
  amenable to computation by fixpoint, and we will in fact be able to avoid the
  recomputation of $\iter_n$ when we show that it is equivalent to $\derive{\lfp}$.
}
\begin{align*}
  &\nextiter_{f, \change{f}} : A \times \changes{A} \rightarrow A \times \changes{A}\\
  &\nextiter_{f, \change{f}} (a, \change{a}) \defeq (f(a), \derive{\ev}((f, a), (\change{f}, \change{a})))
\end{align*}
Which has the property that
\begin{align*}
  &\nextiter_{f, \change{f}}^n (\bot, \bot) = (\iter_n(f), \derive{\iter_n}(f, \change{f}))
\end{align*}

This indeed provides us with a function whose limit we can take, showing
that $\derive{\lfp}$ is a true derivative.

\begin{thm}[name=Derivatives of least fixpoint operators, restate=leastFixpointDerivatives]
  \label{thm:leastFixpointDerivatives}
  Let
  \begin{itemize}
    \item $\cstr{A}$ be a continuous change action
    \item $f : \cstr{A} \rightarrow \cstr{A}$ be a continuous, differentiable function
    \item $\change{f} \in A \rightarrow \changes{A}$ be a function change
    \item $\derive{\ev}$ be a derivative of the evaluation map, continuous with
      respect to $a$ and $\change{a}$.
  \end{itemize}
  Then $\derive{\lfp}$ is a derivative of $\lfp$.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:leastFixpointDerivatives}.
\end{proof}
\fi

Computing this derivative still requires computing a fixpoint \textemdash{} over the change
lattice \textemdash{} but this may still be significantly less expensive than
recomputing the full new fixpoint.

\section{Derivatives for recursive Datalog}
\label{sec:recursiveDatalog}

Given the non-recursive semantics for a language, we can extend it to handle
recursive definitions using fixpoints. \Cref{sec:fixpoints} lets us extend our
derivative for the non-recursive semantics to a derivative for the recursive
semantics, as well as letting us compute the fixpoints themselves
incrementally. 

Again, we will demonstrate the technique with Datalog, although the approach is generic.

\subsection{Semantics of Datalog programs}

First of all, we define the usual ``immediate consequence operator'' which
computes ``one step'' of our program semantics.

\begin{defn}[Immediate consequence operator]
  Given a program $\mathcal{P} = (P_1, \dots, P_m)$, where $P_i$ is a predicate,
  the immediate consequence operator $\consq: \Rel^n \rightarrow \Rel^n$ is defined as follows:
  \begin{displaymath}
    \consq(R_1, \dots, R_n) = (\denote{P_1}(R_1, \dots, R_n), \dots, \denote{P_m}(R_1, \dots, R_n))
  \end{displaymath}
\end{defn}

That is, given a value for the program, we pass in all the relations
to the denotation of each predicate, to get a new tuple of relations.

\begin{defn}[Program semantics]
  The semantics of a program $\mathcal{P}$ is defined to be
  \begin{displaymath}
    \denote{\mathcal{P}} \defeq \lfp_{\Rel^n}(\consq)
  \end{displaymath}
  and may be calculated by iterative application of $\consq$ to $\bot$ until
  fixpoint is reached.
\end{defn}

Whether or not this program semantics exists will depend on whether the fixpoint
exists. Typically this is ensured by constraining the program such that $\consq$
is monotone (or, in the context of a dcpo, continuous). We can be agnostic
about this when applying \cref{thm:fixpointIter}, but it is a requirement when
applying \cref{thm:leastFixpointDerivatives}.

\subsection{Incremental evaluation of Datalog}
\label{sec:datalogIncr}

We can easily extend a derivative for the formula semantics to a derivative for
the immediate consequence operator $\consq$. Putting this together with the
results from \cref{sec:fixpoints}, we get our two big results.

\begin{thm}[Incremental evaluation of Datalog semantics]
\label{thm:diffEval}
  Datalog program semantics can be evaluated incrementally.
\end{thm}
\ifproofs
\begin{proof}
  Corollary of \cref{thm:fixpointIter} and \cref{corollary:consqDiff}.
\end{proof}
\fi

This is known (semi-naive evaluation), but our proof is more
modular, so we will be able to extend this result more easily.

\begin{thm}[Incremental maintenance of Datalog semantics]
\label{thm:diffUpdate}
  Datalog program semantics can be incrementally maintained with changes to
  extensional relations.
\end{thm}
\ifproofs
\begin{proof}
  Corollary of \cref{thm:leastFixpointDerivatives} and \cref{corollary:consqDiff}.
\end{proof}
\fi

This is known \autocite[see][and successors]{gupta1993maintaining},
but again, the proof is now modular so we can extend it.

\subsubsection{Worked example of updating a recursive Datalog program}
\label{sec:workedExample}

The algorithm in \cref{thm:leastFixpointDerivatives} is very abstract, and it is
hard to see how it will work out in practice. It is therefore worth doing a
simple worked example.

% You can recompute the example using ql/Fixpoints.ql, if you want to change the data

Consider the $tc$ program from \cref{sec:intro}:
\begin{align*}
  tc(x, y) &\leftarrow e(x, y) \vee \exists z.(e(x, z) \wedge tc(z, y))
\end{align*}

We will start with an edge relation $e_1$ and change it to a new edge relation
$e_2$ by applying a change $\change{e}$, which both adds and removes some values.
\begin{align*}
  e_1 &= \{(1,2), (2,3), (3,4), (5,6) \}\\
  \change{e} &= (\{(4,5)\}, \{(2,3)\})\\
  e_2 &= e_1 \cplus \change{e}\\
      &=\{ (1,2), (3,4), (4,5), (5,6) \}
\end{align*}

We want to update the fixpoint of $tc$ using $e_1$, which we will call
$tc_{e_1}$,  to the fixpoint of $tc$ using $e_2$, which we will call $tc_{e_2}$.
As we have seen in \cref{thm:leastFixpointDerivatives},
we can do this by computing the fixpoint $\change{w} = \lfp(\adjust(tc_{e_1}, \change{tc}))$. 

A reminder of the expanded definition of $\adjust$:
\begin{align*}
  \adjust(f, \change{f}) &= \lambda\ \change{a}. \change{f}(\lfp(f)) \splus \derive{(f \cplus \change{f})}(\lfp(f), \change{a})
\end{align*}

We've chosen the second defintion of $\ev$ from \cref{prop:evDerivatives}, since
we already know what $f \cplus \change{f}$ looks like \textemdash{} it is simply
$\denote{tc_{e_2}}$ \textemdash{} and $\change{tc}(\lfp(tc_{e_1}))$ can be
computed once up front and reused throughout the computation.

We need the derivative of $tc_{e_2}$:
\begin{align*}
  \updiff(tc_{e_2}(x, y)) \leftarrow & \exists z. (e_2(x,z) \wedge \updiff(tc_{e_2}(z, y)))\\
  \downdiff(tc_{e_2}(x, y)) \leftarrow & \neg e_2(x, y)\\
    &\wedge
    \exists z . (e_2(x, z) \wedge \downdiff(tc_{e_2}(z, y)))\\
    &\wedge
    \neg \exists z . (e_2(x, z) \wedge \bothdiff(tc_{e_2}(z,y)))
\end{align*}

We also need $\change{tc}$:
\begin{align*}
  \change{tc}(f) = &\\
  &(e_2(x,y) \vee \exists z . (e_2(x,z) \wedge f(z,y))) \\
  &\cminus (e_1(x,y) \vee \exists z . (e_1(x,z) \wedge f(z,y)))
\end{align*}

We can now evaluate the fixpoint.\footnote{We would of course like to evaluate this fixpoint
  incrementally, which we can do with exactly the same theoretical machinery.}
Here is how the changes evolve:
\begin{center}
  \begin{tabular} {p{3.5em} p{10em} p{10em}}
    Iteration & Additions to $\updiff$ & Additions to $\downdiff$ \\
    \toprule
    1 & $\{ (4,5), (4,6) \}$ & $\{ (2,3), (2,4) \}$\\
    2 & $\{ (3,5), (3,6) \}$ & $\{ (1,3), (1,4) \}$\\
    3 & (as above) & (as above) \\
    \bottomrule
  \end{tabular}
\end{center}
\medskip

This results in $\change{w} = (\{ (3,5), (3,6), (4,5), (4,6)\}, \{(1,3), (1,4), (2,3), (2,4)\})$.
Applying the change and shows that we have indeed computed the new fixpoint.
\begin{align*}
  tc_{e_1} \cplus \change{w} &= \{(1,2), (1,3), (1,4), (2,3), (2,4), (5,6)\} \cplus \change{w}\\
  &= \{(1,2), (3,5), (3,6), (4,5), (4,6), (5,6)\}\\
  &= tc_{e_2}
\end{align*}

\section{The category of change actions}
\label{sec:category}

The sharp-eyed reader will have noticed that we have defined change actions as a
set of objects with special functions between them (differentiable functions),
and where we have change actions for product, sum, and function types. This begs
the question \textemdash{} is there a category here? And is it Cartesian closed?

The answer to this is yes, and we will gesture in the direction of a categorical
account of change actions.

\begin{defn}[Category of change actions]
  We define the category $\cat{CAct}$ of change actions. The objects are
  change actions and the morphisms are differentiable functions. 
\end{defn}

\subsection{Equivalence with PreOrd}

There is a natural preorder on the base set of a change action, given by reachability
under the action:

\begin{defn}[Reachability preorder]
  $a \reachOrder b$ iff there is a $\change{a} \in \changes{A}$ such that $a \cplus
  \change{a} = b$.
\end{defn}

We can characterize many of the properties of change actions in terms of the reachability preorder,
which suggests a connection between $\cat{CAct}$ and the category of preorders, $\cat{PreOrd}$.

\begin{prop}
  A function is differentiable iff it is monotone with respect to the
  reachability preorder. 
\end{prop}

\begin{corollary}
  Two change actions are isomorphic iff their posets under the reachability
  preorder are isomorphic.
\end{corollary}

\begin{corollary}
  Any function from a discrete change action or into a complete change
  action is differentiable.
\end{corollary}

Indeed, the correspondence between a change action and its reachability preorder gives rise to
a (full and faithful) functor $\reach : \cat{CAct} \rightarrow \cat{PreOrd}$ that acts as the
identity on morphisms.

Conversely, any preorder $\leq$ on some set $A$ induces a change action
$\cstr{A}_\leq \defeq \cstruct{A}{\leq^\star}{\cplus_\star}$.
The action $\cplus_\star$ is defined as the extension of $\cplus_\leq$ to the free
monoid $\leq^\star$, where $\cplus_\leq$ is defined as:
\[
\begin{aligned}
   \cplus_\leq &: (A \times \leq) \rightarrow A&\\
   a \cplus_\leq (b, c) &\defeq
     \begin{cases}
     c&\text{ if $a = b$}\\
     a&\text{ otherwise}
     \end{cases}
\end{aligned}
\]

The mapping to $\cstr{A}_\leq$ gives rise to a (full and faithful) functor
$\direct : \cat{PreOrd} \rightarrow \cat{CAct}$, again acting as the identity on morphisms.

These two functors are in fact enough to give us an equivalence between the categories
$\cat{CAct}$ and $\cat{PreOrd}$.

\begin{thm}[name=Equivalence of $\cat{CAct}$ and $\cat{PreOrd}$, restate=preordEquivalence]
  \label{thm:preordEquivalence}
  The functor $\reach$ from $\cat{CAct}$ to $\cat{PreOrd}$ together with the
  functor $\direct$ in the opposite direction form an equivalence of categories.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:preordEquivalence}.
\end{proof}
\fi

Since $\cat{PreOrd}$ is a Cartesian closed category and has all limits and
colimits, this gives us a proof of the existence of limits, colimits, and exponentials in $\cat{CAct}$.

\begin{corollary}
  The category $\cat{CAct}$ has all limits, colimits and exponential objects.
\end{corollary}

In the case of complete change actions, this equivalence degenerates into an
equivalence with $\cat{Set}$, since all functions are differentiable.

\subsection{Exponentials}
\label{sec:exponentials}

The exponential objects in the category $\cat{CAct}$ are difficult to work with,
because we need to ensure that $f \cplus \change{f}$ continues to be a
differentiable function. Under some conditions, however, we can find a simple representation.

\begin{defn}[Pointwise change actions]
  \label{def:pointwiseChangeActions}
  A change action $\cstr{B}$ is pointwise if every exponential object
  $\exponential{\cstr{A}}{\cstr{B}}$ is isomorphic to a pointwise function change action.
\end{defn}

This corresponds to the intuition about how the correspondence with
$\cat{PreOrd}$ should work: the preorder on monotone functions in $\cat{PreOrd}$ is
pointwise.

This pointwise change action is not well defined for all change actions, since
we require $f \cplus_\rightarrow \change{f}$ to be \emph{differentiable}, which
may not be true for all pointwise changes $\change{f}$.
Fortunately, there are useful subcategories of $\cat{CAct}$ formed of pointwise change actions.

\begin{prop}[name=Pointwise change actions, restate=pointwiseChangeActionProps]
  \label{prop:pointwiseChangeActionProps}
  Every change action $\cstruct{B}{\changes{B}}{\cplus}$ such that the change action
  $\cstruct{\changes{B}}{\changes{B}}{\splus}$ is complete and $\cplus$ is differentiable with
  respect to its first argument is pointwise.

  In particular, every change action where $\cplus$ is a group action is pointwise.
\end{prop}
\ifproofs
  See \cref{prf:pointwiseChangeActionProps}.
\fi

\begin{prop}[name=Complete implies pointwise, restate=pointwiseComplete]
  \label{prop:pointwiseComplete}
   Every complete change action $\cstr{B}$ is pointwise.
\end{prop}
\ifproofs
  See \cref{prf:pointwiseComplete}.
\fi

Furthermore, since the complete change actions are a reflective subcategory of
$\cat{CAct}$ (with the reflector being the ``completion'' of a change action,
i.e. any complete change action, which we can always find), the complete change
action form a Cartesian closed category of pointwise change actions.

Having pointwise changes allows us to actually compute a derivative of the
evaluation map as shown in \cref{prop:evDerivatives}. In practice, this means
that we will only be able to use the results in \cref{sec:fixpoints} when
we have pointwise change actions, or where we have some other way of computing
a derivative of the evaluation map.

\section{Related work}

\subsection{Change actions and incremental computation}

\subsubsection{Change structures}
\label{sec:relatedChangeStructures}

The seminal paper in this area is \textcite{cai2014changes}. We deviate from
that excellent paper in three regards: the
inclusion of minus operators, the nature of function changes, and the use of
dependent types.

We have omitted minus operators from our definition because
there are many interesting change actions that are not complete and so cannot
have a minus operator. Where we can find a change structure with a minus operator, often we are
forced to use unwieldy representations for change sets, and
\citeauthor{cai2014changes} cite this as their reason for using a dependent
type of changes. For example, the monoidal change actions on sets and lists are clearly
useful for incremental computation on streams, yet they do not admit minus
operators \textemdash{} instead, one would
be forced to work with e.g. multisets admitting negative arities, as \citeauthor{cai2014changes} do.

Our function changes (when well behaved) correspond to what \citeauthor{cai2014changes} call
\emph{pointwise differences} \autocite[see][section 2.2]{cai2014changes}. As
they point out, you can reconstruct their
function changes from pointwise changes and derivatives, so the two formulations
are equivalent. However, our function changes correspond to the
exponentials that we get from the categorical equivalence with $\cat{PreOrd}$,
and (when we can use them) pointwise differences are easier to work with.

The equivalence of our presentations means that our work should be compatible
with ILC \autocite[see][section 3]{cai2014changes}. The derivatives we give in \cref{sec:datalogDifferentiability} are more or
less a ``change semantics'' for Datalog \autocite[see][section
3.5]{cai2014changes}. 

\subsubsection{S-acts}
\label{sec:sacts}

S-acts (i.e the category of monoid actions on sets) and their categorical structure have received a fair amount of attention
over the years (\textcite{kilp2000monoids} is a good
overview). However, there is a key difference between our $\cat{CAct}$ and the category of
S-acts $\cat{SAct}$: the objects of $\cat{SAct}$ all maintain the same monoid
structure, whereas we are interested in changing both the base set \emph{and} the structure of the act.

There are similarities: if we compare the definition of an ``act-preserving''
homeomorphism in $\cat{SAct}$ \autocite[see][]{kilp2000monoids} we can see that the structure is
quite similar to the definition of differentiability:
\begin{displaymath}
  f(a \splus s) = f(a) \splus s
\end{displaymath}
as opposed to
\begin{displaymath}
  f(a \cplus s) = f(a) \cplus \derive{f}(a, s)
\end{displaymath}
That is, we use $\derive{f}$ to transform the action element into the new
monoid, whereas in $\cat{SAct}$ it simply remains the same.

In fact, $\cat{SAct}$ is a subcategory of $\cat{CAct}$, where we only
consider change actions with change set $S$, and the only functions are those
whose derivative is $\lambda a. \lambda d. d$.

\subsubsection{Derivatives of fixpoints}

\textcite{arntz2017fixpoints} gives a derivative operator for fixpoints based on
the framework in \textcite{cai2014changes}. However, since we have different
notions of function changes, the result is inapplicable as
stated. In addition, we require a somewhat different set of conditions, in particular we
don't require our changes to always be increasing.

\subsection{Datalog}

\subsubsection{Incremental evaluation}

The earliest interpretation of semi-naive evaluation as a derivative 
appears in \textcite{bancilhon1986naive}. The idea of using an approximate derivative
and the requisite soundness condition appears as a throwaway comment in
\textcite[][section 3.2.2]{bancilhon1986amateur}, and as far as we know nobody has since
developed that approach.

As far as we know, traditional semi-naive is the state of
the art in incremental, bottom-up, Datalog evaluation, and there are no strategies that
accommodate additional language features such as parity-stratified negation and aggregates.

\subsubsection{Incremental maintenance}

There is existing literature on incremental maintenance of relational algebra
expressions. In particular \textcite{griffin1997improved} following
\textcite{qian1991incremental} shows the essential insight that it is necessary to
track both an ``upwards'' and a ``downwards'' difference, and produces a set of
rules that look quite similar to those we derive in \cref{thm:concreteDatalog}.

Where our presentation improves over \citeauthor{griffin1997improved} is mainly in
the genericity of the presentation. Our machinery works for a wider variety of
algebraic structures, and it is clear how the parts of the proof work together
to produce the result. In addition, it is easy to see how to extend the proofs
to cover additional language constructs.

There are some inessential points of difference as well: we work on Datalog,
rather than relational algebra; and we use set semantics rather than bag
semantics. This is largely a matter of convenience: Datalog is an easier
language to work with, and set semantics allows a much wider range of valid
simplifications. However, all the same machinery applies to relational algebra
with bag semantics, it is simply necessary to produce a valid version of \cref{thm:concreteDatalog}.

We also solve the problem of updating \emph{recursive} expressions. As far as we
know, this is unsolved in general. Most of the attempts to solve it have
focussed on Datalog rather than relational algebra, since Datalog is designed to
make heavy use of recursion.

Several approaches
\autocites{gupta1993maintaining}{harrison1992maintenance}
make use of a common tactic: one can get to the new fixed
point by starting from \emph{any} point below it, and then iterating the
semantics again to fixpoint. The approach, then, is to find a way to delete as
few tuples as possible to get below the new fixpoint, and then iterate again
(possibly using an incremental version of the semantics).

This is a perfectly reasonable approach, and given a good, domain-specific,
means of getting below the fixpoint, they can be quite efficient.
The main defect of these approaches is that they \emph{are} domain specific,
and hence inflexible with respect to changes in the language or structure,
whereas our approach is quite generic. Although we know of no theoretical reason
why either approach should give superior performance when both are applicable,
an empirical investigation of this could prove interesting.

Other approaches \autocites{dong2000incremental}{urpi1992method} consider only
restricted subsets of Datalog, or incur other substantial constraints, and our results
are thus significantly more general.

\subsubsection{Embedding Datalog}
\label{sec:embeddingDatalog}

Datafun (\textcite{arntz2016datafun}) is a functional programming language that embeds
Datalog, allowing significant improvements in genericity, such as the use of
higher-order functions. Since we have directly defined a change action and
derivative operator for Datalog, our work could be used as a ``plugin'' in the sense
of \citeauthor{cai2014changes}, allowing Datafun to compute its internal fixpoints
incrementally, but also allowing Datafun expressions to be fully incrementally maintained.

\subsection{Differential $\lambda$-calculus}

Another setting where derivatives of arbitrary higher-order programs have been studied
is the \emph{differential $\lambda$-calculus} \autocites{ehrhard2003differential}{ehrhard2017introduction}.
This is a higher-order, simply-typed
calculus which allows for computing the derivative of a function, in a similar
way to the notion of derivative in Cai's work and the present paper.

While there are clear similarities between the two systems, 
the most important difference is the properties of the derivatives themselves:
in the differential $\lambda$-calculus, derivatives are guaranteed to be linear
in their second argument, whereas in our approach derivatives do not have this restriction 
but are instead required to satisfy a strong relation to the function
that is being differentiated (see \cref{def:derivative}).

Families of denotational models for the differential $\lambda$-calculus have been
studied in depth
\autocites{bucciarelli2010categorical}{blute2010convenient}{cockett2016categorical}{kerjean2016mackey},
and the relationship between these and change actions is the subject of ongoing work.

\subsection{Higher-order automatic differentiation}

Automatic differentiation \autocite{griewank2008evaluating} is a technique that allows
for efficiently computing the derivative of arbitrary programs, with
applications in probabilistic modeling \autocite{kucukelbir2017automatic}
and machine learning \autocite{baydin2014automatic} among other areas. In recent times, this technique has been successfully
applied to higher-order languages \autocites{siskind2008nesting}{baydin2016diffsharp}.
While some approaches have been suggested \autocites{manzyuk2012simply}{kelly2016evolving}, a general
theoretical framework for this technique is still a matter of open research. 

To this purpose, some authors have proposed the incremental $\lambda$-calculus
as a foundational framework on which models of automatic differentiation can
be based \autocite{kelly2016evolving}. We believe our change actions are better suited
to this purpose than the incremental $\lambda$-calculus, since one can easily give them a
synthetic differential geometric reading (by interpreting $\cstr{A}$ as an Euclidean module and $\changes{A}$
as its corresponding spectrum, for example).

\section{Conclusions and future work}

We have presented change actions and their properties, and used them to provide novel
strategies for incrementally evaluating and maintaining recursive functions, in
particular the semantics of Datalog.

Our work opens several avenues for future investigation.

Firstly, the concrete definition of change actions can be generalized in a number of
ways. A 2-categorical presentation (by analogy with the 2-categorical interpretation
of $\cat{PreOrd}$) would smooth over many of the technical difficulties which
the current presentation faces due to the fact that the changes produced
$\derive{f}(a, \change{a})$ can be applied at points other than $f(a)$.
A description of change actions which is generic in
the base category could also be provided, which might lead to models of
the incremental $\lambda$-calculus on different base categories. 

Of those, the theory of change actions on the category of domains is of particular interest. Since
domains are used to model programming language semantics, this could
open up opportunities for incremental evaluation of many programming languages,
even those that do not fit into the model of \citeauthor{cai2014changes}'s ILC.
Our fixpoint theorems are proven over dcpos in general, which is crucial since
fixpoints are often used in domain theory to give a semantics to recursion.

Additionally, we have only begun to explore the tantalizing connection between
change actions, the ILC and synthetic
differential geometry, and a denotational semantics for the
ILC based on smooth spaces is the subject of ongoing research. We believe many concepts
from standard differential geometry, like gradients, vector fields, curves and flows can
be defined for general change actions, which could then have implications for higher-order
computation.

Finally, combining our concrete Datalog derivatives with a system similar to ILC
in a language such as Datafun would be an exciting demonstration of the compositional
power of this approach.

\begin{acks}

We would like to thank Semmle Ltd. for supporting this research, as well as Pavel
Avgustinov, Aditya Sharad, Max Sch\"afer, Katriel Cohn-Gordon, Luke Ong, and Simon Peyton Jones for their
helpful comments on the manuscript.

\end{acks}

\printbibliography

\clearpage
\appendix
\appendixpage
\section{Proofs}

\subsection{Change actions and derivatives}

\products*
\begin{proof}
  \label{prf:products}
  Let $\cstr{Y}$ be a change action, and $f_1: \cstr{Y} \rightarrow \cstr{A}$, $f_2: \cstr{Y}
  \rightarrow \cstr{B}$ be morphisms.

  Then the product morphism in $\cat{Set}$, $\pair{f_1}{f_2}$ is the product
  morphism in $\cat{CAct}$. It can easily be
  shown that $\pair{\derive{f_1}}{\derive{f_2}}$ is a derivative of $\pair{f_1}{f_2}$,
  hence $\pair{f_1}{f_2}$ is a morphism in $\cat{SAct}$.

  Commutativity and uniqueness follow from the corresponding properties of the
  product in the $\cat{Set}$.
\end{proof}

\coproducts*
\begin{proof}
  \label{prf:coproducts}
  Let $\cstr{Y}$ be a change action, and $f_1 : \cstr{A} \rightarrow \cstr{Y}$, $f_2 : \cstr{B}
  \rightarrow \cstr{Y}$ be differentiable functions.

  As before, it suffices to prove that the universal function $[f_1, f_2]$ in $\cat{Set}$ is a differentiable
  function from $\cstruct{A + B}{\changes{A} \times \changes{B}}{\cplus_{A + B}}$ into $Y$. It's easy to see
  that the following morphism is a derivative:
  \begin{align*}
    \derive{[f_1, f_2]} (i_1 a, (\change{a}, \change{b})) &\defeq f_1'(a, \change{a})\\
    \derive{[f_1, f_2]} (i_2 b, (\change{a}, \change{b})) &\defeq f_2'(b, \change{b})
  \end{align*}
\end{proof}

\subsection{Posets and Boolean algebras}

\lsuperpose*
\begin{proof}
  \label{prf:lsuperpose}
  We show that the monoid action property holds:
  \begin{align*}
    &a \twist \left[(p, q) \splus (r, s)\right]\\
    &= a \twist ((p \wedge \neg s) \vee r, (q \wedge \neg r) \vee s)\\
    &= \left(
      a \vee
      \left(
        \left(
          p \wedge \neg s
        \right)
        \vee r
      \right)
    \right)
    \wedge \neg
    \left(
      \left(
        q \wedge \neg r
      \right)
      \vee s
    \right)\\
    &= \left(
      \left(
        \left(
          a \vee p
        \right)
        \wedge
        \left(
          a \vee \neg s
        \right)
      \right)
      \vee r
    \right)
    \wedge
    \left(
      \neg q \vee r
    \right)
    \wedge
    \neg s
    \tag{distributing $\vee$ over $\wedge$, applying de Morgan rules}\\
    &= \left(
      \left(
        \left(
          a \vee p
        \right)
        \wedge
        \left(
          a \vee \neg s
        \right)
        \wedge
        \neg q
      \right)
      \vee r
    \right)
    \wedge
    \neg s
    \tag{un-distributing $\vee$ over $\wedge$ }\\
    &= \left(
      \left(
        \left(
          a \vee p
        \right)
        \wedge
        \neg q
      \right)
      \vee r
    \right)
    \wedge
    \neg s
    \tag{$r \rightarrow \neg s$}\\
    &= a \twist (p, q) \twist (r, s)
  \end{align*}

  It is easy to show that $\twist$ is well-defined, by showing that $(p,q)
  \twist (r, s) \in L \disjointTimes L$ if $(p, q), (r,s) \in L \disjointTimes L$.

  Completeness is easy to show.
\end{proof}

\subsection{Directed-complete partial orders and fixpoints}

\booleanAlgebraContinuous*
\begin{proof}
  \label{prf:booleanAlgebraContinuous}
  $L$ is a complete lattice, so certainly a dcpo. $\cstr{L}_\superpose$ is a
  dcpo with $\bigvee (p_i, q_i) \defeq (\bigvee p_i \wedge \neg \bigwedge q_i, \bigwedge q_i)$.

  Continuity of $\twist$ in its second argument:
  \begin{align*}
    &a \twist \bigvee (p_i, q_i)\\
    &= a \twist (\bigvee p_i, \bigwedge q_i)\\
    &= (a \vee (\bigvee p_i \wedge \neg \bigwedge q_i)) \wedge \neg \bigwedge q_i\\
    &= (a \vee \bigvee p_i) \wedge \neg \bigwedge q_i\\
    &= (a \vee \bigvee p_i) \wedge \bigvee \neg q_i \tag{applying de Morgan}\\
    &= \bigvee (a \vee p_i) \wedge \neg q_i \tag{$\vee$ and $\wedge$ are continuous}\\
    &= \bigvee a \twist (p_i, q_i)
  \end{align*}

  Continuity $\twist$ in its first argument and continuity of $\splus$ follow easily from their definitions and the continuity
  of $\vee$ and $\wedge$.
\end{proof}

\factoringFixpoints*
\begin{proof}
  \label{prf:factoringFixpoints}
  Let
  \begin{displaymath}
    p(b) = (\lfp(f), g(\lfp(f), b))
  \end{displaymath}
  Then $h(h^i(\bot)) \leq p(p^i(\bot))$ (by simple induction), and so by continuity
  \begin{displaymath}
    \lfp(h) = \bigsqcup_{i \in \NN} h^i(\bot) \leq \bigsqcup_{i \in \NN} p^i(\bot) = \lfp(p)
  \end{displaymath}

  But $h(\lfp(p)) = \lfp(p)$, so $\lfp(h) \leq \lfp(p)$, since $\lfp(h)$ is least.

  Hence $\lfp(h) = \lfp(p) = (\lfp(f), \lfp(\lambda b . g(\lfp(f), b)))$.
\end{proof}

\iterDerivativesN*
\begin{proof}
  \label{prf:iterDerivativesN}
  By induction on $n$. We show the inductive step.
  \begin{align*}
    &\iter_f((n+1) + m)\\
    &=f(\iter_f(n + m)) \tag{definition of $\iter_f$}\\
    &=f(\iter_f(n) \cplus \derive{\iter_f}(n, m)) \tag{by induction}\\
    &=\iter_f(n+1) \cplus \derive{f}(\iter_f(n), \derive{\iter_f}(n, m)) \tag{$f$ is differentiable, definition of $\iter_f$}
  \end{align*}
\end{proof}

\fixpointIter*
\begin{proof}
  \label{prf:fixpointIter}
  \begin{align*}
    &\lfp(\iter_f)\\
    &=\bigsqcup_{n \in \NN} \iter_f(n)\\
    &=\bigsqcup_{n \in \NN} \pi_1 (\nextiter_f^n(\bot))
  \end{align*}
\end{proof}

\fixpointPseudoDerivatives*
\begin{proof}
  \label{prf:fixpointPseudoDerivatives}
  
  We show that a change $\change{w} \in \Delta A$ satisfies
  the equation:
  \begin{equation}\label{eqn:fixcondition}
    \change{w} = \adjust(f, \change{f})(\change{w})
  \end{equation}
  if and only if $\fixpoint(f) \cplus \change{w}$ is a fixpoint of $f \cplus \change{f}$.

  Let $\change{w} \in \Delta A$ satisfy \cref{eqn:fixcondition}. Then
  \begin{align*}
    &(f \cplus \change{f})(\fixpoint_A(f) \cplus \change{w})\\
    &= f(\fixpoint(f))
    \cplus
    \adjust(f, \change{f})(\change{w})
    \tag{by \cref{def:functionalChanges}}\\
    &= \fixpoint(f)
    \cplus
    \change{w}
    \tag{rolling the fixpoint and \cref{eqn:fixcondition}}
  \end{align*}

  Hence $\fixpoint(f) \cplus \change{w}$ is a fixpoint of $f \cplus \change{f}$. The converse
  follows from reversing the direction of the proof.
\end{proof}

\iterDerivativesF*
\begin{proof}
  \label{prf:iterDerivativesF}
  The base case is easy to prove.

  For the inductive step:
  \begin{align*}
    &\iter_{n+1}(f \cplus \change{f})\\
    &=(f \cplus \change{f})(\iter_{n}(f \cplus \change{f}))\\
    &= (f \cplus \change{f})(
        \iter_{n}(f)
        \cplus \derive{\iter_{n}}(f, \change{f})
      )
    \tag{ by induction}\\
    &= f(\iter_n(f)) \cplus \derive{\ev}((f, \iter_{n}(f)), (\change{f},
      \derive{\iter_{n}}(f, \change{f})))
    \tag{by \cref{def:functionalChanges}}\\
    & =\iter_{n+1}(f) \cplus \derive{\iter_{n+1}}(f, \change{f})
  \end{align*}
\end{proof}

\leastFixpointDerivatives*
\begin{proof}
  \label{prf:leastFixpointDerivatives}
  $\derive{\iter_n}$ and $\nextiter_{f, \change{f}}$ are continuous since
  $\derive{\ev}$ and $f$ are.

  Hence the set $\{ \derive{\iter}_n \}$ is directed, and so $\bigsqcup_{i \in \NN}
  \derive{\iter_i}$ is indeed a derivative for $\lfp$.

  We now show that it is equivalent to $\derive{\lfp}$:
  \begin{align*}
    &\bigsqcup_{n \in \NN} \derive{\iter_n}(f, \change{f})\\
    &=\bigsqcup_{n \in \NN} \pi_2(\nextiter_{f, \change{f}}^n(\bot))\\
    &=\pi_2(\bigsqcup_{n \in \NN} \nextiter_{f, \change{f}}^n(\bot)) \tag{$\pi_2$ is continuous}\\
    &= \pi_2 (\lfp(\nextiter_{f, \change{f}})) \tag{$\nextiter_{f, \change{f}}$ is continuous, Kleene's Theorem}\\
    &= \pi_2 ((\lfp(f), \lfp (\lambda\ \change{a}. \derive{\ev}((f, \lfp f), (\change{f}, \change{a})))))
    \tag{by \cref{prop:factoringFixpoints}, and the definition of $\nextiter$}\\
    &= \pi_2 (\lfp(f), \lfp(\adjust(f, \change{f})))\\
    &= \lfp(\adjust(f, \change{f}))\\
    &= \derive{\lfp}(f, \change{f})
  \end{align*}
\end{proof}

\subsection{The category of change actions}

\preordEquivalence*
\begin{proof}
  \label{prf:preordEquivalence}
  On one direction, if $U$ is a preorder, it's trivial to check that $\reach (\direct (U)) = U$.

  On the other direction, we need to find a natural isomorphism between $\direct \circ \reach$
  and the identity functor. First, we note that the base set for the change action
  $\direct(\reach(A))$ is the same as the base set for $\cstr{A}$.

  We claim that the desired natural isomorphism is given by the
  the identity on the base sets. It remains to prove that the identities
  $id_A : \cstr{A} \rightarrow \direct(\reach(A))$ and
  $id_{A_{\reachOrder}} : \direct(\reach(A)) \rightarrow \cstr{A}$
  are indeed differentiable in both directions.

  In one direction, a derivative is given by
  \begin{displaymath}
    \derive{id}_A(a, \change{a}) \defeq (a, a \cplus \change{a})
  \end{displaymath}
  Conversely, let $(a, b) \in \reachOrder$. By definition of $\reachOrder$, there is some
  $\change{}_{(a, b)} \in \changes{A}$ satisfying $a \cplus \change{}_{(a,b)} = b$.
  This gives a definition for the derivative of the identity on pairs:
  \begin{displaymath}
    \derive{id}_{A_{\reachOrder}}(a, (a, b)) \defeq \change{}_{(a, b)}
  \end{displaymath}
  which can be extended freely to the whole change set
  $\reachOrder^\star$.\footnote{Note that since we picked arbitrary change
    representatives, the resulting derivative may not preserve the monoid action.}
\end{proof}

\pointwiseChangeActionProps*
\begin{proof}
\label{prf:pointwiseChangeActionProps}
  Let $\cstr{B}$ be a change action, with $\cplus$ differentiable with respect
  to its first argument, and suppose the change action on $\changes{B}$
  is complete.

  First, we prove that the pointwise change action is well defined: let
  $f : \cstr{A} \rightarrow \cstr{B}$ be some differentiable function, and
  $\change{f} : A \rightarrow \changes{B}$ a pointwise change (which is
  differentiable, since $\cstr{\changes{B}}$ is complete). Then:
  \begin{align*}
    &(f \cplus_\rightarrow \change{f})(a \cplus \change{a})\\
    &= f(a \cplus \change{a}) \cplus \change{f}(a \cplus \change{a})\\
    &= (f(a) \cplus \derive{f}(a, \change{a})) \cplus (\change{f}(a) \splus \derive{\change{f}}(a, \change{a}) )\\
    &= f(a) \cplus (\change{f}(a) \splus \derive{\change{f}}(a, \change{a}))
       \cplus \derive{\cplus}((f(a), \derive{f}(a, \change{a})), \change{f}(a \cplus \change{a}))\\
    &= (f \cplus_\rightarrow \change{f})(a) \cplus (\derive{\change{f}}(a, \change{a})
       \splus \derive{\cplus}((f(a), \derive{f}(a, \change{a}), \change{f}(a, \cplus \change{a}))))
  \end{align*}
  Hence $(f \cplus_\rightarrow \change{f})$ is differentiable.
  
  The evaluation map, defined as $\ev(f, a) \defeq f(a)$ is differentiable as well:
  \begin{align*}
    &\ev((f, \change{f}), (a, \change{a}))\\
    &= (f \cplus_\rightarrow \change{f})(a \cplus \change{a}) \\
    &= f(a \cplus \change{a}) \cplus \change{f}(a \cplus \change{a})\\
    &= f(a) \cplus (f'(a, \change{a}) \splus \change{f}(a \cplus \change{a}))\\
    &= \ev(f, a) \cplus (f'(a, \change{a}) \splus \change{f}(a \cplus \change{a}))
  \end{align*}

  Now, on the one hand, suppose that $f : C \times A \rightarrow B$ is a differentiable function,
  and $\curry{f} : C \rightarrow (\exponential{\cstr{A}}{\cstr{B}})$ its corresponding curried version:
  \begin{align*}
    &\curry{f}(c \cplus \change{c})\\
    &= \lambda a . f(c \cplus \change{c}, a)\\
    &= \lambda a . f(c, a) \cplus \derive{f}((c, \change{c}), (a, 0))\\
    &= (\lambda a . f(c, a)) \cplus_\rightarrow (\lambda a . \derive{f}((c, \change{c}), (a, 0)))
  \end{align*}
  Then the function $\lambda a . \derive{f}((c, \change{c}), (a, 0))$ is a derivative for $\curry{f}$,
  thus $\curry{f}$ is differentiable. Conversely, suppose that $\curry{f}$ is differentiable.
  Then we note that, by hypothesis, $\curry{f}(a)$ is differentiable for all $f$, with derivative
  $\derive{f_a}$, and hence:
  \begin{align*}
    &f(a \cplus \change{a}, c \cplus \change{c})\\
    &= \curry{f}(a \cplus \change{a})(c \cplus \change{c})\\
    &= (\curry{f}(a) \cplus_\rightarrow \derive{\curry{f}}(a, \change{a}))(c \cplus \change{c})\\
    &= \curry{f}(a)(c \cplus \change{c}) \cplus \derive{\curry{f}}(a, \change{a})(c\cplus\change{c})\\
    &= \curry{f}(a)(c) \cplus (\derive{f_a}(c, \change{c}) \splus \derive{\curry{f}}(a, \change{a})(c\cplus\change{c}))\\
    &= f(a, c) \cplus (\derive{f_a}(c, \change{c}) \splus \derive{\curry{f}}(a, \change{a})(c\cplus\change{c}))
  \end{align*}
  Thus $f$ is differentiable as a function from $\cstr{C} \times \cstr{A}$ into $\cstr{B}$.
\end{proof}

\pointwiseComplete*
\begin{proof}
\label{prf:pointwiseComplete}
  Let $\cstr{B}$ be a complete change action.
  We prove that the pointwise change action is the exponential object $\exponential{\cstr{A}}{\cstr{B}}$.

  First, we note that the pointwise change action is trivially well defined, since
  every function into $\cstr{B}$ is differentiable. Similarly, the evaluation map
  is differentiable.

  Now consider two elements $\curry{f}$, $\curry{g}$ of $\exponential{\cstr{A}}{\cstr{B}}$. Since
  $\cstr{B}$ is complete, it is endowed with a minus operator $\cminus$, so we define
  $\cminus_\rightarrow : (\exponential{\cstr{A}}{\cstr{B}}) \times (\exponential{\cstr{A}}{\cstr{B}}) \rightarrow A \rightarrow \changes{B}$ by:
  $$ (g \cminus_\rightarrow f)(a) \defeq g(a) \cminus f(a) $$
  It's easy to check that this is indeed a minus operator and, therefore, $\exponential{\cstr{A}}{\cstr{B}}$
  is complete. Thus, trivially, any function $f : C \times A \rightarrow B$ is differentiable
  if and only if its curried version $\curry{f} : C \rightarrow (\exponential{A}{B})$ is.
\end{proof}


\end{document}
