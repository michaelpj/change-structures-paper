% Toggle comments for preamble and topmatter to typeset in ACM style

%\input{preamble-standard}
\input{preamble-acm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BEGIN {Macros / packages by Luke}
% switch of draft/final version
\newif\ifdraft\drafttrue
%\newif\ifdraft\draftfalse

\ifdraft
\newcommand{\lochanged}[1]{{\color{red}{#1}}}
\newcommand{\mpchanged}[1]{{\color{blue}{#1}}}
%\newcommand{\tk}[1]{{\textcolor{DarkGreen}{[{#1}---Tsukada]}}}
%\newcommand{\mp}[1]{{\color{blue}{[{#1}--Mario]}}}
\newcommand{\lo}[1]{{\color{red}{[{#1}--Luke]}}}
\else
\newcommand{\mpchanged}[1]{{#1}}
\newcommand{\lochanged}[1]{{#1}}
%\newcommand{\mp}[1]{}
\newcommand{\lo}[1]{}
\fi
\usepackage{bbm}
%% END {Macros / packages by Luke}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{thmtools}
\usepackage{todonotes}
\usepackage{etoolbox}
\usepackage{appendix}

% Packages where the order matters
\usepackage[
  safeinputenc,
  natbib=true
]{biblatex}
\usepackage{cleveref}
\usepackage{hyperref}

\newcommand{\todoall}[1]{\todo[inline,color=black!30,author=All]{#1}}
\newcommand{\todompj}[1]{\todo[inline,color=yellow!40,author=Michael]{#1}}
\newcommand{\todomario}[1]{\todo[inline,color=blue!40,author=Mario]{#1}}

\input{notation}

\newif\ifproofs
% Comment out to disable proofs
%\proofstrue

\addbibresource{paper.bib}

\begin{document}

%\input{topmatter-standard}
\input{topmatter-acm}

\begin{abstract}
  Incremental computation has been studied using the concepts of \emph{change
  structures} and \emph{derivatives} of programs, where the derivative of a function allows updating the output
  of the function based on a change to its input.

  We generalise change structures to a Cartesian closed category of \emph{change actions},
  and study their algebraic properties. We develop change actions for several common structures
  in computer science, including directed-complete partial orders and Boolean algebras.

  We then show how to compute derivatives of fixpoints. This allows us to
  perform incremental evaluation and maintenance of recursively defined
  functions such as generalised Datalog programs.

  Moreover, unlike previous results, our techniques are \emph{modular} in that
  they are easy to apply both to variants of Datalog and to other programming languages.
\end{abstract}

\title{Fixing incremental computation}
\subtitle{Derivatives of fixpoints, and the recursive semantics of Datalog}

\maketitle

\section{Introduction}
\label{sec:intro}

Consider the following classic Datalog program\footnote{See \autocite[][part D]{abiteboul1995foundations} for an introduction to Datalog.},
which computes the transitive closure of an edge relation $e$:
\begin{align*}
  tc(x, y) &\leftarrow e(x, y)\\
  tc(x, y) &\leftarrow e(x, z) \wedge tc(z, y)
\end{align*}

The semantics of Datalog, tells us that the denotation of this program is the
least fixpoint of the rule $tc$. Kleene's Theorem tells us that we can in fact
compute this by repeatedly applying the rule to fixpoint, starting from the empty relation. For example, supposing
that $e = \{ (1, 2), (2, 3), (3, 4) \}$, we get the following evaluation trace:
\begin{center}
  \begin{tabular} {p{3.5em} p{10em} p{10em}}
    Iteration & Newly deduced facts & Accumulated data in $tc$ \\
    \toprule
    0 & $\{ \}$ & $\{ \}$\\
    1 & $\{ (1, 2), (2, 3), (3, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4) \}$\\
    2 & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4) \}$\\
    3 & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4), (1, 4),(1, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4), (1, 4) \}$\\
    4 & (as above) & (as above) \\
    \bottomrule
  \end{tabular}
\end{center}
\medskip

At this point we have reached a fixpoint, and so we are done.

However, this process is quite wasteful. We deduced the fact $(1,2)$ at every iteration,
even though we had already deduced it in the first iteration. Indeed, for a
chain of $n$ such edges we will deduce $O(n^2)$ facts along the way.

The standard improvement to this evaluation strategy is known as ``semi-naive'' 
evaluation\autocite[See][section 13.1]{abiteboul1995foundations}, where we transform 
the program into a \emph{delta} program with two parts:
\begin{itemize}
  \item A \emph{delta} rule that computes the \emph{new} facts at each
    iteration. 
  \item An \emph{accumulator} rule that accumulates the delta at each
    iteration to compute the final result
\end{itemize}
In this case our delta rule is simple: we only get new transitive edges at iteration $n+1$ if we
can deduce them from transitive edges we deduced at iteration $n$.
\begin{align*}
  \Delta tc_{0}(x, y) &\leftarrow e(x, y)\\
  \Delta tc_{i+1}(x, y) &\leftarrow e(x, z) \wedge \Delta tc_i(z, y)\\
  tc_{0}(x, y) &\leftarrow \emptyset\\
  tc_{i+1}(x, y) &\leftarrow tc_{i}(x,y) \vee \Delta tc_{i+1}(x,y)
\end{align*}

\begin{center}
  \begin{tabular} {p{3.5em} p{8em} p{10em}}
    Iteration & $\Delta tc_i$ & $tc_i$ \\
    \toprule
    0 & $\{ (1, 2), (2, 3), (3, 4) \}$ & $\{ \}$\\
    1 & $\{ (1, 3), (2, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4) \}$\\
    2 & $\{ (1, 4) \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4) \}$\\
    3 & $\{ \}$ & $\{ (1, 2), (2, 3), (3, 4),$ $(1, 3), (2, 4), (1, 4) \}$\\
    4 & (as above) & (as above) \\
    \bottomrule
  \end{tabular}
\end{center}
\medskip

This is much better textemdash{} we have turned a quadratic computation into a
linear one. The delta transformation is a kind of \emph{incremental
  computation}: at each stage we compute the changes in the rule given the previous
changes to its inputs.

But the delta rule translation works only for traditional Datalog. It is common to
liberalise the formula syntax with additional features, such as disjunction,
existential quantification, negation, and aggregation.\footnote{ See, for
  example, \autocites(LogiQL)(){logicbloxWebsite}{halpin2014logiql},
  \autocites(Datomic)(){datomicWebsite},
  \autocites(Souffle)(){souffleWebsite}{scholz2016fast}, and
  \autocites(DES)(){saenz2011deductive}, which between them have all of these
  features and more. } 
This allows us to write programs like the following, where we compute whether all the
nodes in a subtree given by $child$ have some property $p$:
\begin{align*}
  treeP(x) &\leftarrow p(x) \wedge \neg \exists y . (child(x,y) \wedge \neg treeP(y))
\end{align*}

Here the combination of negation and explicit existential quantification amounts
to recursion through a \emph{universal} quantifier. We would
like to be able to use semi-naive evaluation for this rule too, but the simple delta
transformation is not well defined for the extended program syntax, and it is unclear how to extend it (and the
correctness proof) to handle such cases.\footnote{A simple approach is to just
  keep applying the algorithm of ``replace each recursive call in turn with its
  delta, and take the union of each of those''. But this is in fact incorrect
  and does not produce correct incremental programs in general.}

This is of more than theoretical interest \textemdash{} the research
in this paper was carried out at Semmle, which
makes heavy use of a commercial Datalog implementation
\autocites{semmleWebsite}{avgustinov2016ql}{sereni2008adding}{schafer2010type}.
Semmle's implementation includes parity-stratified negation\footnote{Parity-stratified negation means that recursive calls must
  appear under an even number of negations. This ensures that the rule remains
  monotone, so the least fixpoint still exists.},
recursive aggregates \autocite{demoor2013aggregates}, and other non-standard
features, so we are faced with a dilemma: either abandon the new language
features, or abandon incremental computation.

We can tell a similar story about \emph{maintenance} of Datalog programs.
Maintenance means updating the results of the program when its inputs change,
for example, updating the value of $tc$ given a change to $e$. Again, this is a
kind of incremental computation, and there are known solutions for traditional Datalog
\autocite{gupta1993maintaining}, but these break down when the language is extended.

There is a piece of folkloric knowledge in the Datalog community that hints at a
solution: the semi-naive translation of a rule corresponds to the
\emph{derivative} of that rule \autocites{bancilhon1986naive}[section
3.2.2]{bancilhon1986amateur}. The idea of performing incremental computation using derivatives has been
studied recently by \textcite{cai2014changes}, who give an account using
\emph{change structures}. They use this to provide a framework for incrementally evaluating lambda calculus programs.

However, \citeauthor{cai2014changes}'s work isn't directly applicable to Datalog: the tricky part
of Datalog's semantics are recursive definitions and the need for the \emph{fixpoints}, and we need some additional theory to tell us how to
handle incremental evaluation and maintenance of fixpoint computations.

This paper aims to bridge that gap by providing a solid semantic foundation for the incremental
computation of Datalog, and other recursive programs, in terms of changes and
differentiable functions.

\subsection{Contributions}

\todompj{redo for flow}

We start by generalizing change structures to
\emph{change actions} (\cref{sec:changeActions}). Change actions are simpler and weaker than change
structures, while still providing enough information to handle incremental computation,
having nice categorical behaviour (\cref{sec:category}) and fruitful
interactions with a variety of structures (\cref{sec:moreStructures}, \cref{sec:dcpos}).

We then show how change actions can be used to perform incremental evaluation and maintenance
of non-recursive program semantics, using the formula semantics of generalized Datalog as our primary
example (\cref{sec:nonRecursiveDatalog}). Moreover, the structure of the
approach is modular, and can accommodate arbitrary additional
formula constructs (\cref{sec:extensions}).

We then show how to incrementally compute and maintain fixpoints
(\cref{sec:fixpoints}). We use this to perform incremental evaluation and
maintenance of \emph{recursive} program semantics, including generalized
recursive Datalog (\cref{sec:recursiveDatalog}). This provides, to the best
of our knowledge, the world's first incremental
evaluation and maintenance mechanism for Datalog that can handle negation,
disjunction, and existential quantification. 

Finally, we provide a few remarks about the categorical structure of change
actions (\cref{sec:category}).

We have omitted the proofs from this paper. Most of the results have routine
proofs, but the proofs of the more substantial results
(especially those in \cref{sec:fixpoints}) are included in an appendix.

\section{Change actions and derivatives}
\label{sec:changeActions}

Incremental computation requires understanding how values \emph{change}. For
example, we can change an integer by adding a natural to it.
Abstractly, we have a set of values (the integers), and a set of changes
(the naturals) which we can ``apply'' to a value (by addition) to get a new value.

This kind of structure is well-known \textemdash{} it describes a set action. It is
also very natural to want to combine changes sequentially, and if we do this
then we find ourselves with a monoid action.\footnote{
Using monoid actions for change sets gives us a reason to think that
change actions are an adequate representation of changes: any subset of $A
\rightarrow A$ which is closed under composition can be
represented as a monoid action on $A$, so we are able to capture all of these as change
actions.}

\subsection{Change actions}
\label{sec:changeAction}

\begin{defn}[Change actions]
  A \emph{change action} is defined as:
  \begin{displaymath}
    \cstr{A} \defeq \cstruct{A}{\changes{A}}{\cplus_A}
  \end{displaymath}
  where $A$ is a set, $\changes{A}$ is a monoid, and $\cplus_A : A \times \changes{A} \rightarrow A$ is a monoid action on $A$.\footnote{Why not
    just work with monoid actions? The reason is that while the category of
    monoid actions and the category of change actions have the same objects, they
  have different morphisms. See \cref{sec:sacts} for further discussion.}

  We will call $A$ the base set, and $\changes{A}$ the \emph{change set} of the change
  action. We will use $\splus$ for the monoid operation of $\changes{A}$, and
  $\mzero$ for its identity element. 
  When there is no risk of confusion, we will simply write $\cplus$ for $\cplus_A$.
\end{defn}

\subsubsection{Examples}
\label{sec:examples}
A typical change action is $\cstruct{A^\ast}{A^\ast}{\doubleplus}$ where $A^\ast$ is the set of finite words (or lists) of $A$. 
Here we represent changes to a word made by concatenating another word onto it. 
The changes themselves can be combined using $\doubleplus$ as the monoid operation with the empty word as the identity, 
and this is a monoid action: $(a \doubleplus b) \doubleplus c = a \doubleplus \left( b \doubleplus c \right)$.

This is a very common case: any monoid $(A, \splus, 0)$ can be seen as a change action
$\cstruct{A}{A}{\splus}$. Many practical change actions
can be constructed in this way. In particular, for any change action $\cstruct{A}{\changes{A}}{\cplus}$,
$\cstruct{\changes{A}}{\changes{A}}{\splus}$ is also a change action. This means
that we don't have to do any extra work to talk about changes to changes \textemdash{} we can 
always take $\changes{\changes{A}} = \changes{A}$.

%Within this category of change actions, three are of particular interest to us. 
Three examples of change actions are of particular interest to us.
First, whenever
$L$ is a Boolean algebra, we can give it the change actions $(L, L, \vee)$ and $(L, L, \wedge)$, 
as well as a combination of these (see \cref{sec:booleanAlgebras}). Second,
the natural numbers with addition have a change action $\cstr{\NN} \defeq (\NN, \NN, +)$, which we will
use to define a derivative for an iteration function in \cref{sec:iteration}.

Another interesting example of change actions is \textit{semiautomata}. A semiautomaton is a triple
$(Q, \Sigma, T)$, where $Q$ is a set of states, $\Sigma$ is a (non-empty) finite input alphabet
and $T : Q \times \Sigma \rightarrow Q$ is a transition function. It's straightforward to check
that every semiautomaton corresponds to a change action $(Q, \Sigma^*, T^*)$ on the free monoid
over $\Sigma^*$, with $T^*$ being the free extension of $T$. Conversely, every change action $\cstr{A}$
whose change set $\Delta A$ is freely generated by a finite set corresponds to a semiautomaton.

Other recurring examples of change actions are:
\begin{itemize}
  \item $\cstr{A}_1 \defeq \cstruct{A}{M}{\lambda(a, \change{a}). a}$, where $M$ is any monoid,
    which we call the \emph{empty} change action on any base set, since it induces no changes at all.
  \item $\cstr{A}_\Rightarrow \defeq \cstruct{A}{A \rightarrow A}{\ev}$, where $A$ is an arbitrary
    set, $A \rightarrow A$ denotes the set of all functions from $A$ into itself, considered as
    a monoid under composition and $\ev$ is the usual evaluation map. We will call this the
    ``full'' change action on $A$ since it contains every possible non-redundant change.
\end{itemize}
These are particularly relevant because they are, in a sense, the ``smallest'' and ``largest''
change actions that can be imposed on an arbitrary set $A$.

Many other notions in computer science can be understood naturally in terms of change actions,
\emph{e.g.} databases and database updates, files and diffs, Git repositories and commits, even 
video compression algorithms that encode a frame as a series of changes to the previous frame.
\todomario{Maybe references on this}

\subsection{Derivatives}

When we do incremental computation we are usually trying to save ourselves some
work. We have an expensive function $f: A \rightarrow B$, which we've evaluated at some point
$a$. Now we are interested in evaluating $f$ after some change $\change{a}$ to
$a$, but ideally we want to avoid actually computing $f(a \cplus
\change{a})$ directly.

A solution to this problem is a function $\derive{f}: A \times \changes{A}
\rightarrow \changes B$, which given $a$ and $\change{a}$ tells us how to change
$f(a)$ to $f(a \cplus \change{a})$. We call this a \emph{derivative} of a function.

\begin{defn}[Derivatives]
  \label{def:derivative}
  Let $\cstr{A}$ and $\cstr{B}$ be change actions.
  A \emph{derivative} of a function $f: A \rightarrow B$ is a function $\derive{f}: A \times \changes{A} \rightarrow
  \changes{B}$ such that
  \begin{displaymath}
    f(a \cplus_A \change{a}) = f(a) \cplus_B \derive{f}(a, \change{a})
  \end{displaymath}
  A function which has a derivative is 
  \emph{differentiable}, and we will write $\cstr{A} \rightarrow \cstr{B}$ for
  the set of differentiable functions.\footnote{Note that we do not require that $\derive{f}(a,
    \change{a} \splus \change{b}) = \derive{f}(a, \change{a}) \splus \derive{f}(a
    \cplus \change{a}, \change{b})$. This is a natural condition, and almost all
    derivatives satisfy it, but we have not found it to be necessary so far.}
\end{defn}

Derivatives need not be unique in general, so we will speak of ``a''
derivative.\footnote{In several places we will need to pick an arbitrary
  derivative for some construction. In general this needs the Axiom of Choice,
  but in most practical cases we will want to have a computable derivative
  operator for our domain, which alleviates the problem.} A ``thin'' change
action \textemdash{} where $a \cplus \change{a} = a \cplus \change{b}$ implies $\change{a} =
\change{b}$ \textemdash{} has unique derivatives, but many change actions are not thin.
For example, because $\{0\} \cap \{1\} = \{0\}
\cap \{2\}$, $\cstruct{\powerset{\NN}}{\powerset{\NN}}{\cap}$ is not thin.

Derivatives capture the structure of incremental computation, but there are
important operational considerations that affect whether they actually save us
any work. As we will see in a moment (\cref{prop:minusDerivatives}), for many 
change actions we will always have the option
of picking the ``worst'' derivative which merely computes $f(a \cplus \change{a})$
directly and then works out the change that maps $f(a)$ to this new value. 
While this is a derivative formally, it certainly does not save us any work! We will be concerned at
various points with both the possibility of constructing correct derivatives
(\cref{sec:booleanAlgebras} and \cref{sec:fixpoints} in particular), and also in
giving ourselves a range of derivatives to choose from so that we can soundly
optimize for operational value.

\todompj{signposting}

For our Datalog case study, we aim to construct a good derivative for the semantics of
different Datalog constructs. We will show in later sections how to do this for both the
non-recursive (\cref{sec:nonRecursiveDatalog}) and the full, recursive, semantics of Datalog
(\cref{sec:recursiveDatalog}).

\subsection{Useful facts about change actions and derivatives}

\subsubsection{The Chain Rule}

The derivative of a function can be computed compositionally, because derivatives satisfy the standard chain rule.

\begin{thm}[The Chain Rule]
  Let $f: \cstr{A} \rightarrow \cstr{B}$, $g: \cstr{B} \rightarrow \cstr{C}$ be differentiable functions. Then $g \circ f$ is also
  differentiable, with derivative given by
  \begin{displaymath}
    \derive{(g \circ f)}(x, \change{x}) = \derive{g}\left(f(x), \derive{f}(x, \change{x})\right)
  \end{displaymath}
  or, in curried form
  \begin{displaymath}
    \derive{(g \circ f)}(x) = \derive{g}(f(x)) \circ \derive{f}(x)
  \end{displaymath}
\end{thm}

\subsubsection{Complete change actions and minus operators}

Complete change actions are an important class of change actions, because they
have changes between \emph{any} two values in the base set.

\begin{defn}[Complete change actions]
  A change action is \emph{complete} if for any $a, b \in A$, there is
  a change $\change{a} \in \changes{A}$ such that $a \cplus \change{a} = b$.
\end{defn}

Complete change actions have convenient ``minus operators'' that allow us to
compute the difference between two values.

\begin{defn}[Minus operator]
  A \emph{minus operator} is a function $\cminus: A \times A \rightarrow
  \changes{A}$ such that $a \cplus (b \cminus a) = b$ for all $a, b \in A$.
\end{defn}

\begin{prop}[Completeness equivalences]
  Let $\cstr{A}$ be a change action. Then the following are equivalent:
  \begin{itemize}
    \item $\cstr{A}$ is complete.
    \item There is a minus operator on $\cstr{A}$.
    \item Any function $f: {B} \rightarrow {A}$ is differentiable, where $\cstr{B}$ is an arbitrary change action.
  \end{itemize}
\end{prop}

This last property is of the utmost importance, since we are often concerned with the differentiability
of functions.

\begin{prop}[Minus derivative]
  \label{prop:minusDerivatives}
  Given a minus operator $\cminus$, and a function $f$, let
  \begin{displaymath}
    \derive{f}_\cminus(a, \change{a}) \defeq f(a \cplus \change{a}) \cminus f(a)
  \end{displaymath}
  Then $\derive{f}_\cminus$ is a derivative for $f$.
\end{prop}

\subsubsection{Products and sums}

Given change actions on sets $A$ and $B$, the question immediately arises of whether there are
change actions on their Cartesian product $A \times B$ or disjoint union $A + B$. While there are
many candidates, there is a clear ``natural'' choice for both.

\begin{prop}[name=Products, restate=products]
  \label{prop:products}
  Let $\cstr{A} = \cstruct{A}{\changes{A}}{\cplus_A}$ and $\cstr{B} =
  \cstruct{B}{\changes{B}}{\cplus_B}$ be change actions,
  and let $\cplus_{\times} : (A \times B) \times (\changes A \times \changes B)$ be defined by
  \begin{align*}
    (a, b) \cplus_{A \times B} (\change{a}, \change{b}) \defeq (a \cplus_A \change{a}, b \cplus_B \change{b})
  \end{align*}
  Then $\cstr{A} \times \cstr{B} \defeq \cstruct{A \times B}{\changes{A} \times
  \changes{B}}{\cplus_{\times}}$ is a change action, and the projection maps $\pi_1$,$\pi_2$
  are differentiable with respect to it.

  Furthermore, a function 
  $f : A \times B \into C$ is differentiable from $\cstr{A} \times \cstr{B}$ into $\cstr{C}$ if
  and only if, for every fixed $a \in A$ and $b \in B$, the partially applied functions 
  \begin{align*}
    f(a, \cdot) : B \into C\\
    f(\cdot, b) : A \into C
  \end{align*}
  are differentiable.
\end{prop}

Whenever $f : A \times B \rightarrow C$ is differentiable, we will sometimes use $\partial_1 f$ and
$\partial_2 f$ to refer to the derivatives of the partially applied versions, i.e. if
$f'_a : B \times \changes{B} \rightarrow \changes{C}$ and
$f'_b : A \times \changes{A} \rightarrow \changes{C}$ refer to derivatives for 
$f(a, \cdot), f(\cdot, b)$ respectively, then
\begin{gather*}
  \partial_1 f : A \times \changes{A} \times B \rightarrow \changes{C}\\
  \partial_1 f(a, \change{a}, b) \defeq f'_b(a, \change{a})\\
  \partial_2 f : A \times B \times \changes{B} \rightarrow \changes{C}\\
  \partial_2 f(a, b, \change{b}) \defeq f'_a(b, \change{b})
\end{gather*}

\ifproofs
\begin{proof}
  See \cref{prf:products}.
\end{proof}
\fi

\begin{prop}[name=Disjoint unions, restate=disjointUnions]
  \label{prop:disjointUnions}
  Let $\cstr{A} = \cstruct{A}{\changes{A}}{\cplus_A}$ and $\cstr{B} =
  \cstruct{B}{\changes{B}}{\cplus_B}$ be change actions.

  Then $\cstr{A} + \cstr{B} \defeq \cstruct{A + B}{\changes{A} \times
  \changes{B}}{\cplus_{+}}$ is a change action, where is $\cplus_{+}$ defined as:
  \begin{align*}
    \iota_1 a \cplus_{+} (\change{a}, \change{b}) &\defeq \iota_1 (a \cplus_A \change{a})\\
    \iota_2 b \cplus_{+} (\change{a}, \change{b}) &\defeq \iota_2 (b \cplus_B \change{b})
  \end{align*}
  
  The injection maps $\iota_1, \iota_2$ are differentiable with respect to $\cstr{A} + \cstr{B}$. Furthermore,
  whenever $\cstr{C}$ is a change action and $f : A \rightarrow C, g: B \rightarrow C$ are differentiable,
  then so is $\left[ f, g \right]$.
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:disjointUnions}.
\end{proof}
\fi

\subsection{Comparing change actions}
\todomario{
  Not sure if this should go in, but we have the space for it, 
  and we talk about change actions being ``equivalent'' later on so we might as well explain
  what that means, since we can spare the space.
}

Much like topological spaces, we can compare change actions on the same
base set according to coarseness. This 
is useful since differentiability of functions between change actions is characterized
entirely by the coarseness of the actions.

\begin{defn}[Finer and coarser change actions]
  Let $\cstr{A}_1$ and $ \cstr{A}_2$ be 
  change actions. We say that $\cstr{A}_1$ is coarser than $\cstr{A}_2$ (or that $\cstr{A}_2$ is finer
  than $\cstr{A}_1$) whenever for every pair of points $x, y : A$ and change $\change{a}_1 : \changes{A}_1$
  such that $x \cplus \change{a}_1 = y$, there is a change $\change{a}_2 : \changes{A}_2$ such that $x \cplus \change{a}_2 = y$.
  
  We will write $\cstr{A}_1 \leq \cstr{A}_2$ whenever $\cstr{A}_1$ is coarser than $\cstr{A}_2$.
  If $\cstr{A}_1$ is both finer and coarser than $\cstr{A}_2$, we will say that $\cstr{A}_1$
  and $\cstr{A}_2$ are equivalent.
\end{defn}

The relation $\leq$  defines a preorder (but not a partial order) on the set of all change actions 
over a fixed set A. Least and greatest elements do exist up to equivalence, and correspond
respectively to the empty change action $\cstr{A}_1$ and any complete change
action, such as the change action $\cstr{A}_\Rightarrow$,
defined in \cref{sec:changeAction}.

\begin{prop}[Variance and coarseness]
  Let $\cstr{A}_2 \leq \cstr{A}_1$, $\cstr{B}_1 \leq \cstr{B}_2$ be change actions, and suppose
  the function $f : A \rightarrow B$ is differentiable as a function from $\cstr{A}_1$ into
  $\cstr{B}_1$. Then $f$ is differentiable as a function from $\cstr{A}_2$ into $\cstr{B}_2$.
\end{prop}

A straightforward consequence of this fact is that, whenever two change actions are equivalent,
they can be used interchangeably without affecting which functions are differentiable. One last parallel with topology
is the following result, which establishes a simple criterion for when a change action is coarser than
another:

\begin{prop}[Identity criterion]
  Let $\cstr{A}_1, \cstr{A}_2$ be change actions on $A$. Then $\cstr{A}_1$ is coarser than $\cstr{A}_2$
  if and only if the identity function $\id : A \rightarrow A$ is differentiable from $\cstr{A}_1$ to
  $\cstr{A}_2$.
\end{prop}

\subsection{Change kernels and kernel orderings}

Consider the full change action $\cstr{\ZZ}_\Rightarrow$ on the integers.
If one wishes to find a change that transports $0$ to $1$, there
are a few options available: for example, one can pick the function $\lambda x . 1$, or
the function $\lambda x . x + 1$. Clearly, the second one is more natural, since
it does the minimum amount of ``effort''.

This intuition that a change may do too much can be captured %in an elegant way 
by the following definition:
\begin{defn}[Kernel of a change]
  Let $\cstr{A}$ be a change action and $\change{a} : \changes{A}$. Then the
  \emph{kernel} of $\change{a}$ is the equivalence relation $\kernel_{\change{a}}$ on $A$
  %: \mathcal{P}(A \times A)$ 
  defined by
  \begin{displaymath}
    a \kernel_{\change{a}} b \defeq
     a \cplus \change{a} = b \cplus \change{a}
  \end{displaymath}
  The \emph{kernel ordering} on $\changes{A}$ is defined by
  \begin{displaymath}
 {\change{a} \kernelOrder \change{b}} \defeq {{\kernel_{\change{a}}} \subseteq {\kernel_{\change{b}}}}
  \end{displaymath}
\end{defn}

As we will see later (\cref{sec:booleanAlgebras}), minimal derivatives under
the kernel order correspond to ``precise'' derivatives, in the sense of derivatives that do not perform
excessive work.

\section{Posets and Boolean algebras}
\label{sec:moreStructures}

\todompj{signposting}

The semantic domain of Datalog is a complete Boolean algebra, and so our first step needs
to be to construct a good change action for Boolean algebras. Along the way, we
will consider change actions over posets, which give us the ability to
\emph{approximate} derivatives, which will turn out to be very important in practice.

\subsection{Posets}

Ordered sets give us a constrained class of functions: monotone
functions. We can define \emph{ordered} change actions, which are those that
are well-behaved with respect to the order on the underlying set.
\footnote{If we were giving a presentation that was
generic in the base category, then this would simply be the definition of being
a change action in the category of posets and monotone maps.}

\begin{defn}[Ordered change actions]
  A change action $\cstr{A}$ is \emph{ordered} if
  \begin{itemize}
    \item $A$ and $\changes{A}$ are posets.
    \item $\cplus$ is monotone as a map from $A \times \changes{A} \rightarrow A$
    \item $\splus$ is monotone as a map from $\changes{A} \times \changes{A} \rightarrow \changes{A}$
  \end{itemize}
\end{defn}

In fact, any change action whose base set is a poset induces a particularly convenient partial order
on the corresponding change set:

\begin{defn}[Change order]
  $\change{a} \changeOrder \change{b}$ just if for all $a : A$ it is the case that
  $a \cplus \change{a} \leq a \cplus \change{b}$.
\end{defn}

\begin{prop}
  Let $\cstr{A}$ be a change action on a set $A$ equipped with a partial order $\leq$ such that
  $\cplus$ is monotone in its first argument. Then $\cstr{A}$ is an ordered change action when
  $\changes{A}$ is equipped with the partial order $\changeOrder$.
\end{prop}

In what follows, we will extend the partial order $\changeOrder$ on some change
set $\changes{B}$ pointwise to functions from some $A$ into $\changes{B}$. This pointwise
order interacts nicely with derivatives, in that it gives us the following lemma:

\begin{thm}[Sandwich lemma]
  \label{thm:sandwich}
  Let $\cstr{A}$ be an change action, $\cstr{B}$ be an ordered change action,
  $f: \cstr{A} \rightarrow \cstr{B}$, and $g: A \times \changes{A} \rightarrow
  \changes{B}$. If $\supderive{f}$ and $\subderive{f}$ are
  derivatives for $f$ such that
  \begin{displaymath}
    \supderive{f} \changeOrder g \changeOrder \subderive{f}
  \end{displaymath}
  then $g$ is a derivative for $f$.
\end{thm}

If unique minimal and maximal derivatives exist, then this gives us a 
characterisation of all the derivatives for a function.

\begin{thm}[Characterization of derivatives]
\label{thm:derivativeCharacterization}
  Let $\cstr{A}$ and $\cstr{B}$ be change actions, with $\cstr{B}$ ordered, and let
  $f: \cstr{A} \rightarrow \cstr{B}$ be a function. If there exist $\subderiveM{f}$ and
  $\supderiveM{f}$ which are unique minimal and maximal derivatives of $f$,
  respectively, then the derivatives of $f$ are precisely
  the functions $\derive{f}$ such that
  \begin{displaymath}
    \subderiveM{f} \changeOrder \derive{f} \changeOrder \supderiveM{f}
  \end{displaymath}
\end{thm}
\ifproofs
\begin{proof}
  Follows easily from \cref{thm:sandwich} and minimality/maximality.
\end{proof}
\fi

This theorem gives us the leeway that we need when trying to pick a derivative: we can pick out the
bounds, and that tells us how much ``wiggle room'' we have above and below.

\subsection{Boolean algebras}
\label{sec:booleanAlgebras}

\todompj{signposting}

Complete Boolean algebras are of special interest to us due to their role in modelling the semantics of
Datalog programs. Conveniently, these structures have a complete change action.

\begin{prop}[name=Boolean algebra change actions, restate=lsuperpose]
 Let $L$ be a complete Boolean algebra. Define
  \begin{displaymath}
    \cstr{L}_\superpose \defeq \cstruct{L}{L \disjointTimes L}{\twist}
  \end{displaymath}
  where
  \begin{align*}
    A \disjointTimes B &\defeq \{ (a, b) : A \times B \mid a \wedge b = \bot \}\\
    a \twist (p, q) &\defeq (a \vee p) \wedge \neg q
  \end{align*}
  and the monoid operator is
  \begin{displaymath}
    (p, q) \splus (r, s) \defeq ((p \wedge \neg s) \vee r, (q \wedge \neg r) \vee s)
  \end{displaymath}
  with identity element $(\bot, \bot)$.

  Then $\cstr{L}_\superpose$ is a complete change action on $L$.
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:lsuperpose}.
\end{proof}
\fi

We can think of $\cstr{L}_\superpose$ as tracking changes as pairs of ``upwards'' and
``downwards'' changes, where the monoid action simply applies one after the
other, with an adjustment to make sure that the components remain disjoint.\footnote{
  The intuition that $\cstr{L}_\superpose$ is made up of an ``upwards''
  and a ``downwards'' change action glued together can in fact be made precise, but the specifics
  are outside the scope of this paper.}

Boolean algebras also have unique maximal and minimal
derivatives, under the usual preorder based on implication.\footnote{The change
set is, as usual, given the change preorder, which in this case corresponds to
the natural order on $L \times L^{\textrm{op}}$.}

\begin{prop}
  \label{prop:minimalMaximalDerivatives}
  Let $L$ be a (complete) Boolean algebra with the $\cstr{L}_\superpose$ change action, and
  $f: A \rightarrow L$ a function.
  Then, the following are minus operators:
  \begin{align*}
    a \cminus_\bot b &= (a \wedge \neg b, \neg a)\\
    a \cminus_\top b &= (a, b \wedge \neg a)
  \end{align*}
  Additionally, $\derive{f}_{\cminus_{\bot}}$ and $\derive{f}_{\cminus_{\top}}$ 
  define least and greatest derivatives for $f$.
\end{prop}

\Cref{thm:derivativeCharacterization} then gives us bounds for
all the derivatives on Boolean algebras:

\begin{corollary}
\label{cor:booleanCharacterization}
  Let $L$ be a (complete) Boolean algebra with the corresponding change action
  $\cstr{L}_\superpose$, $A$ be an arbitrary change action, and $f: A \rightarrow
  L$ be a function. Then the derivatives of $f$ are precisely those functions
  $\derive{f}: A \times \changes{A} \rightarrow \changes{A}$ such that
  \begin{displaymath}
    \derive{f}_{\cminus_{\bot}}
    \changeOrder
    \derive{f}
    \changeOrder
    \derive{f}_{\cminus_{\top}}
  \end{displaymath}
\end{corollary}

This makes \cref{thm:derivativeCharacterization} actually usable in practice, since
we have concrete definitions for our bounds (which we will make use of in \cref{sec:datalogDifferentiability}).

Moreover, we have a nice definition of the kernel ordering, which gives us a
minus operator with a corresponding \emph{precise} derivative.

\todompj{Proof. The second part follows easily from the charaterization of
  $\kernelOrder$. Pretty sure it's true!}

\begin{prop}
  Let $L$ be a (complete) Boolean algebra with the $\cstr{L}_\superpose$ change action, and
  $f: A \rightarrow L$ a function.

  Then $(p, q) \kernelOrder (r, s)$ iff $p \leq r$ and $q \leq s$.

  Additionally, the following is a minus operator:
  \begin{displaymath}
    a \cminus_\kernel b = (a \wedge \neg b, b \wedge \neg a)
  \end{displaymath}

  Moreover $\derive{f}_{\cminus_\kernel}$ is a minimal derivative of $f$ with respect to $\kernelOrder$.
\end{prop}

This shows us in what sense minimality with respect to the kernel orering gives
us precision: the derivative is precise in that the components are as small as
possible.

\section{Derivatives for non-recursive Datalog}
\label{sec:nonRecursiveDatalog}

\todompj{signposting}

We now want to apply the theory we have developed to the specific case of the semantics
of Datalog. Giving a differentiable semantics for Datalog will then
lead us to a strategy for performing incremental evaluation and maintenance of Datalog programs. 
To begin with, we will restrict ourselves to the non-recursive fragment of the
language \textemdash{} the formulae that make up the right hand sides of Datalog
rules. We will tackle the full program semantics in a later section, once we
know how to handle fixpoints (\cref{sec:recursiveDatalog}).

Although the techniques we are using should work for any language, Datalog
provides a non-trivial case study where the need for incremental computation is
real and pressing, as we saw in \cref{sec:intro}.

\subsection{Semantics of Datalog formulae}

Datalog is usually given a logical semantics where formulae are interpreted as first-order
logic predicates and the semantics of a program is the set of models of its constituent
predicates. We will instead give a simpler denotational semantics that treats a Datalog
formula (and later, a Datalog program) as directly denoting a relation, i.e.
a set of named tuples over a certain schema.

We will adopt the usual closed-world assumption to give a denotation to negation.

\begin{defn}[Closed-world assumption and negation]
  For any schema $\Gamma$ (i.e. a finite set of names),
  there exists a universal relation $\universalRel_\Gamma$.

  Negation on relations is defined as
  \begin{displaymath}
    \neg R \defeq \universalRel_\Gamma \setminus R
  \end{displaymath}
\end{defn}

This makes $\Rel_\Gamma$, the set of all subsets of $\universalRel_\Gamma$ with schema $\Gamma$,
into a complete Boolean algebra.

The semantics of Datalog formulae are usually given in terms of satisfaction by
structures. We would like to use a more denotational semantics (as is typical
when working with fixpoints \autocite[see e.g.][]{compton1994stratified}). We give a semantics
which is parmeterized by the assignments to the free relation variables.

\begin{figure}
  \fbox{
    \begin{minipage}[t]{0.9\textwidth}
      \vspace{-5pt}
      \begin{minipage}[t]{.45\textwidth}
      \begin{align*}
        \sem{\top}_\Gamma(\semR) &\defeq \universalRel_\Gamma\\
        \sem{\bot}_\Gamma(\semR) &\defeq \emptyset\\
        \sem{R_j}_\Gamma(\semR) &\defeq \semR_j\\
      \end{align*}
    \end{minipage}\hfill\noindent
    \begin{minipage}[t]{.45\textwidth}
      \begin{align*}
        \sem{T \wedge U}_\Gamma(\semR) &\defeq \sem{T}_\Gamma(\semR) \cap \sem{U}_\Gamma(\semR)\\
        \sem{T \vee U}_\Gamma(\semR) &\defeq \sem{T}_\Gamma(\semR) \cup \sem{U}_\Gamma(\semR)\\
        \sem{\neg T}_\Gamma(\semR) &\defeq \universalRel_\Gamma \setminus \sem{T}_\Gamma(\semR)\\
      \end{align*}
    \end{minipage}
    \vspace{-12pt}
    \begin{align*}
      \sem{\exists x . T}_\Gamma(\semR) &\defeq \sigma(\sem{T}_{\Gamma, x})
    \end{align*}
    \end{minipage}
  }
  \caption{Formula semantics for Datalog}
  \label{fig:datalogSemantics}
  \vspace{-12pt}
\end{figure}

\begin{defn}[Formula semantics]
  A Datalog formula $T$ whose free term variables are contained in $\Gamma$ denotes a function from 
  its free relation variables $R_1, \ldots, R_n$ 
  to $\Rel_\Gamma$.
  \begin{displaymath}
    \denote{\_}_\Gamma : \Formula_\Gamma \rightarrow \Rel_\Gamma^n \rightarrow \Rel_\Gamma
  \end{displaymath}
  If $\semR = (\semR_1, \ldots, \semR_n)$ is a choice of a relation for each of the variables $R_i$,
  $\denote{T}(\semR)$ is inductively defined according to the rules in \cref{fig:datalogSemantics}.
  \lo{TODO: Define the function $\sigma$ in  \cref{fig:datalogSemantics}.}
\end{defn}

Since $\Rel_\Gamma$ is a complete Boolean algebra, and so is $\Rel_\Gamma^n$, $\denote{T}_\Gamma$ is
a function between complete Boolean algebras. For brevity, we will often leave the schema implicit,
as it is clear from the context.

\subsection{Differentiability of Datalog formula semantics}
\label{sec:datalogDifferentiability}

In order to perform incremental evaluation, we first need to provide derivatives for the semantics
of Datalog formulae. Since $\denote{T}_\Gamma$ is a function between the complete Boolean algebras 
$\Rel_\Gamma^n$ and
$\Rel_\Gamma$, and we know that the corresponding change actions 
$\widehat{\Rel_\Gamma^n}_\superpose, \widehat{\Rel_\Gamma}_\superpose$
are complete, this immediately guarantees the existence of a derivative for $\denote{T}$.

Unfortunately, this does not necessarily provide us with a way to compute an \emph{efficient} 
derivative for $\denote{T}$. The precise derivative that we know how to compute relies on
a minus operator:
\begin{displaymath}
  \derive{f}_{\cminus_\kernel}(a, \change{a}) = f(a \cplus \change{a}) \cminus_\kernel f(a)
\end{displaymath}

Naively computed, this expression requires computing $f(a \cplus \change{a})$
itself, which is the very thing we were trying to avoid computing!

Of course, given a concrete definition of $\cminus_\kernel$ we can simplify this
expression and hopefully make it easier to compute. But we also know from
\cref{cor:booleanCharacterization} that \emph{any} function bounded by
$\derive{f}_{\cminus_\bot}$ and $\derive{f}_{\cminus_\top}$ is a valid derivative,
and we can therefore weaken our derivative within that range to make a 
trade-off between ease of computation and precision.

In the case of Datalog, the change preorder on the change action also
corresponds to the size of the derivative as a pair of relations. The minimal (precise)
derivative contains only the elements that are newly added or removed,
whereas the maximal derivative contains all the elements that have \emph{ever}
been added or removed but not re-added. This means that \cref{cor:booleanCharacterization} allows
us to \emph{approximate} the precise derivative while still being
guaranteed that the result is sound.\footnote{The idea of using an approximation
to the precise derivative, and a soundness condition, appears in \textcite{bancilhon1986amateur}.}

There is also the question of how to compute the derivative. Since the change
set for $\widehat{\Rel}_\superpose$ is a subset of $\Rel \times \Rel$, it
is possible and indeed very natural to compute the two components via a pair of
Datalog formulae, which allows us to reuse an existing Datalog formula
evaluator.\footnote{
  Indeed, if this process is occurring in an optimizing compiler,
  the derivative formulae can themselves be optimized. This is very 
  beneficial in practice, since the initial formulae may be quite complex.}

This does give us additional constraints that the derivative formulae must satisfy:
for example, we need to be able to evaluate them; and we may wish to pick formulae that will be easy or cheap
for our evaluation engine to compute, even if they compute a less precise derivative.

The upshot of these considerations is that the optimal choice of derivatives is likely
to be quite dependent on the precise variant of Datalog being evaluated, and the
specifics of the evaluation engine. Here is one possibility.\footnote{This is
  the derivative actually in use at Semmle. We arrived at it by starting with the
  minimal derivative and then simplifying and weakening it while preserving the
  soundness bound given by the maximal derivative.}

\subsubsection{A concrete Datalog formula derivative}

We define here a ``symbolic'' derivative operator as a pair of mutually recursive functions,
$\updiff$ and $\downdiff$, which turn a formula $T$ into new formulae that compute
the upwards and downwards parts of the derivative, respectively. As we expect
from a derviative, the new formulae will have additional free relation variables
for the upwards and downwards derivatives of the free relation variables of $T$.
\footnote{While the definitions usually exhibit the dualities we would expect
  between corresponding operators, there are a few asymmetries to explain.

  The asymmetry between the cases for $\updiff(T \vee U)$ and
  $\downdiff(T \wedge U)$ is for operational reasons. The symmetrical version of
  $\updiff(T \vee U)$ is $(\updiff(T) \wedge \neg U) \vee (\updiff(U) \wedge \neg
  T)$ (which is also precise). The reason we omit the negated conjuncts is simply
  that they are costly to commpute and not especially helpful to our evaluation engine.

  The asymmetry between the cases for $\exists$ is because our
  dialect of Datalog does not have a primitive universal quantifier.
  If we did have one, the cases for $\exists$ would be dual to the corresponding
  cases for $\forall$.}

%\newcommand{\bothdiff}{\diamond}
\newcommand{\bothdiff}{{\mathsf X}} 

We will make use of an auxilliary function, $\bothdiff$, which computes the
``neXt'' value of a term by applying the upwards and downwards derivatives.

\newcommand{\bothchanges}{\rho}
\begin{thm}[name=Concrete Datalog formula derivatives, restate=concreteDatalog]
\label{thm:concreteDatalog}
  Let $\updiff, \downdiff, \bothdiff : \Formula \rightarrow \Formula$ be mutually recursive functions
  defined by structural induction as in \cref{fig:datalogDerivatives}.

  Then for any schema $\Gamma$ and any Datalog formula $T$ whose free term variables are contained
  in $\Gamma$,
  $\derive{\denote{T}_\Gamma} \defeq (\denote{\updiff(T)}_\Gamma, \denote{\downdiff(T)}_\Gamma)$
  is a derivative for $\denote{T}_\Gamma$.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:concreteDatalog}
\end{proof}
\fi

\begin{figure}
  \fbox{
    \begin{minipage}[t]{0.9\textwidth}
    \vspace{-5pt}
    \begin{minipage}[t]{.45\textwidth}
      \begin{align*}
        \updiff(\bot) &\defeq \bot\\
        \updiff(\top) &\defeq \bot\\
        \updiff(R_j) &\defeq \updiff R_j \\
        \updiff(T\vee U) &\defeq \updiff(T) \vee \updiff (U) &(\dagger)\\
        \updiff(T\wedge U) &\defeq (\updiff(T)\wedge \bothdiff(U))\\
                            & \vee (\updiff(U) \wedge \bothdiff(T))\\
        \updiff(\neg T) &\defeq \downdiff(T)\\
        \updiff(\exists x.T) &\defeq \exists x.\updiff(T) &(\dagger)
      \end{align*}
    \end{minipage}\hfill\noindent
    \begin{minipage}[t]{.45\textwidth}
      \begin{align*}
        \downdiff(\bot) &\defeq \bot\\
        \downdiff(\top) &\defeq \bot\\
        \downdiff(R_j) &\defeq \downdiff R_j \\
        \downdiff(T\vee U) &\defeq (\downdiff(T) \wedge \neg \bothdiff(U))\\
                              & \vee (\downdiff(U) \wedge \neg \bothdiff(T))\\
        \downdiff(T\wedge U) &\defeq (\downdiff(T)\wedge U) \vee (T \wedge \downdiff(U))\\
        \downdiff(\neg T) &\defeq \updiff(T)\\
        \downdiff(\exists x.T) &\defeq \exists x.\downdiff(T) \wedge \neg \exists x.\bothdiff(T)
      \end{align*}
    \end{minipage}
    \vspace{6pt}
    \begin{align*}
      \bothdiff(X) \defeq X \twist (\updiff(X), \downdiff(X))
    \end{align*}
    \end{minipage}
  }
  \caption{Upwards and downwards formula derivatives for Datalog}
  \label{fig:datalogDerivatives}
  \vspace{-12pt}
\end{figure}

\subsubsection{Examples}

We can now give a derivative for our $treeP$ predicate (assuming only changes to
$treeP$ itself):
\begin{align*}
  &\updiff(treeP(x))\\
  &= \updiff(p(x) \wedge \neg \exists y. (child(x, y) \wedge \neg treeP(y)))\\
  &= p(x) \wedge \updiff(\neg \exists y. (child(x, y) \wedge \neg treeP(y)))\\
  &= p(x) \wedge \downdiff(\exists y. (child(x, y) \wedge \neg treeP(y)))\\
  &= p(x) \wedge \exists y. \downdiff(child(x, y) \wedge \neg treeP(y)) \wedge \neg \exists y. \bothdiff(child(x,y) \wedge \neg treeP(y))\\
  &= p(x) \wedge \exists y. (child(x, y) \wedge \downdiff(\neg treeP(y))) \wedge \neg \exists y. (child(x,y) \wedge \neg \bothdiff(treeP(y)))\\
  &= p(x) \wedge \exists y. (child(x, y) \wedge \updiff(treeP(y))) \wedge \neg \exists y. (child(x,y) \wedge \neg \bothdiff(treeP(y)))\\
  \\
  &\downdiff(treeP(x))\\
  &= \downdiff(p(x) \wedge \neg \exists y. (child(x, y) \wedge \neg treeP(y)))\\
  &= p(x) \wedge \downdiff(\neg \exists y. (child(x, y) \wedge \neg treeP(y)))\\
  &= p(x) \wedge \updiff(\exists y. (child(x, y) \wedge \neg treeP(y)))\\
  &= p(x) \wedge \exists y. \updiff(child(x, y) \wedge \neg treeP(y))\\
  &= p(x) \wedge \exists y. (child(x, y) \wedge \updiff(\neg treeP(y)))\\
  &= p(x) \wedge \exists y. (child(x, y) \wedge \downdiff(treeP(y)))
\end{align*}

The upwards difference in particular is not especially easy to compute. If we naively compute it, the
third conjunct requires us to recompute the whole of the recursive part. However,
the second conjunct gives us a
guard: we only need to evaluate the third conjunct if the second conjunct is
non-empty, i.e there is \emph{some} change in the body of the existential.

This shows that our derivatives aren't a panacea: it is simply \emph{hard} to compute
downwards differences for $\exists$ (and, equivalently, upwards differences for
$\forall$) because we must check that there is no other way of deriving the same
facts.\footnote{The ``support'' data structures introduced by
  \autocite{gupta1993maintaining} are an attempt to avoid this issue by
  tracking the number of derivations of each tuple.} However, we can still avoid
the re-evaluation in many cases, and the inefficiency is local to this subformula.

\subsubsection{Precision}

In practice, while the derivative given in \cref{thm:concreteDatalog} is not
precise, most of the cases are \emph{preciseness-preserving}, in that if the
subsidiary recursive cases are precise, then so is that case. The only cases
which lose precision are labelled with $\dagger$.

\subsection{Extensions to Datalog}
\label{sec:extensions}

Our formulation of Datalog formula semantics and incremental evaluation is 
generic and modular, so it is easy to extend the language with new
formula constructs: all we need to do is add cases for $\updiff$ and $\downdiff$.

In fact, because we are using a complete change action, we can \emph{always} do this by using the maximal or
minimal derivative. This justifies our claim that we can support
\emph{arbitrary} additional formula constructs: although the maximal and minimal
derivatives are likely to be impractical, having them
available as options means that we will never be completely stymied.

This is important in practice for Semmle's variant of Datalog. This includes a
kind of aggregates which have well-defined recursive semantics. Aggregates have
the form
\begin{displaymath}
  r = \mathrm{agg}(p)(vs \mid T \mid U)
\end{displaymath}
where $\mathrm{agg}$ refers to an aggregation function (such as ``sum'' or
``min''), $vs$ is a sequence of variables, $p$ and $r$ are variables,
$T$ is a formula possibly mentioning $vs$, and $U$ is a formula
possibly mentioning $vs$ and $p$. The full details can been found in
\textcite{demoor2013aggregates}, but for example this allows us to write
\begin{align*}
  height(n, h) \leftarrow& \neg \exists c. (child(n, c)) \wedge d = 0\\
  &\vee \exists h'. (h' = max(p)(c \mid child(n, c) \mid height(c, p)) \wedge h = h' + 1)
\end{align*}
which recursively computes the height of a node in a tree.

Here is an upwards derivative for an aggregate formula:
\begin{align*}
  \updiff(r = \mathrm{agg}(p)(vs \mid T \mid U)) \defeq \exists vs. (T \wedge \updiff{U}) \wedge r = \mathrm{agg}(p)(vs \mid T \mid U)
\end{align*}

While this isn't a precise derivative, it is still substantially cheaper than
re-evaluating the whole subfomula, as the guard allows us to skip the second conjunct when $U$
has not changed.

\input{hodatalog}

\section{Changes on functions}

\todompj{signposting}

We would like to have a change action structure on function spaces. This would enable us
to discuss derivatives in the context of higher-order languages, but in particular derivatives for
fixpoint operators, which are higher-order functions $\fixpoint : (A \rightarrow A) \rightarrow A$. 

\todomario{Back-references}
Function spaces, however, differ from products and disjoint unions in that there is no obvious choice
of a ``best'' change action structure on $A \rightarrow B$, given change actions $\cstr{A}$ and $\cstr{B}$.
Instead of settling on a concrete choice of a change action, we restrict ourselves to working
with change actions that respect the structure of the function space in the following sense:

\begin{defn}[Functional change actions]
  \label{def:functionalChanges}
  Given change actions $\cstr{A}$ and $\cstr{B}$ and a set $U \subseteq A \rightarrow B$, a change action
  $(U, \changes U, \cplus_U)$ is \emph{functional} whenever the evaluation map $\ev : U \times A \rightarrow B$
  is differentiable, that is to say, whenever there exists a function 
  $\derive{\ev} : (U \times A) \times (\changes U \times \changes A) \rightarrow \changes{B}$ such that:
  \begin{displaymath}
    (f \cplus_U \change{f})(a \cplus_A \change{a}) = 
    f(a) \cplus_B \derive{\ev}((f, a), (\change{f}, \change{a}))
  \end{displaymath}
  
  We will write $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$ whenever 
  $U \subseteq A \rightarrow B$ and $\cstr{U}$ is functional.
\end{defn}

We have defined functional change actions on arbitrary subsets $U \subseteq A \rightarrow B$ for two
reasons. First, it will later allow us to restrict ourselves to spaces of monotone or continuous
functions. But more importantly, functional change actions are necessarily made up of differentiable
functions, and thus a functional change action may not exist for the entire function space
$A \rightarrow B$.

\begin{prop}[Differentiability and functional change actions]
  \label{prop:differentiableFunctionalChanges}
  Let $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$ be a functional change action. Then every 
  $f : U$ is differentiable, with a derivative $\derive{f}$ given by:
  \begin{displaymath}
    \derive{f}(x, \change{x}) = \derive{\ev}((f, x), (0, \change{x}))
  \end{displaymath}
\end{prop}

\iffalse
\todomario{
  The rest of this section won't go into the actual paper and can be deleted safely.
}
Conversely, the derivative of the evaluation map can also be used to compute the effect of a given
function change $\delta f$:
\begin{prop}[Evaluating function changes]
  Let $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$. Then for every $f : U$ and $\delta f : \changes U$
  we have:
  \begin{displaymath}
    (f \cplus \delta f)(x) = f(x) \cplus \ev'((f, x), (\delta f, 0))
  \end{displaymath}
\end{prop}

\begin{prop}[Functional change sets]
  Let $\cstr{A}$ and $\cstr{B}$ be change actions and $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$
  a functional change action. First, we note that the set $U \times A \rightarrow \Delta B$ is
  a monoid with addition $+_\Rightarrow$ and neutral element $0_\Rightarrow$ defined by:
  \begin{align*}
    (\upsilon f +_\Rightarrow \upsilon g)(h, x) 
    &\defeq \upsilon f (h, x) \cplus \upsilon g((\lambda x . \upsilon f (h, x)) , x)
  \end{align*}

  Every functional change action $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{B}$ is equivalent to
  a (functional) change action of the form $(U, W, \cplus_\Rightarrow)$ where:
  \begin{itemize}
  \item $W$ is the monoid generated by $V$ and $+_\Rightarrow$, where $V$ is defined as:
    \begin{gather*}
      V \subseteq U \times A \rightarrow \Delta B\\
      V \defeq \{~
          \lambda f. \lambda x. \ev'((f, x), (\delta f, 0)) ~|~ \delta f : \changes U
          ~\}\\
      (f \cplus_\Rightarrow \upsilon f)(x) \defeq f(x) \cplus \upsilon f(f, x)
    \end{gather*}
  \end{itemize}
\end{prop}
\fi

\subsection{Pointwise functional change actions}
\label{sec:pointwiseFunctional}

As we shall see later in \cref{sec:category}, one can always find functional change actions on the set
of differentiable functions $\cstr{A} \rightarrow \cstr{B}$, but these can be unwieldy for 
the purpose of actual computation. Fortunately, in many cases there is a simple
way of representing spaces of differentiable functions.

\begin{defn}[Pointwise functional change actions]
  Let $\cstr{A}$ and $\cstr{B}$ be change actions. The \emph{pointwise functional change action} 
  $\cstr{A} \ptfunc \cstr{B}$, when it is defined,
  is given by $(\cstr{A} \rightarrow \cstr{B}, A \rightarrow \changes{B}, \cplus_\rightarrow)$, with
  the monoid structure $(A \rightarrow \changes{B}, \splus_\rightarrow, 0_\rightarrow)$ and the action 
  $\cplus_\rightarrow$ defined by:
  \begin{align*}
    (f \cplus_\to \delta f)(x) &\defeq f(x) \cplus_B \delta f (x)\\
    (\delta f \splus_\rightarrow \delta g)(x) &\defeq \delta f(x) \splus_B \delta g(x)\\
    0_\rightarrow (x) &\defeq 0_B
  \end{align*}
\end{defn}

The above definition isn't always well-typed, since given $f : \cstr{A} \rightarrow \cstr{B}$ and
$\delta f : A \rightarrow \changes{B}$ there is, in general, no guarantee that 
$f \cplus_\rightarrow \delta f$ is differentiable. We present two simple criteria that enforce this:

\begin{thm}[Pointwise functional change actions]
  Let $\cstr{A}$ and $\cstr{B}$ be change actions, and suppose that $\cstr{B}$ satisfies one of the
  following conditions:
  \begin{itemize}
    \item $\cstr{B}$ is a complete change action.
    \item The change action $\widehat {\changes{B}} \defeq (\Delta B, \Delta B, \splus_B)$ is 
      complete and 
      $\cplus_B$ is differentiable as a map from $B \times \changes{B}$ into $B$
  \end{itemize}
  Then the pointwise functional change action 
  $(\cstr{A} \rightarrow \cstr{B}, A \rightarrow \changes{B}, \cplus_\rightarrow)$ is well defined. 
  (Moreover, it is the exponentiation object (up to unique isomorphism) from $\cstr{A}$ to $\cstr{B}$ in the category of change actions and differentiable functions (Section~\ref{sec:exponentials}).)
  \footnote{
    Either of these conditions is enough to guarantee that the pointwise functional change action
    is well defined, but it can be the case that $\cstr{B}$ satisfies neither and yet pointwise
    change actions into $\cstr{B}$ do exist. A precise account of when pointwise functional change
    actions exist is outside the scope of this paper.
  }
\end{thm}

These pointwise change actions are functional in the sense of \cref{def:functionalChanges}. Moreover, the derivative of the evaluation map is quite easy to 
compute.
\begin{prop}[Derivatives of the evaluation map]
\label{prop:evDerivatives}
  Let $\cstr{A}$ and $\cstr{B}$ be change actions such that the pointwise functional change action
  $\cstr{A} \ptfunc \cstr{B}$ is well defined, and let
  $f: \cstr{A} \rightarrow \cstr{B}$,
  $a : A$, $\change{a} : \changes{A}$,
  $\change{f} : A \rightarrow \changes{B}$.

  Then, by taking a derivative of $f$ we obtain the following derivative for the evaluation map:
  \begin{displaymath}
    \derive{\ev}_1((f, a), (\change{f}, \change{a})) 
    \defeq \derive{f}(a, \change{a}) \splus \change{f}(a \cplus \change{a})
  \end{displaymath}

  Alternatively, by taking a derivative of $f \cplus \change{f}$ we can obtain another derivative
  for the evaluation map:
  \begin{displaymath}
    \derive{\ev}_2((f, a), (\change{f}, \change{a})) 
    \defeq \change{f}(a) \splus \derive{(f \cplus \change{f})}(a, \change{a})
  \end{displaymath}
\end{prop}

Having pointwise function changes allows us to actually compute a derivative of the
evaluation map as shown. In practice, this means
that we will only be able to use the results in \cref{sec:fixpoints} when
we have pointwise change actions, or where we have some other way of computing
a derivative of the evaluation map.

\section{Directed-complete partial orders and fixpoints}

\todompj{signposting}

An important class of posets, particularly relevant to programming language semantics, is that of 
directed-complete partial orders (dcpos) equipped with a least element, and the associated notion of \emph{(Scott-)continuous} maps. 

\subsection{Dcpos}
\label{sec:dcpos}

As before, we can define change actions on dcpos, rather than sets, as change
actions whose sets $A$, $\Delta A$ are endowed with a dcpo structure, and where
the maps $\cplus$, $\splus$ are continuous.

\begin{defn}[Continuous change actions]
  A change action $\cstr{A}$ is \emph{continuous} if
  \begin{itemize}
    \item $A$ and $\changes{A}$ are dcpos.
    \item $\cplus$ is Scott-continuous as a map from $A \times \changes{A} \rightarrow A$.
    \item $\cplus$ is Scott-continuous as a map from $\changes{A} \times \changes{A} \rightarrow \changes{A}$.
  \end{itemize}
\end{defn}

Unlike the case for posets, the change order $\changeOrder$ does \emph{not}, in general,
induce a dcpo on $\changes{A}$. As a counterexample, consider 
the change action $(\overline{\NN}, \NN, +)$, where $\overline{\NN}$ denotes the dcpo of natural numbers
extended with a positive infinity.

A key example of a continuous change action is the $\cstr{L}_\superpose$ change
action on Boolean algebras.

\begin{prop}[name=Boolean algebra continuity, restate=booleanAlgebraContinuous]
  \label{prop:booleanAlgebraContinuous}
  Let $L$ be a Boolean algebra. Then $\cstr{L}_\superpose$ is a continuous
  change action.
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:booleanAlgebraContinuous}.
\end{proof}
\fi

For a general overview of results in domain theory and dcpos, we refer the reader to an
introductory work such as \cite{abramsky1994domain}, but we state here some specific results that
we shall be using, such as the following, whose proof can be found in 
\cite[Lemma~3.2.6]{abramsky1994domain}:

\begin{prop}[Distributivity of limits across arguments]
  \label{prop:distributivityLimit}
  A function $f : A \times B \rightarrow C$ is continuous iff it is continuous in each variable
  separately.
\end{prop}

It is a well-known result in standard calculus that the limit of an absolutely convergent sequence of
differentiable functions $\{f_i\}$ is itself differentiable, and its derivative is equal to the limit
of the derivatives of the $f_i$. A remarkable consequence of the previous distributivity property
is the following analogous result:

\begin{corollary}[Continuity of differentiation]
  \label{cor:diffContinuous}
  Let $\cstr{A}$, $\cstr{B}$ be change actions, with $\cstr{B}$ continuous and let $\{f_i\}$ and $\{\derive{f_i}\}$ be
  $I$-indexed directed families of functions in $A \rightarrow B$ and $A \times \changes{A} \rightarrow \changes{B}$.

  Then, if for every $i : I$ it is the case that $\derive{f_i}$ is a derivative of $f_i$, then $\bigsqcup_{i : I} \derive{f_i}$ is
  a derivative of $\bigsqcup_{i : I} f_i $.
\end{corollary}
\ifproofs
\begin{proof}
  It suffices to apply $\cplus$ and \cref{prop:distributivityLimit} to the directed families $\{ f_i(a) \}$ and
  $\{ \derive{f_i}(a, \change{a}) \}$.
\end{proof}
\fi

We also state the following additional fixpoint lemma. This is a specialization of
Beki\'c's Theorem \autocite[][section 10.1]{winskel1993formal}, but it has a straightforward direct proof.

\begin{prop}[name=Factoring of fixpoints, restate=factoringFixpoints]
  \label{prop:factoringFixpoints}
  Let $A$ and $B$ be dcpos, $f : A \rightarrow A$ and $g: A \times B \rightarrow B$ be continuous, and let
  \begin{displaymath}
    h(a, b) \defeq (f(a), g(a, b))
  \end{displaymath}
  Then
  \begin{displaymath}
    \lfp(h) = (\lfp(f), \lfp(\lambda b . g(\lfp(f), b)))
  \end{displaymath}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:factoringFixpoints}.
\end{proof}
\fi

\subsection{Fixpoints}
\label{sec:fixpoints}

\todompj{signposting}

Fixpoints appear frequently in the semantics of languages with recursion. If we
can give a generic account of how to compute fixpoints using change actions,
then this gives us a compositional way of extending a derivative for the
non-recursive semantics of a language to a derivative that can handle recursion.
We will do this later to handle full recursive Datalog (\cref{sec:datalogIncr}).

\subsubsection{Iteration functions}
\label{sec:iteration}

Over directed-complete partial orders we can define a least fixpoint operator $\lfp$ in terms of the
iteration function $\iter$:
\begin{align*}
  &\lfp : (A \rightarrow A) \rightarrow A\\
  &\lfp \defeq \bigsqcup_{n : \NN} \iter_n \\
  &\iter : (A \rightarrow A) \times \NN \rightarrow A\\
  &\iter(f, n) \defeq f^n(\bot)
\end{align*}

The iteration function is the basis for all the results in this section:
we can take its partial derivative with respect to $n$, and this will give us a way to get
to the next iteration incrementally; and we can take the partial derivative
with respect to $f$, and this will give us a way to get from iterating $f$ to iterating $f
\cplus \change{f}$.\footnote{
  The sharp-eyed reader may have noticed that we
  could also abstract out the point from which we begin iterating (which is of
  course typically $\bot$) and differentiate with respect to that.
}

\subsubsection{Incremental computation of fixpoints}

The following theorems provide a
generalization of semi-naive evaluation to any differentiable function over a
continuous change action. Throughout this section we will assume that we have a contiuous change action
$\cstr{A}$, and any reference to the change action $\cstr{\NN}$ will refer to the obvious monoidal
change action on the naturals defined in \cref{sec:examples}.

Since we are trying to incrementalize the iterative step, we start by taking the partial
derivative of $\iter$ with respect to $n$.

\todompj{Don't we have least elements as standard? I think we want to assume
  that. I assume the weird thing with $\cminus$ is to avoid requiring
  completeness? It reads oddly.}
\begin{prop}[name=Derivative of the iteration map with respect to $n$, restate=iterDerivativesN]
  \label{prop:iterDerivativesN}
  Let $\cstr{A}$ be a complete change action and let $f: A \rightarrow A$ be a differentiable function. 
  Then $\iter$ is differentiable with respect to its second
  argument, and its partial derivative is given by:
  \begin{align*}
    &\partial_2{\iter}: (A \rightarrow A) \times \NN \times \changes{\NN} \rightarrow \changes{A}\\
    &\partial_2{\iter}(f, 0, m) \defeq \iter(f, m) \cminus \bot\\
    &\partial_2{\iter}(f, n+1, m) \defeq \derive{f}(\iter(f, n), \partial_2{\iter}(f, n, m))
  \end{align*}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:iterDerivativesN}.
\end{proof}
\fi

By using the following recurrence relation, 
we can then compute $\partial_2{\iter}(f, n, 1)$ along with $\iter(f, n)$ simultaneously:
\begin{align*}
  &\nextiter_f : A \times \changes{A} \rightarrow A \times \changes{A}\\
  &\nextiter_f (\bot, \bot) \defeq (\bot, f(\bot) \cminus \bot)\\
  &\nextiter_f (a, \change{a}) \defeq (a \cplus \change{a}, \derive{f}(a, \change{a}))
\end{align*}
Which has the property that
\begin{align*}
  &\nextiter_f^n (\bot, \bot) = (\iter(f, n), \partial_2{\iter}(f, n, 1))
\end{align*}

This gives us a way to compute a fixpoint incrementally, by adding successive
changes to an accumulator until we reach it. This is exactly how
semi-naive evaluation works, with the delta relation and the accumulator relation.

\begin{thm}[name=Incremental computation of least fixpoints, restate=fixpointIter]
\label{thm:fixpointIter}
  Let $\cstr{A}$ be a complete, continuous change action, $f: \cstr{A} \rightarrow
  \cstr{A}$ be continuous and differentiable.

  Then $\lfp(f) = \bigsqcup_{n : \NN}(\pi_1(\nextiter_f^n(\bot, \bot)))$.\footnote{
    Note that we have \emph{not} taken the fixpoint of $\nextiter_f$, since it is
    not continuous.}
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:fixpointIter}.
\end{proof}
\fi

\subsubsection{Derivatives of fixpoints}
\label{sec:fixpointDerivatives}

In the previous section we have shown how to use derivatives to compute fixpoints
more efficiently, but we also want to take the derivative of the fixpoint
operator itself. A typical use case for this is where we have calculated some fixpoint
\begin{displaymath}
  F_{E} \defeq \fixpoint (\lambda X . F(E, X))
\end{displaymath}
then update the parameter $E$ with some change $\change{E}$ and wish to compute the new
value of the fixpoint, i.e.
\begin{displaymath}
  F_{E \cplus \change{E}} \defeq \fixpoint (\lambda X . F(E \cplus \change{E}, X))
\end{displaymath}

If $F : B \times A \rightarrow A$ and $\cstr{A}$ is a change action such that 
$\cstr{A} \ptfunc \cstr{A}$ is well-defined, then 
$\lambda X . F(E \cplus \change{E}, X) = (\lambda X . F(E, X)) \cplus_{pt} (\lambda X . \change{E})$,
i.e. we are applying a change to the \emph{function} whose fixpoint we are taking.

In Datalog this would allow us to update a recursively defined relation given an
update to one of its non-recursive dependencies, or the extensional database.
For example, we might want to take the transitive closure relation
and update it by changing the edge relation $e$.\footnote{See
  \cref{sec:workedExample} for a worked example of this process.}

However, this requires us to provide a derivative for the fixpoint operator
$\fixpoint$ with respect to the function whose fixpoint is being taken.

\begin{defn}[Derivatives of fixpoints]
\label{def:fixpointDerivatives}
  Let $\cstr{A}$ be a change action, let $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{A}$ be a functional
  change action (not necessarily pointwise) and suppose $\fixpoint_U$ and $\fixpoint_{\changes{A}}$ are fixpoint
  operators for functions in $U$ and $\changes{A}$ respectively.
  
  Then we define
  \begin{align*}
    &\adjust : U \times \changes{U} \rightarrow (\changes{A} \rightarrow \changes{A})\\
    &\adjust(f, \change{f}) \defeq \lambda\ \change{a} . \derive{\ev}((f, \fixpoint_U(f)), (\change{f}, \change{a}))\\
    &\derive{\fixpoint_U} : U \times \changes{U} \rightarrow \changes{A}\\
    &\derive{\fixpoint_U}(f, \change{f}) \defeq \fixpoint_{\changes{A}}(\adjust(f, \change{f}))
  \end{align*}
\end{defn}

The suggestively named $\derive{\fixpoint_A}$ will in fact turn out to be a
derivative \textemdash{} for \emph{least} fixpoints. The appearance of
$\derive{\ev}$, a derivative of the evaluation map, in the definition of
$\adjust$ is also no coincidence: as evaluating a fixpoint consists of many
steps of applying the evaluation map, so computing the derivative of a fixpoint
consists of many stages of applying the derivative of the evaluatoin
map.\footnote{Perhaps surprisingly, the authors first discovered an expanded
  version of this formula, and it was only later that we realised the remarkable
  connection to $\derive{\ev}$.}

\begin{thm}[name=Pseudo-derivatives of fixpoints, restate=fixpointPseudoDerivatives]
\label{thm:fixpointPseudoDerivatives}
  Let $\cstr{A}$, $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{A}$, $\fixpoint_{U}$,
  $\fixpoint_{\changes A}$ be as in \cref{def:fixpointDerivatives}. Then, for any
  differentiable function $f : U$ and any change $\change{f} : \changes{U}$,
  $\fixpoint_U(f) \cplus \derive{\fixpoint_U}(f, \change{f})$ is a fixpoint
  of $f \cplus \change{f}$.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:fixpointPseudoDerivatives}.
\end{proof}
\fi

This is not enough to give us a true derivative, because we have only shown
that $\fixpoint_U(f) \cplus \derive{\fixpoint_U}(f, \change{f})$ computes \emph{a} 
fixpoint for $f \cplus \change{f}$, but not necessarily
the same one computed by $\fixpoint_U{(f \cplus \change{f})}$.

However, if we restrict ourselves to directed-complete partial orders, least
fixpoints, and continuous change actions, then $\derive{\lfp}$ (using the
derivative definition from \cref{def:fixpointDerivatives}) \emph{is} a
derivative of $\lfp$. This is not too onerous a restriction, since this is
a very natural setting for computing fixpoints.

Since $\lfp$ is characterized as the limit of a chain of functions,
\cref{cor:diffContinuous} suggests a way to compute its derivative. It suffices to find a derivative
$\derive{\iter_n}$ of each iteration map 
such that the resulting set $\{ \derive{\iter_n} \mid n : \NN\}$ is directed, 
which will entail that $\bigsqcup_{n : \NN}\derive{\iter_n}$ is a derivative of $\lfp$.

These correspond to the first partial derivative of $\iter$ \textemdash{} this time with respect to
$f$. While we are differentiating with respect to $f$, we are still going to
need to define our derivatives inductively in terms of $n$.

\begin{prop}[name=Derivative of the iteration map with respect to $f$, restate=iterDerivativesF]
  \label{prop:iterDerivativesF}
  $\iter$ is differentiable with respect to its first argument and a derivative is given by:
  \begin{align*}
    &\partial_1{\iter} : (A \rightarrow A) \times \changes{(A \rightarrow A)} \times \NN \rightarrow \changes{A}\\
    &\partial_1{\iter} (f, \change{f}, 0) \defeq \bot_{\changes{A}}\\
    &\partial_1{\iter} (f, \change{f}, n + 1) \defeq \derive{\ev}((f, \iter(f, n)), (\change{f}, \partial_1{\iter}(f, \change{f}, n)))
  \end{align*}
\end{prop}
\ifproofs
\begin{proof}
  See \cref{prf:iterDerivativesF}.
\end{proof}
\fi

As before, we can now compute $\derive{\iter}$ together with $\iter$ by
mutual recursion.\footnote{
  In fact, the recursion here is not \emph{mutual}: the first component does not
  depend on the second. However, writing it in this way makes it
  amenable to computation by fixpoint, and we will in fact be able to avoid the
  recomputation of $\iter_n$ when we show that it is equivalent to $\derive{\lfp}$.
}
\begin{align*}
  &\nextiter_{f, \change{f}} : A \times \changes{A} \rightarrow A \times \changes{A}\\
  &\nextiter_{f, \change{f}} (a, \change{a}) \defeq (f(a), \derive{\ev}((f, a), (\change{f}, \change{a})))
\end{align*}
Which has the property that
\begin{align*}
  &\nextiter_{f, \change{f}}^n (\bot, \bot) = (\iter(f, n), \partial_1{\iter}(f, \change{f}, n))
\end{align*}

This indeed provides us with a function whose limit we can take, showing
that $\derive{\lfp}$ is a true derivative.

\begin{thm}[name=Derivatives of least fixpoint operators, restate=leastFixpointDerivatives]
  \label{thm:leastFixpointDerivatives}
  Let
  \begin{itemize}
    \item $\cstr{A}$ be a continuous change action
    \item $U$ be the set of continuous functions $f : A \rightarrow A$, 
      with a functional change action $\cstr{U} \subseteq \cstr{A} \Rightarrow \cstr{A}$
    \item $f : U$ be a continuous, differentiable function
    \item $\change{f} : \changes{U}$ be a function change
    \item $\derive{\ev}$ be a derivative of the evaluation map which is continuous with
      respect to $a$ and $\change{a}$.
  \end{itemize}
  Then $\derive{\lfp}$ is a derivative of $\lfp$.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:leastFixpointDerivatives}.
\end{proof}
\fi

Computing this derivative still requires computing a fixpoint \textemdash{} over the change
lattice \textemdash{} but this may still be significantly less expensive than
recomputing the full new fixpoint.

\section{Derivatives for recursive Datalog}
\label{sec:recursiveDatalog}

Given the non-recursive semantics for a language, we can extend it to handle
recursive definitions using fixpoints. \Cref{sec:fixpoints} lets us extend our
derivative for the non-recursive semantics to a derivative for the recursive
semantics, as well as letting us compute the fixpoints themselves
incrementally. 

Again, we will demonstrate the technique with Datalog, although the approach is generic.

\subsection{Semantics of Datalog programs}

First of all, we define the usual ``immediate consequence operator'' which
computes ``one step'' of our program semantics.

\begin{defn}[Immediate consequence operator]
  Given a program $\mathcal{P} = (P_1, \dots, P_m)$, where $P_i$ is a predicate,
  the immediate consequence operator $\consq: \Rel^n \rightarrow \Rel^n$ is defined as follows:
  \begin{displaymath}
    \consq(R_1, \dots, R_n) = (\denote{P_1}(R_1, \dots, R_n), \dots, \denote{P_m}(R_1, \dots, R_n))
  \end{displaymath}
\end{defn}

That is, given a value for the program, we pass in all the relations
to the denotation of each predicate, to get a new tuple of relations.

\begin{defn}[Program semantics]
  The semantics of a program $\mathcal{P}$ is defined to be
  \begin{displaymath}
    \denote{\mathcal{P}} \defeq \lfp_{\Rel^n}(\consq)
  \end{displaymath}
  and may be calculated by iterative application of $\consq$ to $\bot$ until
  fixpoint is reached.
\end{defn}

Whether or not this program semantics exists will depend on whether the fixpoint
exists. Typically this is ensured by constraining the program such that $\consq$
is monotone (or, in the context of a dcpo, continuous). We can be agnostic
about this when applying \cref{thm:fixpointIter}, but it is a requirement when
applying \cref{thm:leastFixpointDerivatives}.

\subsection{Incremental evaluation of Datalog}
\label{sec:datalogIncr}

We can easily extend a derivative for the formula semantics to a derivative for
the immediate consequence operator $\consq$. Putting this together with the
results from \cref{sec:fixpoints}, we get our two big results.

\begin{corollary}[Incremental evaluation of Datalog semantics]
\label{thm:diffEval}
  Datalog program semantics can be evaluated incrementally.
\end{corollary}
\ifproofs
\begin{proof}
  Corollary of \cref{thm:fixpointIter} and \cref{corollary:consqDiff}.
\end{proof}
\fi

This is known (semi-naive evaluation), but our proof is more
modular, so we will be able to extend this result more easily.

\begin{corollary}[Incremental maintenance of Datalog semantics]
\label{thm:diffUpdate}
  Datalog program semantics can be incrementally maintained with changes to
  extensional relations.
\end{corollary}
\ifproofs
\begin{proof}
  Corollary of \cref{thm:leastFixpointDerivatives} and \cref{corollary:consqDiff}.
\end{proof}
\fi

This is known \autocite[see][and successors]{gupta1993maintaining},
but again, the proof is now modular so we can extend it.

\subsubsection{Worked example of updating a recursive Datalog program}
\label{sec:workedExample}

The algorithm in \cref{thm:leastFixpointDerivatives} is very abstract, and it is
hard to see how it will work out in practice. It is therefore worth doing a
simple worked example.

% You can recompute the example using ql/Fixpoints.ql, if you want to change the data

Consider the $tc$ program from \cref{sec:intro}:
\begin{align*}
  tc(x, y) &\leftarrow e(x, y) \vee \exists z.(e(x, z) \wedge tc(z, y))
\end{align*}

We will start with an edge relation $e_1$ and change it to a new edge relation
$e_2$ by applying a change $\change{e}$, which both adds and removes some values.
\begin{align*}
  e_1 &= \{(1,2), (2,3), (3,4), (5,6) \}\\
  \change{e} &= (\{(4,5)\}, \{(2,3)\})\\
  e_2 &= e_1 \cplus \change{e}\\
      &=\{ (1,2), (3,4), (4,5), (5,6) \}
\end{align*}

We want to update the fixpoint of $tc$ using $e_1$, which we will call
$tc_{e_1}$,  to the fixpoint of $tc$ using $e_2$, which we will call $tc_{e_2}$.
As we have seen in \cref{thm:leastFixpointDerivatives},
we can do this by computing the fixpoint $\change{w} = \lfp(\adjust(tc_{e_1}, \change{tc}))$. 

A reminder of the expanded definition of $\adjust$:
\begin{align*}
  \adjust(f, \change{f}) &= \lambda\ \change{a}. \change{f}(\lfp(f)) \splus \derive{(f \cplus \change{f})}(\lfp(f), \change{a})
\end{align*}

We've chosen the second defintion of $\ev$ from \cref{prop:evDerivatives}, since
we already know what $f \cplus \change{f}$ looks like \textemdash{} it is simply
$\denote{tc_{e_2}}$ \textemdash{} and $\change{tc}(\lfp(tc_{e_1}))$ can be
computed once up front and reused throughout the computation.

We need the derivative of $tc_{e_2}$:
\begin{align*}
  \updiff(tc_{e_2}(x, y)) \leftarrow & \exists z. (e_2(x,z) \wedge \updiff(tc_{e_2}(z, y)))\\
  \downdiff(tc_{e_2}(x, y)) \leftarrow & \neg e_2(x, y)\\
    &\wedge
    \exists z . (e_2(x, z) \wedge \downdiff(tc_{e_2}(z, y)))\\
    &\wedge
    \neg \exists z . (e_2(x, z) \wedge \bothdiff(tc_{e_2}(z,y)))
\end{align*}

We also need $\change{tc}$:
\begin{align*}
  \change{tc}(f) = &\\
  &(e_2(x,y) \vee \exists z . (e_2(x,z) \wedge f(z,y))) \\
  &\cminus (e_1(x,y) \vee \exists z . (e_1(x,z) \wedge f(z,y)))
\end{align*}

We can now evaluate the fixpoint.\footnote{We would of course like to evaluate this fixpoint
  incrementally, which we can do with exactly the same theoretical machinery.}
Here is how the changes evolve:
\begin{center}
  \begin{tabular} {p{3.5em} p{10em} p{10em}}
    Iteration & Additions to $\updiff$ & Additions to $\downdiff$ \\
    \toprule
    1 & $\{ (4,5), (4,6) \}$ & $\{ (2,3), (2,4) \}$\\
    2 & $\{ (3,5), (3,6) \}$ & $\{ (1,3), (1,4) \}$\\
    3 & (as above) & (as above) \\
    \bottomrule
  \end{tabular}
\end{center}
\medskip

This results in $\change{w} = (\{ (3,5), (3,6), (4,5), (4,6)\}, \{(1,3), (1,4), (2,3), (2,4)\})$.
Applying the change and shows that we have indeed computed the new fixpoint.
\begin{align*}
  tc_{e_1} \cplus \change{w} &= \{(1,2), (1,3), (1,4), (2,3), (2,4), (5,6)\} \cplus \change{w}\\
  &= \{(1,2), (3,5), (3,6), (4,5), (4,6), (5,6)\}\\
  &= tc_{e_2}
\end{align*}

\section{The category of change actions}
\label{sec:category}

The sharp-eyed reader will have noticed that we have defined change actions as a
set of objects with special functions between them (differentiable functions),
and where we have change actions for product, sum, and function types. This begs
the question \textemdash{} is there a category here? And is it Cartesian closed?

The answer to this is yes, and we will gesture in the direction of a categorical
account of change actions, although a full treatment is beyond the scope of this paper.

\begin{defn}[Category of change actions]
  The category $\cat{CAct}$ of change actions has change actions as its objects and
  differentiable functions as its morphisms. 
\end{defn}

\subsection{Equivalence with PreOrd}

There is a natural preorder on the base set of a change action, given by reachability
under the action:

\begin{defn}[Reachability preorder]
  $a \reachOrder b$ iff there is a $\change{a} : \changes{A}$ such that $a \cplus
  \change{a} = b$.
\end{defn}

We can characterize many of the properties of change actions in terms of the reachability preorder,
which suggests a connection between $\cat{CAct}$ and the category of preorders, $\cat{PreOrd}$.

\begin{prop}
  A function is differentiable iff it is monotone with respect to the
  reachability preorder. 
\end{prop}

\begin{corollary}
  Two change actions are isomorphic iff their posets under the reachability
  preorder are isomorphic.
\end{corollary}

\begin{corollary}
  Any function from an empty change action or into a complete change
  action is differentiable.
\end{corollary}

Indeed, the correspondence between a change action and its reachability preorder gives rise to
a (full and faithful) functor $\reach : \cat{CAct} \rightarrow \cat{PreOrd}$ that acts as the
identity on morphisms.

Conversely, any preorder $\leq$ on some set $A$ induces a change action
$\cstr{A}_\leq \defeq \cstruct{A}{\leq^\star}{\cplus_\star}$.
The action $\cplus_\star$ is defined as the extension of $\cplus_\leq$ to the free
monoid $\leq^\star$, where $\cplus_\leq$ is defined as:
\[
\begin{aligned}
   \cplus_\leq &: (A \times \leq) \rightarrow A&\\
   a \cplus_\leq (b, c) &\defeq
     \begin{cases}
     c&\text{ if $a = b$}\\
     a&\text{ otherwise}
     \end{cases}
\end{aligned}
\]

The mapping to $\cstr{A}_\leq$ gives rise to a (full and faithful) functor
$\direct : \cat{PreOrd} \rightarrow \cat{CAct}$, again acting as the identity on morphisms.

These two functors are in fact enough to give us an equivalence between the categories
$\cat{CAct}$ and $\cat{PreOrd}$.

\begin{thm}[name=Equivalence of $\cat{CAct}$ and $\cat{PreOrd}$, restate=preordEquivalence]
  \label{thm:preordEquivalence}
  The functor $\reach$ from $\cat{CAct}$ to $\cat{PreOrd}$ together with the
  functor $\direct$ in the opposite direction form an equivalence of categories.
\end{thm}
\ifproofs
\begin{proof}
  See \cref{prf:preordEquivalence}.
\end{proof}
\fi

Since $\cat{PreOrd}$ is a Cartesian closed category and has all limits and
colimits, this gives us a proof of the existence of limits, colimits, and exponentials in $\cat{CAct}$.

\begin{corollary}
  The category $\cat{CAct}$ has all limits, colimits and exponential objects.
\end{corollary}

In the case of complete change actions, this equivalence degenerates into an
equivalence with $\cat{Set}$, since all functions are differentiable.

\subsection{Exponentials}
\label{sec:exponentials}

The exponential objects in the category $\cat{CAct}$ are difficult to work with,
because we need to ensure that $f \cplus \change{f}$ continues to be a
differentiable function. Fortunately, under some circumstances these correspond
to the pointwise functional change actions we saw earlier (in \cref{sec:pointwiseFunctional}).

\begin{defn}[Convenient change actions]
  \label{def:convenientChangeActions}
  A change action $\cstr{B}$ is convenient if every exponential object
  $\exponential{\cstr{A}}{\cstr{B}}$ is isomorphic to a pointwise functional change action.
\end{defn}

This corresponds to the intuition about how the correspondence with
$\cat{PreOrd}$ should work, since exponentials $A \Rightarrow B$ in $\cat{PreOrd}$ inherit the
structure of $B$, lifted pointwise.

As we mentioned in \cref{sec:pointwiseFunctional}, 
the pointwise functional change action is not well defined for all change actions.
This is because we require every pointwise change $\change{f}$ to map a differentiable
function $f$ into a differentiable function $f \cplus \change{f}$, but there is no way
to guarantee that this is the case for arbitrary pointwise changes.
Fortunately, convenient change actions form a relatively large subcategory of $\cat{CAct}$.

\begin{prop}[name=Convenient change actions, restate=convenientChangeActionProps]
  \label{prop:convenientChangeActionProps}
  Every change action $\cstruct{B}{\changes{B}}{\cplus}$ such that the change action
  $\cstruct{\changes{B}}{\changes{B}}{\splus}$ is complete and $\cplus$ is differentiable with
  respect to its first argument is convenient.

  In particular, every change action where $\cplus$ is a group action is convenient.
\end{prop}
\ifproofs
  See \cref{prf:convenientChangeActionProps}.
\fi

\begin{prop}[name=Complete change actions are convenient, restate=pointwiseComplete]
  \label{prop:pointwiseComplete}
   Every complete change action $\cstr{B}$ is convenient.
\end{prop}
\ifproofs
  See \cref{prf:pointwiseComplete}.
\fi

Since the product and exponential of complete change actions is also complete,  the complete change
actions are a Cartesian closed full subcategory of $\cat{CAct}$ which is, in fact equivalent
to $\cat{Set}$ (as every set-theoretic function between complete change actions is differentiable).

Furthermore, it can be shown that convenient change actions are themselves a Cartesian closed
subcategory of $\cat{CAct}$, and therefore constitute a viable setting for general, higher-order
incremental computation.

\begin{prop}[name=Convenient category of change actions]
  Let $\cstr{A}$ and $\cstr{B}$ be convenient change actions. Then the product 
  $\cstr{A} \times \cstr{B}$ and the exponential $\cstr{A} \Rightarrow \cstr{B}$ are also convenient
  change actions.
  
  Hence $\cat{Conv}$, the full subcategory of $\cat{CAct}$ whose objects are all the convenient change
  actions, is a Cartesian closed category.
\end{prop}

\section{Related work}

\subsection{Change actions and incremental computation}

\subsubsection{Change structures}
\label{sec:relatedChangeStructures}

The seminal paper in this area is \textcite{cai2014changes}. We deviate from
that excellent paper in three regards: the
inclusion of minus operators, the nature of function changes, and the use of
dependent types.

We have omitted minus operators from our definition because
there are many interesting change actions that are not complete and so cannot
have a minus operator. Where we can find a change structure with a minus operator, often we are
forced to use unwieldy representations for change sets, and
\citeauthor{cai2014changes} cite this as their reason for using a dependent
type of changes. For example, the monoidal change actions on sets and lists are clearly
useful for incremental computation on streams, yet they do not admit minus
operators \textemdash{} instead, one would
be forced to work with e.g. multisets admitting negative arities, as \citeauthor{cai2014changes} do.

Our function changes (when well behaved) correspond to what \citeauthor{cai2014changes} call
\emph{pointwise differences} \autocite[see][section 2.2]{cai2014changes}. As
they point out, you can reconstruct their
function changes from pointwise changes and derivatives, so the two formulations
are equivalent. However, our function changes correspond to the
exponentials that we get from the categorical equivalence with $\cat{PreOrd}$,
and (when we can use them) pointwise differences are easier to work with.

The equivalence of our presentations means that our work should be compatible
with ILC \autocite[see][section 3]{cai2014changes}. The derivatives we give in \cref{sec:datalogDifferentiability} are more or
less a ``change semantics'' for Datalog \autocite[see][section
3.5]{cai2014changes}. 

\subsubsection{S-acts}
\label{sec:sacts}

S-acts (i.e the category of monoid actions on sets) and their categorical structure have received a fair amount of attention
over the years (\textcite{kilp2000monoids} is a good
overview). However, there is a key difference between our $\cat{CAct}$ and the category of
S-acts $\cat{SAct}$: the objects of $\cat{SAct}$ all maintain the same monoid
structure, whereas we are interested in changing both the base set \emph{and} the structure of the act.

There are similarities: if we compare the definition of an ``act-preserving''
homeomorphism in $\cat{SAct}$ \autocite[see][]{kilp2000monoids} we can see that the structure is
quite similar to the definition of differentiability:
\begin{displaymath}
  f(a \splus s) = f(a) \splus s
\end{displaymath}
as opposed to
\begin{displaymath}
  f(a \cplus s) = f(a) \cplus \derive{f}(a, s)
\end{displaymath}
That is, we use $\derive{f}$ to transform the action element into the new
monoid, whereas in $\cat{SAct}$ it simply remains the same.

In fact, $\cat{SAct}$ is a subcategory of $\cat{CAct}$, where we only
consider change actions with change set $S$, and the only functions are those
whose derivative is $\lambda a. \lambda d. d$.

\subsubsection{Derivatives of fixpoints}

\textcite{arntz2017fixpoints} gives a derivative operator for fixpoints based on
the framework in \textcite{cai2014changes}. However, since we have different
notions of function changes, the result is inapplicable as
stated. In addition, we require a somewhat different set of conditions, in particular we
don't require our changes to always be increasing.

\subsection{Datalog}

\subsubsection{Incremental evaluation}

The earliest interpretation of semi-naive evaluation as a derivative 
appears in \textcite{bancilhon1986naive}. The idea of using an approximate derivative
and the requisite soundness condition appears as a throwaway comment in
\textcite[][section 3.2.2]{bancilhon1986amateur}, and as far as we know nobody has since
developed that approach.

As far as we know, traditional semi-naive is the state of
the art in incremental, bottom-up, Datalog evaluation, and there are no strategies that
accommodate additional language features such as parity-stratified negation and aggregates.

\subsubsection{Incremental maintenance}

There is existing literature on incremental maintenance of relational algebra
expressions. In particular \textcite{griffin1997improved} following
\textcite{qian1991incremental} shows the essential insight that it is necessary to
track both an ``upwards'' and a ``downwards'' difference, and produces a set of
rules that look quite similar to those we derive in \cref{thm:concreteDatalog}.

Where our presentation improves over \citeauthor{griffin1997improved} is mainly in
the genericity of the presentation. Our machinery works for a wider variety of
algebraic structures, and it is clear how the parts of the proof work together
to produce the result. In addition, it is easy to see how to extend the proofs
to cover additional language constructs.

There are some inessential points of difference as well: we work on Datalog,
rather than relational algebra; and we use set semantics rather than bag
semantics. This is largely a matter of convenience: Datalog is an easier
language to work with, and set semantics allows a much wider range of valid
simplifications. However, all the same machinery applies to relational algebra
with bag semantics, it is simply necessary to produce a valid version of \cref{thm:concreteDatalog}.

We also solve the problem of updating \emph{recursive} expressions. As far as we
know, this is unsolved in general. Most of the attempts to solve it have
focussed on Datalog rather than relational algebra, since Datalog is designed to
make heavy use of recursion.

Several approaches
\autocites{gupta1993maintaining}{harrison1992maintenance}
make use of a common tactic: one can get to the new fixed
point by starting from \emph{any} point below it, and then iterating the
semantics again to fixpoint. The approach, then, is to find a way to delete as
few tuples as possible to get below the new fixpoint, and then iterate again
(possibly using an incremental version of the semantics).

This is a perfectly reasonable approach, and given a good, domain-specific,
means of getting below the fixpoint, they can be quite efficient.
The main defect of these approaches is that they \emph{are} domain specific,
and hence inflexible with respect to changes in the language or structure,
whereas our approach is quite generic. Although we know of no theoretical reason
why either approach should give superior performance when both are applicable,
an empirical investigation of this could prove interesting.

Other approaches \autocites{dong2000incremental}{urpi1992method} consider only
restricted subsets of Datalog, or incur other substantial constraints, and our results
are thus significantly more general.

\subsubsection{Embedding Datalog}
\label{sec:embeddingDatalog}

Datafun (\textcite{arntz2016datafun}) is a functional programming language that embeds
Datalog, allowing significant improvements in genericity, such as the use of
higher-order functions. Since we have directly defined a change action and
derivative operator for Datalog, our work could be used as a ``plugin'' in the sense
of \citeauthor{cai2014changes}, allowing Datafun to compute its internal fixpoints
incrementally, but also allowing Datafun expressions to be fully incrementally maintained.

\subsection{Differential $\lambda$-calculus}

Another setting where derivatives of arbitrary higher-order programs have been studied
is the \emph{differential $\lambda$-calculus} \autocites{ehrhard2003differential}{ehrhard2017introduction}.
This is a higher-order, simply-typed
calculus which allows for computing the derivative of a function, in a similar
way to the notion of derivative in Cai's work and the present paper.

While there are clear similarities between the two systems, 
the most important difference is the properties of the derivatives themselves:
in the differential $\lambda$-calculus, derivatives are guaranteed to be linear
in their second argument, whereas in our approach derivatives do not have this restriction 
but are instead required to satisfy a strong relation to the function
that is being differentiated (see \cref{def:derivative}).

Families of denotational models for the differential $\lambda$-calculus have been
studied in depth
\autocites{bucciarelli2010categorical}{blute2010convenient}{cockett2016categorical}{kerjean2016mackey},
and the relationship between these and change actions is the subject of ongoing work.

\subsection{Higher-order automatic differentiation}

Automatic differentiation \autocite{griewank2008evaluating} is a technique that allows
for efficiently computing the derivative of arbitrary programs, with
applications in probabilistic modeling \autocite{kucukelbir2017automatic}
and machine learning \autocite{baydin2014automatic} among other areas. In recent times, this technique has been successfully
applied to higher-order languages \autocites{siskind2008nesting}{baydin2016diffsharp}.
While some approaches have been suggested \autocites{manzyuk2012simply}{kelly2016evolving}, a general
theoretical framework for this technique is still a matter of open research. 

To this purpose, some authors have proposed the incremental $\lambda$-calculus
as a foundational framework on which models of automatic differentiation can
be based \autocite{kelly2016evolving}. We believe our change actions are better suited
to this purpose than the incremental $\lambda$-calculus, since one can easily give them a
synthetic differential geometric reading (by interpreting $\cstr{A}$ as an Euclidean module and $\changes{A}$
as its corresponding spectrum, for example).

\section{Conclusions and future work}

We have presented change actions and their properties, and used them to provide novel
strategies for incrementally evaluating and maintaining recursive functions, in
particular the semantics of Datalog.

Our work opens several avenues for future investigation.

Firstly, the concrete definition of change actions can be generalized in a number of
ways. A 2-categorical presentation (by analogy with the 2-categorical interpretation
of $\cat{PreOrd}$) would smooth over many of the technical difficulties which
the current presentation faces due to the fact that the changes produced
$\derive{f}(a, \change{a})$ can be applied at points other than $f(a)$.
A description of change actions which is generic in
the base category could also be provided, which might lead to models of
the incremental $\lambda$-calculus on different base categories. 

Of those, the theory of change actions on the category of domains is of particular interest. Since
domains are used to model programming language semantics, this could
open up opportunities for incremental evaluation of many programming languages,
even those that do not fit into the model of \citeauthor{cai2014changes}'s ILC.
Our fixpoint theorems are proven over dcpos in general, which is crucial since
fixpoints are often used in domain theory to give a semantics to recursion.

Additionally, we have only begun to explore the tantalizing connection between
change actions, the ILC and synthetic
differential geometry, and a denotational semantics for the
ILC based on smooth spaces is the subject of ongoing research. We believe many concepts
from standard differential geometry, like gradients, vector fields, curves and flows can
be defined for general change actions, which could then have implications for higher-order
computation.

Finally, combining our concrete Datalog derivatives with a system similar to ILC
in a language such as Datafun would be an exciting demonstration of the compositional
power of this approach.

\begin{acks}

We would like to thank Semmle Ltd. for supporting this research, as well as Pavel
Avgustinov, Aditya Sharad, Max Sch\"afer, Katriel Cohn-Gordon, Luke Ong, and Simon Peyton Jones for their
helpful comments on the manuscript.

\end{acks}

\printbibliography

\clearpage
\appendix
\appendixpage
\section{Proofs}

\subsection{Change actions and derivatives}

\products*
\begin{proof}
  \label{prf:products}
  Let $\cstr{Y}$ be a change action, and $f_1: \cstr{Y} \rightarrow \cstr{A}$, $f_2: \cstr{Y}
  \rightarrow \cstr{B}$ be morphisms.

  Then the product morphism in $\cat{Set}$, $\pair{f_1}{f_2}$ is the product
  morphism in $\cat{CAct}$. It can easily be
  shown that $\pair{\derive{f_1}}{\derive{f_2}}$ is a derivative of $\pair{f_1}{f_2}$,
  hence $\pair{f_1}{f_2}$ is a morphism in $\cat{SAct}$.

  Commutativity and uniqueness follow from the corresponding properties of the
  product in the $\cat{Set}$.
\end{proof}

\disjointUnions*
\begin{proof}
  \label{prf:disjointUnions}
  Let $\cstr{Y}$ be a change action, and $f_1 : \cstr{A} \rightarrow \cstr{Y}$, $f_2 : \cstr{B}
  \rightarrow \cstr{Y}$ be differentiable functions.

  As before, it suffices to prove that the universal function $[f_1, f_2]$ in $\cat{Set}$ is a differentiable
  function from $\cstruct{A + B}{\changes{A} \times \changes{B}}{\cplus_{A + B}}$ into $Y$. It's easy to see
  that the following morphism is a derivative:
  \begin{align*}
    \derive{[f_1, f_2]} (i_1 a, (\change{a}, \change{b})) &\defeq f_1'(a, \change{a})\\
    \derive{[f_1, f_2]} (i_2 b, (\change{a}, \change{b})) &\defeq f_2'(b, \change{b})
  \end{align*}
\end{proof}

\subsection{Posets and Boolean algebras}

\lsuperpose*
\begin{proof}
  \label{prf:lsuperpose}
  We show that the monoid action property holds:
  \begin{align*}
    &a \twist \left[(p, q) \splus (r, s)\right]\\
    &= a \twist ((p \wedge \neg s) \vee r, (q \wedge \neg r) \vee s)\\
    &= \left(
      a \vee
      \left(
        \left(
          p \wedge \neg s
        \right)
        \vee r
      \right)
    \right)
    \wedge \neg
    \left(
      \left(
        q \wedge \neg r
      \right)
      \vee s
    \right)\\
    &= \left(
      \left(
        \left(
          a \vee p
        \right)
        \wedge
        \left(
          a \vee \neg s
        \right)
      \right)
      \vee r
    \right)
    \wedge
    \left(
      \neg q \vee r
    \right)
    \wedge
    \neg s
    \tag{distributing $\vee$ over $\wedge$, applying de Morgan rules}\\
    &= \left(
      \left(
        \left(
          a \vee p
        \right)
        \wedge
        \left(
          a \vee \neg s
        \right)
        \wedge
        \neg q
      \right)
      \vee r
    \right)
    \wedge
    \neg s
    \tag{un-distributing $\vee$ over $\wedge$ }\\
    &= \left(
      \left(
        \left(
          a \vee p
        \right)
        \wedge
        \neg q
      \right)
      \vee r
    \right)
    \wedge
    \neg s
    \tag{$r \rightarrow \neg s$}\\
    &= a \twist (p, q) \twist (r, s)
  \end{align*}

  It is easy to show that $\twist$ is well-defined, by showing that $(p,q)
  \twist (r, s) : L \disjointTimes L$ if $(p, q), (r,s) : L \disjointTimes L$.

  Completeness is easy to show.
\end{proof}

\subsection {Derivatives of Datalog formulae}
\concreteDatalog*
\begin{proof}
  \label{prf:concreteDatalog}
  Let $T$ be a Datalog formula with free relation variables $R_1, \ldots, R_n$,
  a choice of a semantics for the free relation variables $\semR_1, \ldots, \semR_n : \Rel_\Gamma$
  and differences $\change{\semR_1}, \ldots, \change{\semR_n} : \Rel_\Gamma \disjointTimes \Rel_\Gamma$.

  For brevity, we refer to the tuple $(\semR_1, \ldots, \semR_n)$ as $\semR$ and
  the tuple $(\change{\semR_1}, \ldots, \change{\semR_n})$ as $\diffR$. We abuse the notation
  and refer to $(\semR_1 \twist \change{\semR_1}, \ldots, \semR_n \twist \change{\semR_n})$
  as $\semR \twist \diffR$. We will also omit the arguments to $\upsem{T}$ and
  $\downsem{T}$ often, as there is never room for ambiguity.

  Then, it is the case that 
  \begin{displaymath}
    \sem{T}_\Gamma(\semR \twist \diffR)
    =
    \sem{T}_\Gamma(\semR) \twist 
    (\sem{\updiff{T}}_\Gamma(\diffR), 
    \sem{\downdiff{T}}_\Gamma(\diffR))
  \end{displaymath}

  We proceed by structural induction on $T$. We omit the cases for $\top$, $\bot$
  and relational variables for being trivial.
  
  Conjunction:
  \begin{align*}
    &\sem{T \wedge U}_\Gamma(\semR \twist \diffR)\\
    %
    &= \sem{T}_\Gamma(\semR \twist \diffR) \cap \sem{U}_\Gamma(\semR \twist \diffR) \tag{semantics of $\wedge$}\\
    %
    &= \sem{T}_\Gamma(\semR) \twist (\upsem{T}_\Gamma, \downsem{T}_\Gamma) 
      \cap \sem{U}_\Gamma(\semR) \twist (\upsem{U}_\Gamma, \downsem{U}_\Gamma) \tag{induction hypothesis}\\
    %
    &= (\sem{T}_\Gamma(\semR) \cup \upsem{T}_\Gamma) \cap \neg \downsem{T}_\Gamma 
      \cap (\sem{U}_\Gamma(\semR) \cup \upsem{U}_\Gamma) \cap \neg \downsem{U}_\Gamma \tag{definition of $\twist$}\\
    &= (\sem{T}_\Gamma(\semR) \cap \neg \downsem{T}_\Gamma \cup \upsem{T}_\Gamma)
      \cap (\sem{U}_\Gamma(\semR) \cap \neg \downsem{U}_\Gamma \cup \upsem{U}_\Gamma) \tag{disjointness of $\upsem{}, \downsem{}$}\\
    %
    &= (\sem{T}_\Gamma(\semR) \cap \neg \downsem{T}_\Gamma) \cap (\sem{U}_\Gamma(\semR) \cap \neg \downsem{U}_\Gamma) \tag{Boolean algebra}\\
    & \cup ((\upsem{T}_\Gamma \cap (\sem{U}_\Gamma(\semR) \cup \upsem{U}_\Gamma) \cap \neg \downsem{U}_\Gamma)
      \cap (\upsem{U}_\Gamma \cap (\sem{T}_\Gamma(\semR) \cup \upsem{T}_\Gamma) \cap \neg \downsem{T}_\Gamma))\\
    %
    &= (\sem{T}_\Gamma(\semR) \cap \neg \downsem{T}_\Gamma) \cap (\sem{U}_\Gamma(\semR) \cap \neg \downsem{U}_\Gamma) \tag{induction hypothesis on $\bothdiff$}\\
    & \cup ((\upsem{T}_\Gamma \cap \bothsem{U}_\Gamma(\semR, \diffR))
            \cup (\upsem{U}_\Gamma \cap \bothsem{T}_\Gamma(\semR, \diffR)))\\
    %
    &= \sem{T}_\Gamma(\semR) \cap \sem{U}_\Gamma(\semR) \cap \neg (\downsem{T}_\Gamma \cup \downsem{U}_\Gamma) \tag{Boolean algebra}\\
      &\cup ((\upsem{T}_\Gamma \cap \bothsem{U}_\Gamma(\semR, \diffR))
            \cup (\upsem{U}_\Gamma \cap \bothsem{T}_\Gamma(\semR, \diffR)))\\
    %
    &= \sem{T}_\Gamma(\semR) \cap \sem{U}_\Gamma(\semR) \tag{Boolean algebra}\\
    & \cup ((\upsem{T}_\Gamma \cap \bothsem{U}_\Gamma)
            \cup (\upsem{U}_\Gamma \cap \bothsem{T}_\Gamma))
      \cap \neg (\downsem{T}_\Gamma \cup \downsem{U}_\Gamma)\\
    %
    &= \sem{T \wedge U}_\Gamma(\semR)
      \twist (\upsem{(T \wedge U)}_\Gamma, \downsem{T}_\Gamma \cup \downsem{U}_\Gamma) \tag{definition of $\twist, \updiff$}\\
    %
    &= \sem{T \wedge U}_\Gamma(\semR)
      \twist (\upsem{(T \wedge U)}_\Gamma, 
      (\downsem{T}_\Gamma \cap \sem{U}_\Gamma(\semR)) \cup (\downsem{U}_\Gamma \cap \sem{T}_\Gamma(\semR))) \tag{Boolean algebra}\\
    %
    &= \sem{T \wedge U}_\Gamma(\semR)
      \twist (\upsem{(T \wedge U)}_\Gamma, \downsem{(T \wedge U)}_\Gamma) \tag{definition of $\downdiff{}$}
  \end{align*}
  
  Disjunction: identical to conjunction.
  
  Negation:
  \begin{align*}
    &\sem{\neg T}_\Gamma(\semR \twist \diffR)\\
    &= \neg \sem{T}_\Gamma(\semR \twist \diffR) \tag{semantics of $\neg$}\\
    &= \neg ((\sem{T}_\Gamma(\semR) \cup \upsem{T}_\Gamma) \cap \neg \downsem{T}_\Gamma) \tag{induction hypothesis, definition of $\twist$}\\
    &= \neg (\sem{T}_\Gamma(\semR) \cup \upsem{T}_\Gamma) \cup \downsem{T}_\Gamma \tag{Boolean algebra}\\
    &= \neg \sem{T}_\Gamma(\semR) \cap \neg \upsem{T}_\Gamma \cup \downsem{T}_\Gamma \tag{Boolean algebra}\\
    &= (\neg \sem{T}_\Gamma(\semR) \cup \downsem{T}_\Gamma) \cap \neg \upsem{T}_\Gamma \tag{disjointness of $\upsem{}, \downsem{}$}\\
    &= \sem{\neg T}_\Gamma(\semR) \twist (\downsem{T}_\Gamma, \upsem{T}_\Gamma) \tag{definition of $\twist$}\\
    &= \sem{\neg T}_\Gamma(\semR) \twist (\upsem{\neg T}_\Gamma, \downsem{\neg T}_\Gamma) \tag{definition of $\updiff{}, \downdiff{}$}
  \end{align*}

  Existential:
  Before proving the existential, we state the following (trivial) properties of the selection map $\sigma_\Gamma$:
  \begin{prop}[Distributivity of $\sigma_\Gamma$]
    \label{prop:sigmaDist}
    For any $A, B : \Rel_{\Gamma, x}$ we have:
    \begin{align*}
      \sigma_\Gamma(A \cup B) &= \sigma_\Gamma(A) \cup \sigma_\Gamma(B)\\
      \sigma_\Gamma (A \cap \neg B) &= \sigma_\Gamma(A) \cap \neg \sigma_\Gamma(B) \cup \sigma_\Gamma(A \cap \neg B)
    \end{align*}
  \end{prop}
  
  With these in mind, we can proceed with the proof proper:
  \begin{align*}
    &\sem{\exists x . T}_\Gamma(\semR \twist \diffR)\\
    &=\sigma_\Gamma(\sem{T}_{\Gamma, x}(\semR \twist \diffR)) \tag{semantics of $\exists$}\\
    &=\sigma_\Gamma(\sem{T}_{\Gamma, x}(\semR) \twist (\upsem{T}_{\Gamma, x}, \downsem{T}_{\Gamma, x})) \tag{induction hypothesis}\\
    &=\sigma_\Gamma((\sem{T}_{\Gamma, x}(\semR) \cup \upsem{T}_{\Gamma, x}) \cap \neg \downsem{T}_{\Gamma, x}) \tag{definition of $\twist$}\\
    %
    &=\sigma_\Gamma(\sem{T}_{\Gamma, x}(\semR) \cup \upsem{T}_{\Gamma, x}) \tag{\cref{prop:sigmaDist}}\\
    &  \cap \neg \sigma_\Gamma(\downsem{T}_{\Gamma, x})
      \cup \sigma_\Gamma((\sem{T}_{\Gamma, x}(\semR) \cup \upsem{T}_{\Gamma, x}) \cap \downsem{T}_{\Gamma, x})\\
    %
    &=(\sigma_\Gamma(\sem{T}_{\Gamma, x}(\semR)) \cup \sigma_\Gamma(\upsem{T}_{\Gamma, x})) \tag{\cref{prop:sigmaDist}}\\
    &\cap \neg \sigma_\Gamma(\downsem{T}_{\Gamma, x})
      \cup \sigma_\Gamma((\sem{T}_{\Gamma, x}(\semR) \cup \upsem{T}_{\Gamma, x}) \cap \downsem{T}_{\Gamma, x})
      \\
    %
    &=(\sigma_\Gamma(\sem{T}_{\Gamma, x}(\semR)) \cup \sigma_\Gamma(\upsem{T}_{\Gamma, x})) \tag{Boolean algebra}\\
    & \cap \neg 
      (\sigma_\Gamma(\downsem{T}_{\Gamma, x} \cap \neg \sigma_\Gamma((\sem{T}_{\Gamma, x}(\semR) \cup \upsem{T}_{\Gamma, x}) \cap \downsem{T}_{\Gamma, x})))
    \\
    %
    &=(\sem{\exists x . T}_{\Gamma}(\semR) \cup \upsem{\exists x . T}_{\Gamma})
      \cap \neg 
      (\downsem{\exists x . T}_{\Gamma} \cap \neg \bothsem{\exists x . T}_\Gamma) \tag{definition of $\updiff{}, \downdiff{}$}\\
    %
    &= \sem{\exists x . T}_\Gamma \twist (\upsem{\exists x . T}_\Gamma, \downsem{\exists x . T}_\Gamma) \tag{definition of $\twist$}
  \end{align*}

\end{proof}

\subsection{Directed-complete partial orders and fixpoints}

\booleanAlgebraContinuous*
\begin{proof}
  \label{prf:booleanAlgebraContinuous}
  $L$ is a complete lattice, so certainly a dcpo. $\cstr{L}_\superpose$ is a
  dcpo with $\bigvee (p_i, q_i) \defeq (\bigvee p_i \wedge \neg \bigwedge q_i, \bigwedge q_i)$.

  Continuity of $\twist$ in its second argument:
  \begin{align*}
    &a \twist \bigvee (p_i, q_i)\\
    &= a \twist (\bigvee p_i, \bigwedge q_i)\\
    &= (a \vee (\bigvee p_i \wedge \neg \bigwedge q_i)) \wedge \neg \bigwedge q_i\\
    &= (a \vee \bigvee p_i) \wedge \neg \bigwedge q_i\\
    &= (a \vee \bigvee p_i) \wedge \bigvee \neg q_i \tag{applying de Morgan}\\
    &= \bigvee (a \vee p_i) \wedge \neg q_i \tag{$\vee$ and $\wedge$ are continuous}\\
    &= \bigvee a \twist (p_i, q_i)
  \end{align*}

  Continuity $\twist$ in its first argument and continuity of $\splus$ follow easily from their definitions and the continuity
  of $\vee$ and $\wedge$.
\end{proof}

\factoringFixpoints*
\begin{proof}
  \label{prf:factoringFixpoints}
  Let
  \begin{displaymath}
    p(b) = (\lfp(f), g(\lfp(f), b))
  \end{displaymath}
  Then $h(h^i(\bot)) \leq p(p^i(\bot))$ (by simple induction), and so by continuity
  \begin{displaymath}
    \lfp(h) = \bigsqcup_{i : \NN} h^i(\bot) \leq \bigsqcup_{i : \NN} p^i(\bot) = \lfp(p)
  \end{displaymath}

  But $h(\lfp(p)) = \lfp(p)$, so $\lfp(h) \leq \lfp(p)$, since $\lfp(h)$ is least.

  Hence $\lfp(h) = \lfp(p) = (\lfp(f), \lfp(\lambda b . g(\lfp(f), b)))$.
\end{proof}

\iterDerivativesN*
\begin{proof}
  \label{prf:iterDerivativesN}
  By induction on $n$. We show the inductive step.
  \begin{align*}
    &\partial_2\iter(f, (n+1) + m)\\
    &=f(\iter(f, n + m)) \tag{definition of $\iter$}\\
    &=f(\iter(f, n) \cplus \partial_2{\iter}(f, n, m)) \tag{by induction}\\
    &=\iter(f, n+1) \cplus \derive{f}(\iter(f, n), \partial_2{\iter}(f, n, m)) \tag{$f$ is differentiable, definition of $\iter$}
  \end{align*}
\end{proof}

\fixpointIter*
\begin{proof}
  \label{prf:fixpointIter}
  \begin{align*}
    &\lfp(\iter_f)\\
    &=\bigsqcup_{n : \NN} \iter(f, n)\\
    &=\bigsqcup_{n : \NN} \pi_1 (\nextiter_f^n(\bot))
  \end{align*}
\end{proof}

\fixpointPseudoDerivatives*
\begin{proof}
  \label{prf:fixpointPseudoDerivatives}
  
  We show that a change $\change{w} : \Delta A$ satisfies
  the equation:
  \begin{equation}\label{eqn:fixcondition}
    \change{w} = \adjust(f, \change{f})(\change{w})
  \end{equation}
  if and only if $\fixpoint(f) \cplus \change{w}$ is a fixpoint of $f \cplus \change{f}$.

  Let $\change{w} : \Delta A$ satisfy \cref{eqn:fixcondition}. Then
  \begin{align*}
    &(f \cplus \change{f})(\fixpoint_A(f) \cplus \change{w})\\
    &= f(\fixpoint(f))
    \cplus
    \adjust(f, \change{f})(\change{w})
    \tag{by \cref{def:functionalChanges}}\\
    &= \fixpoint(f)
    \cplus
    \change{w}
    \tag{rolling the fixpoint and \cref{eqn:fixcondition}}
  \end{align*}

  Hence $\fixpoint(f) \cplus \change{w}$ is a fixpoint of $f \cplus \change{f}$. The converse
  follows from reversing the direction of the proof.
\end{proof}

\iterDerivativesF*
\begin{proof}
  \label{prf:iterDerivativesF}
  The base case is easy to prove.

  For the inductive step:
  \begin{align*}
    &\iter(f \cplus \change{f}, n + 1)\\
    &=(f \cplus \change{f})(\iter(f \cplus \change{f}, n))\\
    &= (f \cplus \change{f})(
        \iter(f, n)
        \cplus \partial_1{\iter}(f, \change{f}, n)
      )
    \tag{ by induction}\\
    &= f(\iter(f, n)) \cplus \derive{\ev}((f, \iter(f, n)), (\change{f},
      \partial_1{\iter}(f, \change{f}, n)))
    \tag{by \cref{def:functionalChanges}}\\
    & =\iter(f, n + 1) \cplus \partial_1{\iter}(f, \change{f}, n)
  \end{align*}
\end{proof}

\leastFixpointDerivatives*
\begin{proof}
  \label{prf:leastFixpointDerivatives}
  $\partial_1{\iter}$ and $\nextiter_{f, \change{f}}$ are continuous since
  $\derive{\ev}$ and $f$ are.

  Hence the set $\{ \partial_1{\iter}(\cdot, \cdot, n) \}$ is directed, and so $\bigsqcup_{i : \NN}
  \{ \partial_1{\iter}(\cdot, \cdot, n) \}$ is indeed a derivative for $\lfp$.

  We now show that it is equivalent to $\derive{\lfp}$:
  \begin{align*}
    &\bigsqcup_{n : \NN} \partial_1{\iter}(f, \change{f}, n)\\
    &=\bigsqcup_{n : \NN} \pi_2(\nextiter_{f, \change{f}}^n(\bot))\\
    &=\pi_2(\bigsqcup_{n : \NN} \nextiter_{f, \change{f}}^n(\bot)) \tag{$\pi_2$ is continuous}\\
    &= \pi_2 (\lfp(\nextiter_{f, \change{f}})) \tag{$\nextiter_{f, \change{f}}$ is continuous, Kleene's Theorem}\\
    &= \pi_2 ((\lfp(f), \lfp (\lambda\ \change{a}. \derive{\ev}((f, \lfp f), (\change{f}, \change{a})))))
    \tag{by \cref{prop:factoringFixpoints}, and the definition of $\nextiter$}\\
    &= \pi_2 (\lfp(f), \lfp(\adjust(f, \change{f})))\\
    &= \lfp(\adjust(f, \change{f}))\\
    &= \derive{\lfp}(f, \change{f})
  \end{align*}
\end{proof}

\subsection{The category of change actions}

\preordEquivalence*
\begin{proof}
  \label{prf:preordEquivalence}
  On one direction, if $U$ is a preorder, it's trivial to check that $\reach (\direct (U)) = U$.

  On the other direction, we need to find a natural isomorphism between $\direct \circ \reach$
  and the identity functor. First, we note that the base set for the change action
  $\direct(\reach(A))$ is the same as the base set for $\cstr{A}$.

  We claim that the desired natural isomorphism is given by the
  the identity on the base sets. It remains to prove that the identities
  $id_A : \cstr{A} \rightarrow \direct(\reach(A))$ and
  $id_{A_{\reachOrder}} : \direct(\reach(A)) \rightarrow \cstr{A}$
  are indeed differentiable in both directions.

  In one direction, a derivative is given by
  \begin{displaymath}
    \derive{id}_A(a, \change{a}) \defeq (a, a \cplus \change{a})
  \end{displaymath}
  Conversely, let $(a, b) : \reachOrder$. By definition of $\reachOrder$, there is some
  $\change{}_{(a, b)} : \changes{A}$ satisfying $a \cplus \change{}_{(a,b)} = b$.
  This gives a definition for the derivative of the identity on pairs:
  \begin{displaymath}
    \derive{id}_{A_{\reachOrder}}(a, (a, b)) \defeq \change{}_{(a, b)}
  \end{displaymath}
  which can be extended freely to the whole change set
  $\reachOrder^\star$.\footnote{Note that since we picked arbitrary change
    representatives, the resulting derivative may not preserve the monoid action.}
\end{proof}

\convenientChangeActionProps*
\begin{proof}
\label{prf:convenientChangeActionProps}
  Let $\cstr{B}$ be a change action, with $\cplus$ differentiable with respect
  to its first argument, and suppose the change action on $\changes{B}$
  is complete.

  First, we prove that the pointwise change action is well defined: let
  $f : \cstr{A} \rightarrow \cstr{B}$ be some differentiable function, and
  $\change{f} : A \rightarrow \changes{B}$ a pointwise change (which is
  differentiable, since $\cstr{\changes{B}}$ is complete). Then:
  \begin{align*}
    &(f \cplus_\rightarrow \change{f})(a \cplus \change{a})\\
    &= f(a \cplus \change{a}) \cplus \change{f}(a \cplus \change{a})\\
    &= (f(a) \cplus \derive{f}(a, \change{a})) \cplus (\change{f}(a) \splus \derive{\change{f}}(a, \change{a}) )\\
    &= f(a) \cplus (\change{f}(a) \splus \derive{\change{f}}(a, \change{a}))
       \cplus \derive{\cplus}((f(a), \derive{f}(a, \change{a})), \change{f}(a \cplus \change{a}))\\
    &= (f \cplus_\rightarrow \change{f})(a) \cplus (\derive{\change{f}}(a, \change{a})
       \splus \derive{\cplus}((f(a), \derive{f}(a, \change{a}), \change{f}(a, \cplus \change{a}))))
  \end{align*}
  Hence $(f \cplus_\rightarrow \change{f})$ is differentiable.
  
  The evaluation map, defined as $\ev(f, a) \defeq f(a)$ is differentiable as well:
  \begin{align*}
    &\ev((f, \change{f}), (a, \change{a}))\\
    &= (f \cplus_\rightarrow \change{f})(a \cplus \change{a}) \\
    &= f(a \cplus \change{a}) \cplus \change{f}(a \cplus \change{a})\\
    &= f(a) \cplus (f'(a, \change{a}) \splus \change{f}(a \cplus \change{a}))\\
    &= \ev(f, a) \cplus (f'(a, \change{a}) \splus \change{f}(a \cplus \change{a}))
  \end{align*}

  Now, on the one hand, suppose that $f : C \times A \rightarrow B$ is a differentiable function,
  and $\curry{f} : C \rightarrow (\exponential{\cstr{A}}{\cstr{B}})$ its corresponding curried version:
  \begin{align*}
    &\curry{f}(c \cplus \change{c})\\
    &= \lambda a . f(c \cplus \change{c}, a)\\
    &= \lambda a . f(c, a) \cplus \derive{f}((c, \change{c}), (a, 0))\\
    &= (\lambda a . f(c, a)) \cplus_\rightarrow (\lambda a . \derive{f}((c, \change{c}), (a, 0)))
  \end{align*}
  Then the function $\lambda a . \derive{f}((c, \change{c}), (a, 0))$ is a derivative for $\curry{f}$,
  thus $\curry{f}$ is differentiable. Conversely, suppose that $\curry{f}$ is differentiable.
  Then we note that, by hypothesis, $\curry{f}(a)$ is differentiable for all $f$, with derivative
  $\derive{f_a}$, and hence:
  \begin{align*}
    &f(a \cplus \change{a}, c \cplus \change{c})\\
    &= \curry{f}(a \cplus \change{a})(c \cplus \change{c})\\
    &= (\curry{f}(a) \cplus_\rightarrow \derive{\curry{f}}(a, \change{a}))(c \cplus \change{c})\\
    &= \curry{f}(a)(c \cplus \change{c}) \cplus \derive{\curry{f}}(a, \change{a})(c\cplus\change{c})\\
    &= \curry{f}(a)(c) \cplus (\derive{f_a}(c, \change{c}) \splus \derive{\curry{f}}(a, \change{a})(c\cplus\change{c}))\\
    &= f(a, c) \cplus (\derive{f_a}(c, \change{c}) \splus \derive{\curry{f}}(a, \change{a})(c\cplus\change{c}))
  \end{align*}
  Thus $f$ is differentiable as a function from $\cstr{C} \times \cstr{A}$ into $\cstr{B}$.
\end{proof}

\pointwiseComplete*
\begin{proof}
\label{prf:pointwiseComplete}
  Let $\cstr{B}$ be a complete change action.
  We prove that the pointwise change action is the exponential object $\exponential{\cstr{A}}{\cstr{B}}$.

  First, we note that the pointwise change action is trivially well defined, since
  every function into $\cstr{B}$ is differentiable. Similarly, the evaluation map
  is differentiable.

  Now consider two elements $\curry{f}$, $\curry{g}$ of $\exponential{\cstr{A}}{\cstr{B}}$. Since
  $\cstr{B}$ is complete, it is endowed with a minus operator $\cminus$, so we define
  $\cminus_\rightarrow : (\exponential{\cstr{A}}{\cstr{B}}) \times (\exponential{\cstr{A}}{\cstr{B}}) \rightarrow A \rightarrow \changes{B}$ by:
  $$ (g \cminus_\rightarrow f)(a) \defeq g(a) \cminus f(a) $$
  It's easy to check that this is indeed a minus operator and, therefore, $\exponential{\cstr{A}}{\cstr{B}}$
  is complete. Thus, trivially, any function $f : C \times A \rightarrow B$ is differentiable
  if and only if its curried version $\curry{f} : C \rightarrow (\exponential{A}{B})$ is.
\end{proof}


\end{document}
